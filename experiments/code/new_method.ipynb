{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Total parameters: 119,873,161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 313/313 [00:57<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Avg Loss: 0.00346, Color Loss: 0.07229, LR: 1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 1: 100%|██████████| 40/40 [00:03<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00309, Color Loss: 0.06812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 93.63it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.34it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.26it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val loss 0.00309 and color loss 0.06812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 313/313 [00:57<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Avg Loss: 0.00325, Color Loss: 0.06845, LR: 9.99e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 2: 100%|██████████| 40/40 [00:03<00:00, 11.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00293, Color Loss: 0.06595\n",
      "New best model saved with val loss 0.00293 and color loss 0.06595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 313/313 [00:57<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Avg Loss: 0.00312, Color Loss: 0.06697, LR: 9.98e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 3: 100%|██████████| 40/40 [00:03<00:00, 11.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00278, Color Loss: 0.06307\n",
      "New best model saved with val loss 0.00278 and color loss 0.06307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Avg Loss: 0.00293, Color Loss: 0.06305, LR: 9.96e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 4: 100%|██████████| 40/40 [00:03<00:00, 11.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00280, Color Loss: 0.06369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Avg Loss: 0.00309, Color Loss: 0.06609, LR: 9.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 5: 100%|██████████| 40/40 [00:03<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00280, Color Loss: 0.06407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 313/313 [00:57<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Avg Loss: 0.00264, Color Loss: 0.05911, LR: 9.91e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 6: 100%|██████████| 40/40 [00:03<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00276, Color Loss: 0.06274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.20it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.80it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.52it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.51it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val loss 0.00276 and color loss 0.06274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 313/313 [00:56<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Avg Loss: 0.00266, Color Loss: 0.05901, LR: 9.88e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 7: 100%|██████████| 40/40 [00:03<00:00, 11.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00273, Color Loss: 0.06177\n",
      "New best model saved with val loss 0.00273 and color loss 0.06177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Avg Loss: 0.00270, Color Loss: 0.05934, LR: 9.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 8: 100%|██████████| 40/40 [00:03<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00277, Color Loss: 0.06236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Avg Loss: 0.00270, Color Loss: 0.05974, LR: 9.80e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 9: 100%|██████████| 40/40 [00:03<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00275, Color Loss: 0.06244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Avg Loss: 0.00253, Color Loss: 0.05677, LR: 9.76e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 10: 100%|██████████| 40/40 [00:03<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00261, Color Loss: 0.05982\n",
      "New best model saved with val loss 0.00261 and color loss 0.05982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Avg Loss: 0.00261, Color Loss: 0.05776, LR: 9.70e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 11: 100%|██████████| 40/40 [00:03<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00260, Color Loss: 0.05989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.44it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 95.05it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.99it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.29it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val loss 0.00260 and color loss 0.05989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Avg Loss: 0.00276, Color Loss: 0.06040, LR: 9.65e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 12: 100%|██████████| 40/40 [00:03<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00269, Color Loss: 0.06123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Avg Loss: 0.00261, Color Loss: 0.05755, LR: 9.59e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 13: 100%|██████████| 40/40 [00:03<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00269, Color Loss: 0.06129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 313/313 [00:56<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Avg Loss: 0.00257, Color Loss: 0.05707, LR: 9.52e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 14: 100%|██████████| 40/40 [00:03<00:00, 11.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00265, Color Loss: 0.06075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 313/313 [00:56<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Avg Loss: 0.00257, Color Loss: 0.05728, LR: 9.46e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 15: 100%|██████████| 40/40 [00:03<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00266, Color Loss: 0.06078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Avg Loss: 0.00225, Color Loss: 0.05137, LR: 9.38e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 16: 100%|██████████| 40/40 [00:03<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00262, Color Loss: 0.06026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.73it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.85it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.72it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.98it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 17: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Avg Loss: 0.00222, Color Loss: 0.05151, LR: 9.30e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 17: 100%|██████████| 40/40 [00:03<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00271, Color Loss: 0.06088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Avg Loss: 0.00215, Color Loss: 0.04983, LR: 9.22e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 18: 100%|██████████| 40/40 [00:03<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00265, Color Loss: 0.06043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Avg Loss: 0.00208, Color Loss: 0.04906, LR: 9.14e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 19: 100%|██████████| 40/40 [00:03<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00266, Color Loss: 0.05999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 313/313 [00:56<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Avg Loss: 0.00222, Color Loss: 0.05129, LR: 9.05e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 20: 100%|██████████| 40/40 [00:03<00:00, 11.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00251, Color Loss: 0.05808\n",
      "New best model saved with val loss 0.00251 and color loss 0.05808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Avg Loss: 0.00215, Color Loss: 0.04994, LR: 8.95e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 21: 100%|██████████| 40/40 [00:03<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00258, Color Loss: 0.05923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.32it/s]\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.50it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.30it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.70it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 22: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Avg Loss: 0.00222, Color Loss: 0.05106, LR: 8.85e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 22: 100%|██████████| 40/40 [00:03<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00251, Color Loss: 0.05843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Avg Loss: 0.00196, Color Loss: 0.04652, LR: 8.75e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 23: 100%|██████████| 40/40 [00:03<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00252, Color Loss: 0.05835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Avg Loss: 0.00210, Color Loss: 0.04878, LR: 8.64e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 24: 100%|██████████| 40/40 [00:03<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00243, Color Loss: 0.05666\n",
      "New best model saved with val loss 0.00243 and color loss 0.05666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Avg Loss: 0.00194, Color Loss: 0.04654, LR: 8.54e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 25: 100%|██████████| 40/40 [00:03<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00247, Color Loss: 0.05751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26: 100%|██████████| 313/313 [00:57<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 - Avg Loss: 0.00197, Color Loss: 0.04650, LR: 8.42e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 26: 100%|██████████| 40/40 [00:03<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00246, Color Loss: 0.05707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.43it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.75it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 95.09it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.60it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 27: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 - Avg Loss: 0.00181, Color Loss: 0.04389, LR: 8.31e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 27: 100%|██████████| 40/40 [00:03<00:00, 11.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00243, Color Loss: 0.05667\n",
      "New best model saved with val loss 0.00243 and color loss 0.05667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 - Avg Loss: 0.00179, Color Loss: 0.04328, LR: 8.19e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 28: 100%|██████████| 40/40 [00:03<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00251, Color Loss: 0.05791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 - Avg Loss: 0.00182, Color Loss: 0.04396, LR: 8.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 29: 100%|██████████| 40/40 [00:03<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00248, Color Loss: 0.05760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Avg Loss: 0.00172, Color Loss: 0.04237, LR: 7.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 30: 100%|██████████| 40/40 [00:03<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00244, Color Loss: 0.05678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 - Avg Loss: 0.00188, Color Loss: 0.04464, LR: 7.81e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 31: 100%|██████████| 40/40 [00:03<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00242, Color Loss: 0.05678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.19it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.79it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.44it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.32it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val loss 0.00242 and color loss 0.05678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 - Avg Loss: 0.00175, Color Loss: 0.04260, LR: 7.68e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 32: 100%|██████████| 40/40 [00:03<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00248, Color Loss: 0.05719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 - Avg Loss: 0.00175, Color Loss: 0.04248, LR: 7.55e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 33: 100%|██████████| 40/40 [00:03<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00246, Color Loss: 0.05720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34: 100%|██████████| 313/313 [00:56<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 - Avg Loss: 0.00143, Color Loss: 0.03681, LR: 7.41e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 34: 100%|██████████| 40/40 [00:03<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00243, Color Loss: 0.05678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 - Avg Loss: 0.00151, Color Loss: 0.03846, LR: 7.27e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 35: 100%|██████████| 40/40 [00:03<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00242, Color Loss: 0.05627\n",
      "New best model saved with val loss 0.00242 and color loss 0.05627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36: 100%|██████████| 313/313 [00:56<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 - Avg Loss: 0.00168, Color Loss: 0.04109, LR: 7.13e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 36: 100%|██████████| 40/40 [00:03<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00241, Color Loss: 0.05619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.76it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.79it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.62it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.50it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val loss 0.00241 and color loss 0.05619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 - Avg Loss: 0.00176, Color Loss: 0.04229, LR: 6.99e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 37: 100%|██████████| 40/40 [00:03<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00242, Color Loss: 0.05644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 - Avg Loss: 0.00148, Color Loss: 0.03715, LR: 6.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 38: 100%|██████████| 40/40 [00:03<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00235, Color Loss: 0.05467\n",
      "New best model saved with val loss 0.00235 and color loss 0.05467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 - Avg Loss: 0.00137, Color Loss: 0.03551, LR: 6.69e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 39: 100%|██████████| 40/40 [00:03<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00238, Color Loss: 0.05577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 - Avg Loss: 0.00142, Color Loss: 0.03642, LR: 6.55e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 40: 100%|██████████| 40/40 [00:03<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00240, Color Loss: 0.05610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 - Avg Loss: 0.00140, Color Loss: 0.03603, LR: 6.39e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 41: 100%|██████████| 40/40 [00:03<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00237, Color Loss: 0.05560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 93.74it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.00it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.12it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.40it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 42: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 - Avg Loss: 0.00133, Color Loss: 0.03477, LR: 6.24e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 42: 100%|██████████| 40/40 [00:03<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00238, Color Loss: 0.05528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 - Avg Loss: 0.00137, Color Loss: 0.03544, LR: 6.09e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 43: 100%|██████████| 40/40 [00:03<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00247, Color Loss: 0.05659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 - Avg Loss: 0.00127, Color Loss: 0.03372, LR: 5.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 44: 100%|██████████| 40/40 [00:03<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00239, Color Loss: 0.05557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 - Avg Loss: 0.00129, Color Loss: 0.03381, LR: 5.78e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 45: 100%|██████████| 40/40 [00:03<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00238, Color Loss: 0.05541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46: 100%|██████████| 313/313 [00:56<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 - Avg Loss: 0.00135, Color Loss: 0.03521, LR: 5.63e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 46: 100%|██████████| 40/40 [00:03<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00231, Color Loss: 0.05445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.52it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.76it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.58it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.10it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val loss 0.00231 and color loss 0.05445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 - Avg Loss: 0.00153, Color Loss: 0.03804, LR: 5.47e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 47: 100%|██████████| 40/40 [00:03<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00241, Color Loss: 0.05602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 - Avg Loss: 0.00143, Color Loss: 0.03652, LR: 5.31e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 48: 100%|██████████| 40/40 [00:03<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00235, Color Loss: 0.05531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 - Avg Loss: 0.00145, Color Loss: 0.03665, LR: 5.16e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 49: 100%|██████████| 40/40 [00:03<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00233, Color Loss: 0.05450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 - Avg Loss: 0.00142, Color Loss: 0.03631, LR: 5.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 50: 100%|██████████| 40/40 [00:03<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00238, Color Loss: 0.05511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 - Avg Loss: 0.00145, Color Loss: 0.03690, LR: 4.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 51: 100%|██████████| 40/40 [00:03<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00236, Color Loss: 0.05495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.35it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.83it/s]\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 95.23it/s]\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.01it/s]\n",
      "Training Epoch 52: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 - Avg Loss: 0.00143, Color Loss: 0.03629, LR: 4.69e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 52: 100%|██████████| 40/40 [00:03<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00238, Color Loss: 0.05541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 - Avg Loss: 0.00136, Color Loss: 0.03502, LR: 4.53e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 53: 100%|██████████| 40/40 [00:03<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00236, Color Loss: 0.05502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 - Avg Loss: 0.00142, Color Loss: 0.03614, LR: 4.37e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 54: 100%|██████████| 40/40 [00:03<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00239, Color Loss: 0.05549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 - Avg Loss: 0.00137, Color Loss: 0.03509, LR: 4.22e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 55: 100%|██████████| 40/40 [00:03<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00232, Color Loss: 0.05461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 - Avg Loss: 0.00142, Color Loss: 0.03621, LR: 4.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 56: 100%|██████████| 40/40 [00:03<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00239, Color Loss: 0.05577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.39it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.65it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.96it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.48it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping after 56 epochs!\n",
      "Training completed!\n",
      "Loaded best model from epoch 46 with val loss 0.00231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 95.42it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 96.06it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 95.09it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 95.59it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.0407_test/test_sample_1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 825\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# 執行訓練\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;66;03m# 開始訓練W\u001b[39;00m\n\u001b[0;32m--> 825\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 820\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(epochs, patience)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded best model from epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with val loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# 測試復原效果\u001b[39;00m\n\u001b[0;32m--> 820\u001b[0m \u001b[43mtest_restoration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 746\u001b[0m, in \u001b[0;36mtest_restoration\u001b[0;34m(model, quality_levels)\u001b[0m\n\u001b[1;32m    743\u001b[0m         plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    745\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m--> 746\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.0407_test/test_sample_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# 顯示平均結果\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py:1023\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39msavefig)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavefig\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1022\u001b[0m     fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[0;32m-> 1023\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py:3343\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3339\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3340\u001b[0m         stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m   3341\u001b[0m             ax\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39m_cm_set(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m-> 3343\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2366\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2368\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2372\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2373\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2228\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2231\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2232\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py:458\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 458\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py:1689\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1687\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1688\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[0;32m-> 1689\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py:2317\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2320\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.0407_test/test_sample_1.png'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from PIL import Image\n",
    "import io\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pytorch_msssim import ssim\n",
    "import lpips\n",
    "\n",
    "# 設定設備\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 資料預處理\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "train_dataset, valid_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, valid_size, test_size]\n",
    ")\n",
    "\n",
    "# 資料載入器設定\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# 改進的JPEG壓縮函數\n",
    "def jpeg_compress(x, quality):\n",
    "    \"\"\"執行JPEG壓縮並加強色彩保存\"\"\"\n",
    "    x = (x * 127.5 + 127.5).clamp(0, 255).to(torch.uint8).cpu()\n",
    "    compressed_images = []\n",
    "    for img in x:\n",
    "        pil_img = torchvision.transforms.ToPILImage()(img)\n",
    "        buffer = io.BytesIO()\n",
    "        # 確保quality在1-100的有效範圍內\n",
    "        quality = max(1, min(100, int(quality)))\n",
    "        # 根據質量選擇子採樣模式，提高色彩保留\n",
    "        subsampling = \"4:4:4\" if quality > 30 else \"4:2:0\"\n",
    "        pil_img.save(buffer, format=\"JPEG\", quality=quality, subsampling=subsampling)\n",
    "        buffer.seek(0)\n",
    "        compressed_img = Image.open(buffer)\n",
    "        compressed_tensor = torchvision.transforms.ToTensor()(compressed_img)\n",
    "        compressed_images.append(compressed_tensor)\n",
    "    return torch.stack(compressed_images).to(device).sub(0.5).div(0.5)\n",
    "\n",
    "# 色彩感知損失函數\n",
    "def color_preservation_loss(pred, target):\n",
    "    \"\"\"色彩保存損失，增加色度重要性\"\"\"\n",
    "    # 將圖像轉換到[0,1]範圍\n",
    "    pred = (pred * 0.5 + 0.5).clamp(0, 1)\n",
    "    target = (target * 0.5 + 0.5).clamp(0, 1)\n",
    "    \n",
    "    # 計算RGB差異，給予綠色通道較高權重\n",
    "    r_loss = F.l1_loss(pred[:, 0], target[:, 0])\n",
    "    g_loss = F.l1_loss(pred[:, 1], target[:, 1])\n",
    "    b_loss = F.l1_loss(pred[:, 2], target[:, 2])\n",
    "    \n",
    "    # 綠色通道權重略高，因人眼對綠色更敏感\n",
    "    color_loss = 0.25 * r_loss + 0.5 * g_loss + 0.25 * b_loss\n",
    "    \n",
    "    # 額外添加結構相似性損失\n",
    "    ssim_loss = 1 - ssim(pred, target, data_range=1.0, size_average=True)\n",
    "    \n",
    "    # 結合損失\n",
    "    return color_loss + 0.5 * ssim_loss\n",
    "\n",
    "# 時間嵌入模組\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim * 4, dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, t):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return self.proj(emb)\n",
    "\n",
    "# 修正後的離散余弦變換層\n",
    "class DCTLayer(nn.Module):\n",
    "    \"\"\"實現DCT變換層，用於頻域分析\"\"\"\n",
    "    def __init__(self, block_size=8):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 保存原始尺寸\n",
    "        b, c, h, w = x.shape\n",
    "        \n",
    "        # 使用可調整的插值確保輸出與輸入尺寸相同\n",
    "        # 先進行DCT變換\n",
    "        x_dct = self._apply_dct(x)\n",
    "        \n",
    "        # 確保輸出尺寸與輸入相同\n",
    "        if x_dct.shape[2:] != x.shape[2:]:\n",
    "            x_dct = F.interpolate(x_dct, size=(h, w), mode='bilinear', align_corners=False)\n",
    "            \n",
    "        return x_dct\n",
    "    \n",
    "    def _apply_dct(self, x):\n",
    "        \"\"\"實際執行DCT變換的輔助函數\"\"\"\n",
    "        b, c, h, w = x.shape\n",
    "        \n",
    "        # 補充填充以確保尺寸是block_size的倍數\n",
    "        h_pad = (self.block_size - h % self.block_size) % self.block_size\n",
    "        w_pad = (self.block_size - w % self.block_size) % self.block_size\n",
    "        \n",
    "        x_padded = F.pad(x, (0, w_pad, 0, h_pad))\n",
    "        \n",
    "        # 獲取填充後的尺寸\n",
    "        _, _, h_padded, w_padded = x_padded.shape\n",
    "        \n",
    "        # 計算块的數量\n",
    "        h_blocks = h_padded // self.block_size\n",
    "        w_blocks = w_padded // self.block_size\n",
    "        \n",
    "        # 分塊處理\n",
    "        x_blocks = x_padded.unfold(2, self.block_size, self.block_size).unfold(3, self.block_size, self.block_size)\n",
    "        \n",
    "        # 獲取展開後的尺寸\n",
    "        b_unf, c_unf, h_unf, w_unf, bs_h, bs_w = x_blocks.shape\n",
    "        \n",
    "        # 重構為便於進行DCT的形狀\n",
    "        x_blocks_flat = x_blocks.reshape(-1, self.block_size, self.block_size)\n",
    "        \n",
    "        # 獲取DCT矩陣\n",
    "        dct_matrix = self._get_dct_matrix(self.block_size).to(x.device)\n",
    "        \n",
    "        # 應用DCT變換: D * X * D^T\n",
    "        x_dct_flat = torch.matmul(dct_matrix, x_blocks_flat)\n",
    "        x_dct_flat = torch.matmul(x_dct_flat, dct_matrix.transpose(0, 1))\n",
    "        \n",
    "        # 恢復展開形狀\n",
    "        x_dct_blocks = x_dct_flat.reshape(b_unf, c_unf, h_unf, w_unf, bs_h, bs_w)\n",
    "        \n",
    "        # 重新排列為可以恢復原始形狀的排列\n",
    "        x_dct_perm = x_dct_blocks.permute(0, 1, 2, 4, 3, 5)\n",
    "        \n",
    "        # 重構為填充後的原始形狀\n",
    "        x_dct = x_dct_perm.reshape(b, c, h_padded, w_padded)\n",
    "        \n",
    "        # 去除填充部分\n",
    "        if h_pad > 0 or w_pad > 0:\n",
    "            x_dct = x_dct[:, :, :h, :w]\n",
    "        \n",
    "        return x_dct\n",
    "    \n",
    "    def _get_dct_matrix(self, size):\n",
    "        \"\"\"生成離散餘弦變換矩陣\"\"\"\n",
    "        dct_matrix = torch.zeros(size, size)\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                if i == 0:\n",
    "                    dct_matrix[i, j] = 1.0 / torch.sqrt(torch.tensor(size, dtype=torch.float32))\n",
    "                else:\n",
    "                    dct_matrix[i, j] = torch.sqrt(torch.tensor(2.0 / size)) * torch.cos(torch.tensor(torch.pi * (2 * j + 1) * i / (2 * size)))\n",
    "        return dct_matrix\n",
    "\n",
    "# 高頻補償模塊\n",
    "class HFCM(nn.Module):\n",
    "    \"\"\"高頻補償模塊，從FDG-Diff論文改編\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.dct = DCTLayer(block_size=8)\n",
    "        self.high_freq_attn = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.conv_out = nn.Conv2d(channels, channels, 1)\n",
    "        \n",
    "    def forward(self, x, compression_level):\n",
    "        # 提取DCT頻域表示\n",
    "        x_dct = self.dct(x)\n",
    "        \n",
    "        # 確保x_dct與x有相同的空間尺寸\n",
    "        if x_dct.shape[2:] != x.shape[2:]:\n",
    "            x_dct = F.interpolate(x_dct, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # 高頻注意力掩碼生成\n",
    "        attn_mask = self.high_freq_attn(x)\n",
    "        \n",
    "        # 確保compression_level是標量或可廣播的形狀\n",
    "        if isinstance(compression_level, torch.Tensor) and compression_level.dim() > 0:\n",
    "            compression_level = compression_level.view(-1, 1, 1, 1)\n",
    "        \n",
    "        # 根據壓縮級別調整高頻增強程度\n",
    "        # 壓縮級別越高(質量越低)，增強程度越大\n",
    "        freq_scale = 1.0 - compression_level\n",
    "        \n",
    "        # 應用高頻增強\n",
    "        enhanced = x + attn_mask * x_dct * freq_scale\n",
    "        return self.conv_out(enhanced)\n",
    "\n",
    "# 頻域引導模塊\n",
    "class FrequencyAwareBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.dct_layer = DCTLayer(block_size=8)\n",
    "        self.freq_conv = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.freq_attn = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // 4, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels // 4, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, compression_level):\n",
    "        # 提取頻域特徵\n",
    "        x_dct = self.dct_layer(x)\n",
    "        \n",
    "        # 確保x_dct與x有相同的空間尺寸\n",
    "        if x_dct.shape[2:] != x.shape[2:]:\n",
    "            x_dct = F.interpolate(x_dct, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "            \n",
    "        x_freq = self.freq_conv(x_dct)\n",
    "        \n",
    "        # 確保x_freq與x有相同的空間尺寸\n",
    "        if x_freq.shape[2:] != x.shape[2:]:\n",
    "            x_freq = F.interpolate(x_freq, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # 生成頻域注意力\n",
    "        attn = self.freq_attn(x_freq)\n",
    "        \n",
    "        # 確保compression_level是標量或可廣播的形狀\n",
    "        if isinstance(compression_level, torch.Tensor) and compression_level.dim() > 0:\n",
    "            compression_level = compression_level.view(-1, 1, 1, 1)\n",
    "        \n",
    "        # 根據壓縮級別調整頻域注意力\n",
    "        attn = attn * (1.0 - compression_level) + 0.5\n",
    "        \n",
    "        # 確保attn可以與x_freq適當廣播\n",
    "        if attn.shape[2:] != x_freq.shape[2:]:\n",
    "            attn = F.interpolate(attn, size=x_freq.shape[2:], mode='nearest')\n",
    "        \n",
    "        # 應用頻域注意力\n",
    "        return x + x_freq * attn\n",
    "\n",
    "# 改進的殘差注意力模塊\n",
    "class ResAttnBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c, time_dim, dropout=0.1, use_freq_guide=False):\n",
    "        super().__init__()\n",
    "        # 確保組數能被通道數整除\n",
    "        num_groups = min(8, in_c)\n",
    "        while in_c % num_groups != 0 and num_groups > 1:\n",
    "            num_groups -= 1\n",
    "            \n",
    "        self.norm1 = nn.GroupNorm(num_groups, in_c)\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, 3, padding=1)\n",
    "        self.time_proj = nn.Linear(time_dim, out_c)\n",
    "        \n",
    "        # 調整 out_c 的組數\n",
    "        num_groups_out = min(8, out_c)\n",
    "        while out_c % num_groups_out != 0 and num_groups_out > 1:\n",
    "            num_groups_out -= 1\n",
    "            \n",
    "        self.norm2 = nn.GroupNorm(num_groups_out, out_c)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, 3, padding=1)\n",
    "        self.attn = nn.MultiheadAttention(out_c, 4, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.shortcut = nn.Conv2d(in_c, out_c, 1) if in_c != out_c else nn.Identity()\n",
    "        \n",
    "        # 頻域引導(僅在某些塊使用)\n",
    "        self.use_freq_guide = use_freq_guide\n",
    "        if use_freq_guide:\n",
    "            self.freq_guide = FrequencyAwareBlock(out_c)\n",
    "            self.hfcm = HFCM(out_c)\n",
    "        \n",
    "    def forward(self, x, t_emb, compression_level=None):\n",
    "        h = self.norm1(x)\n",
    "        h = self.conv1(h)\n",
    "        \n",
    "        # 加入時間編碼\n",
    "        t = self.time_proj(t_emb)[..., None, None]\n",
    "        h = h + t\n",
    "        \n",
    "        h = self.norm2(h)\n",
    "        h = self.conv2(F.silu(h))\n",
    "        \n",
    "        # 應用自注意力機制\n",
    "        b, c, hh, ww = h.shape\n",
    "        h_attn = h.view(b, c, -1).permute(0, 2, 1)\n",
    "        h_attn, _ = self.attn(h_attn, h_attn, h_attn)\n",
    "        h_attn = h_attn.permute(0, 2, 1).view(b, c, hh, ww)\n",
    "        \n",
    "        # 應用頻域引導(如果啟用)\n",
    "        if self.use_freq_guide and compression_level is not None:\n",
    "            h_attn = self.freq_guide(h_attn, compression_level)\n",
    "            h_attn = self.hfcm(h_attn, compression_level)\n",
    "        \n",
    "        return self.shortcut(x) + self.dropout(h_attn)\n",
    "\n",
    "# SVD結構保留輔助函數\n",
    "def svd_structure_preservation(x, k_ratio=0.5):\n",
    "    \"\"\"使用SVD提取主要結構特徵\"\"\"\n",
    "    b, c, h, w = x.shape\n",
    "    x_flat = x.view(b, c, -1)\n",
    "    \n",
    "    # 對每個通道進行SVD分解\n",
    "    structure_tensors = []\n",
    "    for i in range(b):\n",
    "        channels_structure = []\n",
    "        for j in range(c):\n",
    "            # SVD分解\n",
    "            U, S, Vh = torch.linalg.svd(x_flat[i, j].view(h, w), full_matrices=False)\n",
    "            \n",
    "            # 確定保留的奇異值數量\n",
    "            k = max(1, int(min(h, w) * k_ratio))\n",
    "            \n",
    "            # 重建降秩表示\n",
    "            S_k = torch.zeros_like(S)\n",
    "            S_k[:k] = S[:k]\n",
    "            structure = torch.matmul(U, torch.matmul(torch.diag(S_k), Vh))\n",
    "            channels_structure.append(structure.unsqueeze(0))\n",
    "        \n",
    "        # 所有通道結合\n",
    "        structure_tensors.append(torch.cat(channels_structure, dim=0).unsqueeze(0))\n",
    "    \n",
    "    return torch.cat(structure_tensors, dim=0)\n",
    "\n",
    "# 相位一致性函數\n",
    "def phase_consistency(x, ref, alpha=0.7):\n",
    "    \"\"\"保持參考圖像的相位信息，同時使用新的幅度\"\"\"\n",
    "    # FFT變換\n",
    "    x_fft = torch.fft.fft2(x)\n",
    "    ref_fft = torch.fft.fft2(ref)\n",
    "    \n",
    "    # 提取幅度和相位\n",
    "    x_mag = torch.abs(x_fft)\n",
    "    ref_phase = torch.angle(ref_fft)\n",
    "    \n",
    "    # 創建新的複數張量，使用x的幅度和參考的相位\n",
    "    real = x_mag * torch.cos(ref_phase)\n",
    "    imag = x_mag * torch.sin(ref_phase)\n",
    "    adjusted_fft = torch.complex(real, imag)\n",
    "    \n",
    "    # 反變換\n",
    "    adjusted_img = torch.fft.ifft2(adjusted_fft).real\n",
    "    \n",
    "    # 混合原始圖像和相位調整圖像\n",
    "    return alpha * x + (1 - alpha) * adjusted_img\n",
    "\n",
    "# 改進的UNet架構\n",
    "class JPEGDiffusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        time_dim = 256\n",
    "        self.time_embed = TimeEmbedding(time_dim)\n",
    "        \n",
    "        # 下采样路径 - 增強中層使用頻域引導\n",
    "        self.down1 = ResAttnBlock(3, 64, time_dim)\n",
    "        self.down2 = ResAttnBlock(64, 128, time_dim, use_freq_guide=True)\n",
    "        self.down3 = ResAttnBlock(128, 256, time_dim, use_freq_guide=True)\n",
    "        self.down4 = ResAttnBlock(256, 512, time_dim)\n",
    "        self.down5 = ResAttnBlock(512, 512, time_dim)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # 瓶颈层 - 使用頻域引導\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            ResAttnBlock(512, 1024, time_dim, use_freq_guide=True),\n",
    "            ResAttnBlock(1024, 1024, time_dim),\n",
    "            ResAttnBlock(1024, 512, time_dim, use_freq_guide=True)\n",
    "        )\n",
    "        \n",
    "        # 上采样路径 - 增強中層使用頻域引導\n",
    "        self.up1 = ResAttnBlock(1024, 512, time_dim)\n",
    "        self.up2 = ResAttnBlock(512 + 512, 256, time_dim, use_freq_guide=True)\n",
    "        self.up3 = ResAttnBlock(256 + 256, 128, time_dim, use_freq_guide=True)\n",
    "        self.up4 = ResAttnBlock(128 + 128, 64, time_dim)\n",
    "        self.up5 = ResAttnBlock(64 + 64, 64, time_dim)\n",
    "        \n",
    "        # 輸出層 - 使用1x1卷積保留空間色彩相關性\n",
    "        self.out_conv = nn.Conv2d(64, 3, 1)\n",
    "        \n",
    "    def forward(self, x, t, compression_level=None):\n",
    "        t_emb = self.time_embed(t)\n",
    "        \n",
    "        # 如果未提供壓縮級別，從時間步估計\n",
    "        if compression_level is None:\n",
    "            compression_level = t.clone().detach()\n",
    "        \n",
    "        # 下采样\n",
    "        d1 = self.down1(x, t_emb)  # 32x32\n",
    "        d2 = self.down2(self.pool(d1), t_emb, compression_level)  # 16x16\n",
    "        d3 = self.down3(self.pool(d2), t_emb, compression_level)  # 8x8\n",
    "        d4 = self.down4(self.pool(d3), t_emb)  # 4x4\n",
    "        d5 = self.down5(self.pool(d4), t_emb)  # 2x2\n",
    "        \n",
    "        # 瓶颈层\n",
    "        b = self.bottleneck[0](self.pool(d5), t_emb, compression_level)\n",
    "        b = self.bottleneck[1](b, t_emb)\n",
    "        b = self.bottleneck[2](b, t_emb, compression_level)\n",
    "        \n",
    "        # 上采样 - 使用雙線性上採樣避免棋盤格效應\n",
    "        u1 = self.up1(torch.cat([F.interpolate(b, scale_factor=2, mode='bilinear', align_corners=False), d5], dim=1), t_emb)\n",
    "        u2 = self.up2(torch.cat([F.interpolate(u1, scale_factor=2, mode='bilinear', align_corners=False), d4], dim=1), t_emb, compression_level)\n",
    "        u3 = self.up3(torch.cat([F.interpolate(u2, scale_factor=2, mode='bilinear', align_corners=False), d3], dim=1), t_emb, compression_level)\n",
    "        u4 = self.up4(torch.cat([F.interpolate(u3, scale_factor=2, mode='bilinear', align_corners=False), d2], dim=1), t_emb)\n",
    "        u5 = self.up5(torch.cat([F.interpolate(u4, scale_factor=2, mode='bilinear', align_corners=False), d1], dim=1), t_emb)\n",
    "        \n",
    "        return self.out_conv(u5)\n",
    "\n",
    "# 初始化模型\n",
    "model = JPEGDiffusionModel().to(device)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# 設定優化器 - 使用AdamW配合學習率調整\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5, betas=(0.9, 0.99))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=100, T_mult=2)\n",
    "# 組合Huber損失和色彩保存損失\n",
    "huber_loss_fn = nn.HuberLoss(reduction='mean', delta=1.0)\n",
    "\n",
    "# 設定JPEG擴散參數\n",
    "num_timesteps = 100\n",
    "# 根據DriftRec論文，使用余弦調度的噪聲\n",
    "betas = torch.linspace(1e-4, 0.02, num_timesteps).to(device)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "# 高斯混合模型採樣器\n",
    "class GaussianMixtureSampler:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def sample(self, x_t, steps=100, use_phase_consistency=True, use_svd_guide=True, guidance_scale=1.0):\n",
    "        \"\"\"使用高斯混合模型進行採樣，結合相位一致性和SVD引導\"\"\"\n",
    "        self.model.eval()\n",
    "        # 保存原始壓縮圖像用於相位一致性\n",
    "        original_compressed = x_t.clone()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # 從給定的噪聲圖像開始\n",
    "            for i in tqdm(range(steps-1, -1, -1), desc=\"Sampling\"):\n",
    "                t = torch.full((x_t.size(0),), i, device=device).float() / num_timesteps\n",
    "                compression_level = t.clone()  # 壓縮級別與時間步對應\n",
    "                \n",
    "                # 獲取噪聲預測\n",
    "                pred_noise = model(x_t, t, compression_level)\n",
    "                \n",
    "                # 如果啟用SVD引導\n",
    "                if use_svd_guide and i > steps // 2:\n",
    "                    # 在前半部分採樣過程中使用SVD引導(粗糙結構)\n",
    "                    k_ratio = i / steps  # 隨時間降低保留比例\n",
    "                    structure_prior = svd_structure_preservation(x_t, k_ratio)\n",
    "                    # 混合SVD結構和預測\n",
    "                    guide_strength = k_ratio * 0.3  # SVD影響隨時間降低\n",
    "                    pred_noise = (1 - guide_strength) * pred_noise + guide_strength * (original_compressed - structure_prior)\n",
    "                \n",
    "                if i > 0:\n",
    "                    # 預測的x0\n",
    "                    x0_pred = x_t + pred_noise\n",
    "                    \n",
    "                    # 計算多個高斯分量的均值\n",
    "                    # 第一個均值 - 更保守的估計\n",
    "                    mu1 = x0_pred * 0.9 + x_t * 0.1\n",
    "                    # 第二個均值 - 更積極的估計\n",
    "                    mu2 = x0_pred * 1.1 - x_t * 0.1\n",
    "                    \n",
    "                    # 根據當前時間步選擇使用哪個分量\n",
    "                    # 時間步較大時傾向使用保守估計，較小時傾向使用積極估計\n",
    "                    p_conservative = max(0.2, min(0.8, i / steps))\n",
    "                    use_first = torch.rand(1).item() < p_conservative\n",
    "                    next_mean = mu1 if use_first else mu2\n",
    "                    \n",
    "                    # 逐步減少噪聲尺度\n",
    "                    noise_scale = 0.1 * i / steps * guidance_scale\n",
    "                    x_next = next_mean + noise_scale * torch.randn_like(x_t)\n",
    "                    \n",
    "                    # 相位一致性(每5步應用一次)\n",
    "                    if use_phase_consistency and i % 5 == 0:\n",
    "                        alpha = 0.6 + 0.3 * (1 - i / steps)  # 隨時間增加原始圖像權重\n",
    "                        x_next = phase_consistency(x_next, original_compressed, alpha)\n",
    "                    \n",
    "                    x_t = x_next\n",
    "                else:\n",
    "                    # 最後一步直接使用預測的原始圖像\n",
    "                    x_t = x_t + pred_noise\n",
    "        \n",
    "        return x_t\n",
    "\n",
    "# 改進的前向過程(基於DriftRec)\n",
    "def forward_process(x0, t, quality_factors=None):\n",
    "    \"\"\"使用基於DriftRec的前向SDE進行JPEG壓縮\"\"\"\n",
    "    b = x0.size(0)\n",
    "    \n",
    "    # 如果未提供quality_factors，從時間步估計\n",
    "    if quality_factors is None:\n",
    "        # 將時間步映射到壓縮質量因子(1-100)，t越大，質量越低\n",
    "        quality_factors = torch.clamp(100 * (1 - t.float() / num_timesteps), 1, 100).cpu().numpy()\n",
    "    \n",
    "    # JPEG壓縮\n",
    "    xt = torch.stack([jpeg_compress(x0[i:i+1], int(q)) for i, q in enumerate(quality_factors)]).squeeze()\n",
    "    \n",
    "    # 添加少量高斯噪聲以增加穩定性(DriftRec思想)\n",
    "    noise_scale = 0.01 * t.float() / num_timesteps  # 隨時間線性增加\n",
    "    xt = xt + noise_scale.view(-1, 1, 1, 1) * torch.randn_like(xt)\n",
    "    \n",
    "    return xt\n",
    "\n",
    "# 改進的訓練函數(一致性擴散)\n",
    "def train_epoch(model, loader, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    color_loss_total = 0\n",
    "    \n",
    "    for x0, _ in tqdm(loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "        x0 = x0.to(device)\n",
    "        b = x0.size(0)\n",
    "        \n",
    "        # 使用更結構化的質量分布\n",
    "        # 確保模型見到各種質量水平的樣本\n",
    "        if random.random() < 0.3 + min(0.4, epoch * 0.01):  # 隨著訓練進行增加高質量樣本比例\n",
    "            # 高質量壓縮\n",
    "            quality_range = (70, 100)\n",
    "        elif random.random() < 0.5:\n",
    "            # 中等質量壓縮\n",
    "            quality_range = (40, 70)\n",
    "        else:\n",
    "            # 低質量壓縮\n",
    "            quality_range = (5, 40)\n",
    "            \n",
    "        # 隨機選擇時間步\n",
    "        t = torch.randint(1, num_timesteps, (b,), device=device).long()\n",
    "        \n",
    "        # 將時間步映射到質量因子，加入範圍控制\n",
    "        min_q, max_q = quality_range\n",
    "        quality = torch.clamp(min_q + (max_q - min_q) * (1 - t.float() / num_timesteps), 1, 100).cpu().numpy()\n",
    "        \n",
    "        # 使用改進的前向過程\n",
    "        xt = forward_process(x0, t, quality)\n",
    "        \n",
    "        # 計算噪聲 (x0 - xt)\n",
    "        noise = x0 - xt\n",
    "        \n",
    "        # 模型預測噪聲\n",
    "        compression_level = t.float() / num_timesteps  # 壓縮級別\n",
    "        pred_noise = model(xt, t.float()/num_timesteps, compression_level)\n",
    "        \n",
    "        # 標準重建損失\n",
    "        huber_loss = huber_loss_fn(pred_noise, noise)\n",
    "        \n",
    "        # 色彩保存損失\n",
    "        col_loss = color_preservation_loss(xt + pred_noise, x0)\n",
    "        \n",
    "        # 結合損失，逐漸增加色彩損失的權重\n",
    "        color_weight = min(1.0, 0.2 + epoch * 0.02)\n",
    "        loss = huber_loss + color_weight * col_loss\n",
    "        \n",
    "        # 反向傳播更新\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # 梯度裁剪防止爆炸\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += huber_loss.item()\n",
    "        color_loss_total += col_loss.item()\n",
    "    \n",
    "    # 更新學習率\n",
    "    scheduler.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    avg_color_loss = color_loss_total / len(loader)\n",
    "    print(f\"Epoch {epoch+1} - Avg Loss: {avg_loss:.5f}, Color Loss: {avg_color_loss:.5f}, LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    return avg_loss, avg_color_loss\n",
    "\n",
    "# 驗證函數\n",
    "def validate(model, loader, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    color_loss_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x0, _ in tqdm(loader, desc=f\"Validating Epoch {epoch+1}\"):\n",
    "            x0 = x0.to(device)\n",
    "            b = x0.size(0)\n",
    "            \n",
    "            # 固定質量用於評估\n",
    "            quality = torch.randint(10, 90, (b,)).cpu().numpy()\n",
    "            t = torch.full((b,), num_timesteps//2, device=device).long()\n",
    "            \n",
    "            # 使用改進的前向過程\n",
    "            xt = forward_process(x0, t, quality)\n",
    "            \n",
    "            # 計算噪聲\n",
    "            noise = x0 - xt\n",
    "            \n",
    "            # 模型預測噪聲\n",
    "            compression_level = t.float() / num_timesteps\n",
    "            pred_noise = model(xt, t.float()/num_timesteps, compression_level)\n",
    "            \n",
    "            # 計算損失\n",
    "            huber_loss = huber_loss_fn(pred_noise, noise)\n",
    "            col_loss = color_preservation_loss(xt + pred_noise, x0)\n",
    "            \n",
    "            total_loss += huber_loss.item()\n",
    "            color_loss_total += col_loss.item()\n",
    "            \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    avg_color_loss = color_loss_total / len(loader)\n",
    "    print(f\"Validation - Avg Loss: {avg_loss:.5f}, Color Loss: {avg_color_loss:.5f}\")\n",
    "    \n",
    "    # 保存一些復原效果樣本用於視覺檢查\n",
    "    if epoch % 5 == 0:\n",
    "        visualize_restoration(model, epoch)\n",
    "    \n",
    "    return avg_loss, avg_color_loss\n",
    "\n",
    "# 視覺化復原效果\n",
    "def visualize_restoration(model, epoch):\n",
    "    model.eval()\n",
    "    sampler = GaussianMixtureSampler(model)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x0, _ = next(iter(test_dataloader))\n",
    "        x0 = x0.to(device)\n",
    "        \n",
    "        # 選擇不同的質量級別進行可視化\n",
    "        qualities = [10, 30, 50, 70]\n",
    "        plt.figure(figsize=(len(qualities)*3+3, 6))\n",
    "        \n",
    "        # 顯示原始圖像\n",
    "        plt.subplot(2, len(qualities)+1, 1)\n",
    "        plt.imshow(x0[0].cpu().permute(1,2,0)*0.5+0.5)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 為每個質量級別顯示JPEG和復原效果\n",
    "        for i, q in enumerate(qualities):\n",
    "            # JPEG壓縮\n",
    "            xt = jpeg_compress(x0, q)\n",
    "            \n",
    "            # 設定初始時間步基於質量\n",
    "            init_t = int((100 - q) / 100 * num_timesteps)\n",
    "            \n",
    "            # 使用GMM採樣器進行復原\n",
    "            restored = sampler.sample(xt, steps=init_t+1)\n",
    "            \n",
    "            # 顯示JPEG壓縮結果\n",
    "            plt.subplot(2, len(qualities)+1, i+2)\n",
    "            plt.imshow(xt[0].cpu().permute(1,2,0)*0.5+0.5)\n",
    "            plt.title(f\"JPEG Q{q}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # 顯示復原結果\n",
    "            plt.subplot(2, len(qualities)+1, len(qualities)+i+2)\n",
    "            plt.imshow(restored[0].cpu().permute(1,2,0)*0.5+0.5)\n",
    "            plt.title(f\"Restored Q{q}\")\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'viz_epoch_{epoch}.png')\n",
    "        plt.close()\n",
    "\n",
    "# 測試復原效果，使用高斯混合模型採樣器\n",
    "def test_restoration(model, quality_levels=[10, 30, 50, 70]):\n",
    "    # 初始化採樣器\n",
    "    sampler = GaussianMixtureSampler(model)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 隨機選取10個樣本\n",
    "        results = {q: {'psnr': [], 'ssim': []} for q in quality_levels}\n",
    "        \n",
    "        for idx in range(10):\n",
    "            x0, _ = next(iter(test_dataloader))\n",
    "            x0 = x0.to(device)\n",
    "            \n",
    "            plt.figure(figsize=(len(quality_levels)*3+3, 6))\n",
    "            \n",
    "            # 顯示原始圖像\n",
    "            plt.subplot(2, len(quality_levels)+1, 1)\n",
    "            plt.imshow(x0[0].cpu().permute(1,2,0)*0.5+0.5)\n",
    "            plt.title(\"Original\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # 為每個質量級別顯示JPEG和復原效果\n",
    "            for i, q in enumerate(quality_levels):\n",
    "                # JPEG壓縮\n",
    "                xt = jpeg_compress(x0, q)\n",
    "                \n",
    "                # 設定初始時間步基於質量\n",
    "                init_t = int((100 - q) / 100 * num_timesteps)\n",
    "                \n",
    "                # 使用GMM採樣器進行復原\n",
    "                restored = sampler.sample(xt, steps=init_t+1, guidance_scale=0.8)\n",
    "                \n",
    "                # 計算PSNR\n",
    "                x0_01 = (x0 * 0.5 + 0.5).clamp(0, 1)\n",
    "                xt_01 = (xt * 0.5 + 0.5).clamp(0, 1)\n",
    "                restored_01 = (restored * 0.5 + 0.5).clamp(0, 1)\n",
    "                \n",
    "                # 計算PSNR\n",
    "                xt_psnr = -10 * torch.log10(F.mse_loss(xt_01, x0_01)).item()\n",
    "                restored_psnr = -10 * torch.log10(F.mse_loss(restored_01, x0_01)).item()\n",
    "                \n",
    "                # 計算SSIM\n",
    "                xt_ssim = ssim(xt_01, x0_01, data_range=1.0).item()\n",
    "                restored_ssim = ssim(restored_01, x0_01, data_range=1.0).item()\n",
    "                \n",
    "                # 儲存結果\n",
    "                results[q]['psnr'].append(restored_psnr - xt_psnr)  # PSNR增益\n",
    "                results[q]['ssim'].append(restored_ssim - xt_ssim)  # SSIM增益\n",
    "                \n",
    "                # 顯示JPEG壓縮結果\n",
    "                plt.subplot(2, len(quality_levels)+1, i+2)\n",
    "                plt.imshow(xt[0].cpu().permute(1,2,0)*0.5+0.5)\n",
    "                plt.title(f\"JPEG Q{q}\\nPSNR: {xt_psnr:.2f}dB\\nSSIM: {xt_ssim:.4f}\")\n",
    "                plt.axis('off')\n",
    "                \n",
    "                # 顯示復原結果\n",
    "                plt.subplot(2, len(quality_levels)+1, len(quality_levels)+i+2)\n",
    "                plt.imshow(restored[0].cpu().permute(1,2,0)*0.5+0.5)\n",
    "                plt.title(f\"Restored\\nPSNR: {restored_psnr:.2f}dB\\nSSIM: {restored_ssim:.4f}\")\n",
    "                plt.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'./0407_test/test_sample_{idx+1}.png')\n",
    "            plt.close()\n",
    "        \n",
    "        # 顯示平均結果\n",
    "        print(\"\\nAverage Improvement:\")\n",
    "        for q in quality_levels:\n",
    "            avg_psnr_gain = sum(results[q]['psnr']) / len(results[q]['psnr'])\n",
    "            avg_ssim_gain = sum(results[q]['ssim']) / len(results[q]['ssim'])\n",
    "            print(f\"Quality {q}: PSNR Gain = {avg_psnr_gain:.2f}dB, SSIM Gain = {avg_ssim_gain:.4f}\")\n",
    "\n",
    "# 訓練循環\n",
    "def train_model(epochs=100, patience=10):\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    color_losses = []\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # 訓練一個周期\n",
    "        train_loss, train_color_loss = train_epoch(model, train_dataloader, epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # 驗證一個周期\n",
    "        val_loss, val_color_loss = validate(model, valid_dataloader, epoch)\n",
    "        val_losses.append(val_loss)\n",
    "        color_losses.append(val_color_loss)\n",
    "        \n",
    "        # 檢查是否需要保存最佳模型\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'color_loss': val_color_loss\n",
    "            }, f\"best_jpeg_diffusion.pth\")\n",
    "            print(f\"New best model saved with val loss {val_loss:.5f} and color loss {val_color_loss:.5f}\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping after {epoch+1} epochs!\")\n",
    "                break\n",
    "        \n",
    "        # 繪製訓練曲線\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(val_losses, label='Val Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(color_losses, label='Color Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Color Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_curves.png')\n",
    "        plt.close()\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "    \n",
    "    # 載入最佳模型\n",
    "    checkpoint = torch.load(\"best_jpeg_diffusion.pth\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded best model from epoch {checkpoint['epoch']+1} with val loss {checkpoint['val_loss']:.5f}\")\n",
    "    \n",
    "    # 測試復原效果\n",
    "    test_restoration(model)\n",
    "\n",
    "# 執行訓練\n",
    "if __name__ == \"__main__\":\n",
    "    # 開始訓練W\n",
    "    train_model(epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Loaded model from epoch 46\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 1 質量 10:\n",
      "  PSNR - 壓縮: 24.09dB, 修復: 20.24dB\n",
      "  SSIM - 壓縮: 0.8448, 修復: 0.7933\n",
      "  LPIPS - 壓縮: 0.0205, 修復: 0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 93.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 1 質量 30:\n",
      "  PSNR - 壓縮: 27.97dB, 修復: 24.19dB\n",
      "  SSIM - 壓縮: 0.9330, 修復: 0.9179\n",
      "  LPIPS - 壓縮: 0.0110, 修復: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 1 質量 50:\n",
      "  PSNR - 壓縮: 30.33dB, 修復: 25.39dB\n",
      "  SSIM - 壓縮: 0.9556, 修復: 0.9231\n",
      "  LPIPS - 壓縮: 0.0018, 修復: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 1 質量 70:\n",
      "  PSNR - 壓縮: 32.62dB, 修復: 29.25dB\n",
      "  SSIM - 壓縮: 0.9710, 修復: 0.9420\n",
      "  LPIPS - 壓縮: 0.0009, 修復: 0.0029\n",
      "處理圖像 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 95.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 2 質量 10:\n",
      "  PSNR - 壓縮: 19.96dB, 修復: 18.06dB\n",
      "  SSIM - 壓縮: 0.7189, 修復: 0.6536\n",
      "  LPIPS - 壓縮: 0.0312, 修復: 0.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 95.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 2 質量 30:\n",
      "  PSNR - 壓縮: 21.97dB, 修復: 19.75dB\n",
      "  SSIM - 壓縮: 0.8039, 修復: 0.7559\n",
      "  LPIPS - 壓縮: 0.0119, 修復: 0.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 95.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 2 質量 50:\n",
      "  PSNR - 壓縮: 25.30dB, 修復: 21.17dB\n",
      "  SSIM - 壓縮: 0.8962, 修復: 0.7901\n",
      "  LPIPS - 壓縮: 0.0029, 修復: 0.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 95.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 2 質量 70:\n",
      "  PSNR - 壓縮: 27.23dB, 修復: 23.43dB\n",
      "  SSIM - 壓縮: 0.9306, 修復: 0.8649\n",
      "  LPIPS - 壓縮: 0.0013, 修復: 0.0147\n",
      "處理圖像 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 95.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 3 質量 10:\n",
      "  PSNR - 壓縮: 23.96dB, 修復: 19.33dB\n",
      "  SSIM - 壓縮: 0.7913, 修復: 0.7252\n",
      "  LPIPS - 壓縮: 0.0656, 修復: 0.1242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 95.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 3 質量 30:\n",
      "  PSNR - 壓縮: 27.54dB, 修復: 22.05dB\n",
      "  SSIM - 壓縮: 0.9001, 修復: 0.8379\n",
      "  LPIPS - 壓縮: 0.0127, 修復: 0.0470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 95.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 3 質量 50:\n",
      "  PSNR - 壓縮: 29.97dB, 修復: 24.13dB\n",
      "  SSIM - 壓縮: 0.9364, 修復: 0.8540\n",
      "  LPIPS - 壓縮: 0.0035, 修復: 0.0389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 95.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 3 質量 70:\n",
      "  PSNR - 壓縮: 32.01dB, 修復: 26.46dB\n",
      "  SSIM - 壓縮: 0.9611, 修復: 0.9071\n",
      "  LPIPS - 壓縮: 0.0017, 修復: 0.0226\n",
      "處理圖像 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 95.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 4 質量 10:\n",
      "  PSNR - 壓縮: 23.83dB, 修復: 21.10dB\n",
      "  SSIM - 壓縮: 0.8628, 修復: 0.8060\n",
      "  LPIPS - 壓縮: 0.0311, 修復: 0.0717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 95.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 4 質量 30:\n",
      "  PSNR - 壓縮: 27.45dB, 修復: 24.47dB\n",
      "  SSIM - 壓縮: 0.9280, 修復: 0.8975\n",
      "  LPIPS - 壓縮: 0.0193, 修復: 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 95.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 4 質量 50:\n",
      "  PSNR - 壓縮: 29.91dB, 修復: 25.42dB\n",
      "  SSIM - 壓縮: 0.9545, 修復: 0.9188\n",
      "  LPIPS - 壓縮: 0.0032, 修復: 0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 95.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 4 質量 70:\n",
      "  PSNR - 壓縮: 32.12dB, 修復: 28.21dB\n",
      "  SSIM - 壓縮: 0.9705, 修復: 0.9500\n",
      "  LPIPS - 壓縮: 0.0012, 修復: 0.0089\n",
      "處理圖像 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 95.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 5 質量 10:\n",
      "  PSNR - 壓縮: 20.99dB, 修復: 19.45dB\n",
      "  SSIM - 壓縮: 0.7819, 修復: 0.7708\n",
      "  LPIPS - 壓縮: 0.0623, 修復: 0.0671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 5 質量 30:\n",
      "  PSNR - 壓縮: 24.20dB, 修復: 22.55dB\n",
      "  SSIM - 壓縮: 0.8764, 修復: 0.8666\n",
      "  LPIPS - 壓縮: 0.0112, 修復: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 5 質量 50:\n",
      "  PSNR - 壓縮: 26.23dB, 修復: 23.78dB\n",
      "  SSIM - 壓縮: 0.9157, 修復: 0.8938\n",
      "  LPIPS - 壓縮: 0.0035, 修復: 0.0328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 5 質量 70:\n",
      "  PSNR - 壓縮: 28.30dB, 修復: 25.59dB\n",
      "  SSIM - 壓縮: 0.9463, 修復: 0.9303\n",
      "  LPIPS - 壓縮: 0.0024, 修復: 0.0089\n",
      "處理圖像 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 6 質量 10:\n",
      "  PSNR - 壓縮: 20.79dB, 修復: 19.84dB\n",
      "  SSIM - 壓縮: 0.7111, 修復: 0.6786\n",
      "  LPIPS - 壓縮: 0.0405, 修復: 0.0682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 95.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 6 質量 30:\n",
      "  PSNR - 壓縮: 23.96dB, 修復: 22.71dB\n",
      "  SSIM - 壓縮: 0.8415, 修復: 0.8292\n",
      "  LPIPS - 壓縮: 0.0115, 修復: 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 95.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 6 質量 50:\n",
      "  PSNR - 壓縮: 26.70dB, 修復: 23.75dB\n",
      "  SSIM - 壓縮: 0.9192, 修復: 0.8722\n",
      "  LPIPS - 壓縮: 0.0054, 修復: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 6 質量 70:\n",
      "  PSNR - 壓縮: 28.80dB, 修復: 24.36dB\n",
      "  SSIM - 壓縮: 0.9523, 修復: 0.9018\n",
      "  LPIPS - 壓縮: 0.0010, 修復: 0.0122\n",
      "處理圖像 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 95.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 7 質量 10:\n",
      "  PSNR - 壓縮: 24.51dB, 修復: 23.17dB\n",
      "  SSIM - 壓縮: 0.6991, 修復: 0.6912\n",
      "  LPIPS - 壓縮: 0.0644, 修復: 0.0728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 95.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 7 質量 30:\n",
      "  PSNR - 壓縮: 27.42dB, 修復: 23.83dB\n",
      "  SSIM - 壓縮: 0.8103, 修復: 0.8049\n",
      "  LPIPS - 壓縮: 0.0272, 修復: 0.0610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 95.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 7 質量 50:\n",
      "  PSNR - 壓縮: 29.51dB, 修復: 26.39dB\n",
      "  SSIM - 壓縮: 0.8811, 修復: 0.8418\n",
      "  LPIPS - 壓縮: 0.0070, 修復: 0.0405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 95.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 7 質量 70:\n",
      "  PSNR - 壓縮: 31.31dB, 修復: 27.45dB\n",
      "  SSIM - 壓縮: 0.9152, 修復: 0.8722\n",
      "  LPIPS - 壓縮: 0.0025, 修復: 0.0158\n",
      "處理圖像 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 95.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 8 質量 10:\n",
      "  PSNR - 壓縮: 23.44dB, 修復: 18.67dB\n",
      "  SSIM - 壓縮: 0.7481, 修復: 0.6461\n",
      "  LPIPS - 壓縮: 0.0385, 修復: 0.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 95.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 8 質量 30:\n",
      "  PSNR - 壓縮: 26.89dB, 修復: 22.37dB\n",
      "  SSIM - 壓縮: 0.8618, 修復: 0.7837\n",
      "  LPIPS - 壓縮: 0.0096, 修復: 0.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 8 質量 50:\n",
      "  PSNR - 壓縮: 29.30dB, 修復: 24.60dB\n",
      "  SSIM - 壓縮: 0.9050, 修復: 0.8405\n",
      "  LPIPS - 壓縮: 0.0028, 修復: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 93.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 8 質量 70:\n",
      "  PSNR - 壓縮: 31.33dB, 修復: 25.34dB\n",
      "  SSIM - 壓縮: 0.9395, 修復: 0.8584\n",
      "  LPIPS - 壓縮: 0.0011, 修復: 0.0123\n",
      "處理圖像 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 9 質量 10:\n",
      "  PSNR - 壓縮: 25.56dB, 修復: 21.67dB\n",
      "  SSIM - 壓縮: 0.7455, 修復: 0.6240\n",
      "  LPIPS - 壓縮: 0.0655, 修復: 0.0751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 9 質量 30:\n",
      "  PSNR - 壓縮: 28.41dB, 修復: 23.67dB\n",
      "  SSIM - 壓縮: 0.8549, 修復: 0.7792\n",
      "  LPIPS - 壓縮: 0.0314, 修復: 0.1286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 9 質量 50:\n",
      "  PSNR - 壓縮: 30.46dB, 修復: 25.08dB\n",
      "  SSIM - 壓縮: 0.8915, 修復: 0.7766\n",
      "  LPIPS - 壓縮: 0.0091, 修復: 0.0825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 9 質量 70:\n",
      "  PSNR - 壓縮: 32.10dB, 修復: 28.95dB\n",
      "  SSIM - 壓縮: 0.9164, 修復: 0.8731\n",
      "  LPIPS - 壓縮: 0.0027, 修復: 0.0111\n",
      "處理圖像 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 93.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 10 質量 10:\n",
      "  PSNR - 壓縮: 23.16dB, 修復: 22.17dB\n",
      "  SSIM - 壓縮: 0.8133, 修復: 0.8094\n",
      "  LPIPS - 壓縮: 0.0359, 修復: 0.0646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 10 質量 30:\n",
      "  PSNR - 壓縮: 26.74dB, 修復: 23.76dB\n",
      "  SSIM - 壓縮: 0.9070, 修復: 0.8803\n",
      "  LPIPS - 壓縮: 0.0131, 修復: 0.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 10 質量 50:\n",
      "  PSNR - 壓縮: 29.77dB, 修復: 26.73dB\n",
      "  SSIM - 壓縮: 0.9440, 修復: 0.9246\n",
      "  LPIPS - 壓縮: 0.0037, 修復: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 93.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 10 質量 70:\n",
      "  PSNR - 壓縮: 32.05dB, 修復: 27.31dB\n",
      "  SSIM - 壓縮: 0.9661, 修復: 0.9281\n",
      "  LPIPS - 壓縮: 0.0023, 修復: 0.0158\n",
      "處理圖像 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 11 質量 10:\n",
      "  PSNR - 壓縮: 20.99dB, 修復: 20.61dB\n",
      "  SSIM - 壓縮: 0.8618, 修復: 0.8585\n",
      "  LPIPS - 壓縮: 0.0453, 修復: 0.0743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 95.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 11 質量 30:\n",
      "  PSNR - 壓縮: 24.26dB, 修復: 22.78dB\n",
      "  SSIM - 壓縮: 0.9286, 修復: 0.9164\n",
      "  LPIPS - 壓縮: 0.0108, 修復: 0.0575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 11 質量 50:\n",
      "  PSNR - 壓縮: 26.86dB, 修復: 23.77dB\n",
      "  SSIM - 壓縮: 0.9508, 修復: 0.9401\n",
      "  LPIPS - 壓縮: 0.0030, 修復: 0.0151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 11 質量 70:\n",
      "  PSNR - 壓縮: 28.86dB, 修復: 25.42dB\n",
      "  SSIM - 壓縮: 0.9710, 修復: 0.9607\n",
      "  LPIPS - 壓縮: 0.0014, 修復: 0.0085\n",
      "處理圖像 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 12 質量 10:\n",
      "  PSNR - 壓縮: 29.17dB, 修復: 20.83dB\n",
      "  SSIM - 壓縮: 0.7970, 修復: 0.7780\n",
      "  LPIPS - 壓縮: 0.0262, 修復: 0.0522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 12 質量 30:\n",
      "  PSNR - 壓縮: 32.96dB, 修復: 23.76dB\n",
      "  SSIM - 壓縮: 0.9028, 修復: 0.8598\n",
      "  LPIPS - 壓縮: 0.0098, 修復: 0.0279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 93.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 12 質量 50:\n",
      "  PSNR - 壓縮: 35.84dB, 修復: 26.57dB\n",
      "  SSIM - 壓縮: 0.9327, 修復: 0.9037\n",
      "  LPIPS - 壓縮: 0.0031, 修復: 0.0243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 93.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 12 質量 70:\n",
      "  PSNR - 壓縮: 37.60dB, 修復: 28.57dB\n",
      "  SSIM - 壓縮: 0.9533, 修復: 0.9200\n",
      "  LPIPS - 壓縮: 0.0029, 修復: 0.0197\n",
      "處理圖像 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 13 質量 10:\n",
      "  PSNR - 壓縮: 23.16dB, 修復: 21.15dB\n",
      "  SSIM - 壓縮: 0.7963, 修復: 0.7438\n",
      "  LPIPS - 壓縮: 0.0837, 修復: 0.0575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 13 質量 30:\n",
      "  PSNR - 壓縮: 26.97dB, 修復: 22.58dB\n",
      "  SSIM - 壓縮: 0.9016, 修復: 0.8263\n",
      "  LPIPS - 壓縮: 0.0103, 修復: 0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 13 質量 50:\n",
      "  PSNR - 壓縮: 29.60dB, 修復: 26.30dB\n",
      "  SSIM - 壓縮: 0.9368, 修復: 0.8963\n",
      "  LPIPS - 壓縮: 0.0040, 修復: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 13 質量 70:\n",
      "  PSNR - 壓縮: 31.29dB, 修復: 27.42dB\n",
      "  SSIM - 壓縮: 0.9554, 修復: 0.9113\n",
      "  LPIPS - 壓縮: 0.0039, 修復: 0.0131\n",
      "處理圖像 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 14 質量 10:\n",
      "  PSNR - 壓縮: 22.50dB, 修復: 21.22dB\n",
      "  SSIM - 壓縮: 0.7622, 修復: 0.7445\n",
      "  LPIPS - 壓縮: 0.0975, 修復: 0.1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 14 質量 30:\n",
      "  PSNR - 壓縮: 25.73dB, 修復: 24.40dB\n",
      "  SSIM - 壓縮: 0.8696, 修復: 0.8456\n",
      "  LPIPS - 壓縮: 0.0255, 修復: 0.0351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 14 質量 50:\n",
      "  PSNR - 壓縮: 28.46dB, 修復: 25.28dB\n",
      "  SSIM - 壓縮: 0.9197, 修復: 0.8760\n",
      "  LPIPS - 壓縮: 0.0040, 修復: 0.0231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 93.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 14 質量 70:\n",
      "  PSNR - 壓縮: 30.59dB, 修復: 26.17dB\n",
      "  SSIM - 壓縮: 0.9496, 修復: 0.8993\n",
      "  LPIPS - 壓縮: 0.0024, 修復: 0.0179\n",
      "處理圖像 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 15 質量 10:\n",
      "  PSNR - 壓縮: 23.20dB, 修復: 18.69dB\n",
      "  SSIM - 壓縮: 0.7836, 修復: 0.5285\n",
      "  LPIPS - 壓縮: 0.0241, 修復: 0.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 94.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 15 質量 30:\n",
      "  PSNR - 壓縮: 27.14dB, 修復: 20.86dB\n",
      "  SSIM - 壓縮: 0.8764, 修復: 0.6264\n",
      "  LPIPS - 壓縮: 0.0074, 修復: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 15 質量 50:\n",
      "  PSNR - 壓縮: 29.75dB, 修復: 24.45dB\n",
      "  SSIM - 壓縮: 0.9249, 修復: 0.7402\n",
      "  LPIPS - 壓縮: 0.0014, 修復: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 15 質量 70:\n",
      "  PSNR - 壓縮: 31.82dB, 修復: 25.94dB\n",
      "  SSIM - 壓縮: 0.9483, 修復: 0.7990\n",
      "  LPIPS - 壓縮: 0.0016, 修復: 0.0065\n",
      "處理圖像 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 94.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 16 質量 10:\n",
      "  PSNR - 壓縮: 25.98dB, 修復: 24.32dB\n",
      "  SSIM - 壓縮: 0.8714, 修復: 0.8254\n",
      "  LPIPS - 壓縮: 0.0291, 修復: 0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 95.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 16 質量 30:\n",
      "  PSNR - 壓縮: 30.60dB, 修復: 27.65dB\n",
      "  SSIM - 壓縮: 0.9487, 修復: 0.9033\n",
      "  LPIPS - 壓縮: 0.0099, 修復: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 93.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 16 質量 50:\n",
      "  PSNR - 壓縮: 33.09dB, 修復: 28.70dB\n",
      "  SSIM - 壓縮: 0.9705, 修復: 0.9368\n",
      "  LPIPS - 壓縮: 0.0019, 修復: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 16 質量 70:\n",
      "  PSNR - 壓縮: 35.21dB, 修復: 30.22dB\n",
      "  SSIM - 壓縮: 0.9818, 修復: 0.9566\n",
      "  LPIPS - 壓縮: 0.0010, 修復: 0.0050\n",
      "處理圖像 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 95.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 17 質量 10:\n",
      "  PSNR - 壓縮: 24.99dB, 修復: 21.43dB\n",
      "  SSIM - 壓縮: 0.8157, 修復: 0.7124\n",
      "  LPIPS - 壓縮: 0.0543, 修復: 0.0827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 95.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 17 質量 30:\n",
      "  PSNR - 壓縮: 28.79dB, 修復: 26.02dB\n",
      "  SSIM - 壓縮: 0.8902, 修復: 0.8623\n",
      "  LPIPS - 壓縮: 0.0139, 修復: 0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 17 質量 50:\n",
      "  PSNR - 壓縮: 31.47dB, 修復: 27.40dB\n",
      "  SSIM - 壓縮: 0.9276, 修復: 0.8719\n",
      "  LPIPS - 壓縮: 0.0044, 修復: 0.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 17 質量 70:\n",
      "  PSNR - 壓縮: 33.69dB, 修復: 28.93dB\n",
      "  SSIM - 壓縮: 0.9537, 修復: 0.8965\n",
      "  LPIPS - 壓縮: 0.0020, 修復: 0.0126\n",
      "處理圖像 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 95.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 18 質量 10:\n",
      "  PSNR - 壓縮: 25.19dB, 修復: 21.90dB\n",
      "  SSIM - 壓縮: 0.7466, 修復: 0.6440\n",
      "  LPIPS - 壓縮: 0.0644, 修復: 0.1155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 95.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 18 質量 30:\n",
      "  PSNR - 壓縮: 29.35dB, 修復: 26.03dB\n",
      "  SSIM - 壓縮: 0.8728, 修復: 0.8218\n",
      "  LPIPS - 壓縮: 0.0133, 修復: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 95.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 18 質量 50:\n",
      "  PSNR - 壓縮: 31.98dB, 修復: 27.76dB\n",
      "  SSIM - 壓縮: 0.9012, 修復: 0.8636\n",
      "  LPIPS - 壓縮: 0.0030, 修復: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 95.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 18 質量 70:\n",
      "  PSNR - 壓縮: 33.85dB, 修復: 28.87dB\n",
      "  SSIM - 壓縮: 0.9308, 修復: 0.8675\n",
      "  LPIPS - 壓縮: 0.0017, 修復: 0.0153\n",
      "處理圖像 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 95.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 19 質量 10:\n",
      "  PSNR - 壓縮: 25.72dB, 修復: 23.38dB\n",
      "  SSIM - 壓縮: 0.7400, 修復: 0.7125\n",
      "  LPIPS - 壓縮: 0.0810, 修復: 0.0809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 95.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 19 質量 30:\n",
      "  PSNR - 壓縮: 29.60dB, 修復: 26.99dB\n",
      "  SSIM - 壓縮: 0.8840, 修復: 0.8321\n",
      "  LPIPS - 壓縮: 0.0183, 修復: 0.0431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 95.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 19 質量 50:\n",
      "  PSNR - 壓縮: 31.71dB, 修復: 27.55dB\n",
      "  SSIM - 壓縮: 0.9120, 修復: 0.8605\n",
      "  LPIPS - 壓縮: 0.0117, 修復: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 94.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 19 質量 70:\n",
      "  PSNR - 壓縮: 33.55dB, 修復: 29.16dB\n",
      "  SSIM - 壓縮: 0.9397, 修復: 0.8966\n",
      "  LPIPS - 壓縮: 0.0085, 修復: 0.0271\n",
      "處理圖像 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 95.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 20 質量 10:\n",
      "  PSNR - 壓縮: 23.43dB, 修復: 21.99dB\n",
      "  SSIM - 壓縮: 0.7941, 修復: 0.7729\n",
      "  LPIPS - 壓縮: 0.0472, 修復: 0.0592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 95.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 20 質量 30:\n",
      "  PSNR - 壓縮: 27.10dB, 修復: 24.48dB\n",
      "  SSIM - 壓縮: 0.9037, 修復: 0.8825\n",
      "  LPIPS - 壓縮: 0.0160, 修復: 0.0190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 94.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 20 質量 50:\n",
      "  PSNR - 壓縮: 28.90dB, 修復: 26.50dB\n",
      "  SSIM - 壓縮: 0.9316, 修復: 0.9151\n",
      "  LPIPS - 壓縮: 0.0051, 修復: 0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 95.08it/s]\n",
      "/tmp/ipykernel_6224/1523092173.py:631: UserWarning: Glyph 36074 (\\N{CJK UNIFIED IDEOGRAPH-8CEA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_6224/1523092173.py:631: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_6224/1523092173.py:631: UserWarning: Glyph 25552 (\\N{CJK UNIFIED IDEOGRAPH-63D0}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_6224/1523092173.py:631: UserWarning: Glyph 21319 (\\N{CJK UNIFIED IDEOGRAPH-5347}) missing from current font.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像 20 質量 70:\n",
      "  PSNR - 壓縮: 30.69dB, 修復: 28.01dB\n",
      "  SSIM - 壓縮: 0.9540, 修復: 0.9392\n",
      "  LPIPS - 壓縮: 0.0023, 修復: 0.0058\n",
      "處理圖像 20/20\n",
      "\n",
      "============================================================\n",
      "平均結果：\n",
      "============================================================\n",
      "質量         PSNR (壓縮)       PSNR (修復)       SSIM (壓縮)       SSIM (修復)       LPIPS (壓縮)      LPIPS (修復)     \n",
      "------------------------------------------------------------------------------------------\n",
      "10         23.73           20.96           0.7843          0.7259          0.0504          0.0727         \n",
      "30         27.25           23.74           0.8848          0.8365          0.0147          0.0375         \n",
      "50         29.76           25.54           0.9254          0.8720          0.0042          0.0256         \n",
      "70         31.75           27.25           0.9503          0.9037          0.0022          0.0128         \n",
      "==========================================================================================\n",
      "PSNR: 越高越好 | SSIM: 越高越好 | LPIPS: 越低越好\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6224/1523092173.py:631: UserWarning: Glyph 25913 (\\N{CJK UNIFIED IDEOGRAPH-6539}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_6224/1523092173.py:631: UserWarning: Glyph 21892 (\\N{CJK UNIFIED IDEOGRAPH-5584}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_6224/1523092173.py:631: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_6224/1523092173.py:631: UserWarning: Glyph 36234 (\\N{CJK UNIFIED IDEOGRAPH-8D8A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_6224/1523092173.py:631: UserWarning: Glyph 39640 (\\N{CJK UNIFIED IDEOGRAPH-9AD8}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_6224/1523092173.py:631: UserWarning: Glyph 22909 (\\N{CJK UNIFIED IDEOGRAPH-597D}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_6224/1523092173.py:632: UserWarning: Glyph 36074 (\\N{CJK UNIFIED IDEOGRAPH-8CEA}) missing from current font.\n",
      "  plt.savefig('performance_gains.png')\n",
      "/tmp/ipykernel_6224/1523092173.py:632: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from current font.\n",
      "  plt.savefig('performance_gains.png')\n",
      "/tmp/ipykernel_6224/1523092173.py:632: UserWarning: Glyph 25552 (\\N{CJK UNIFIED IDEOGRAPH-63D0}) missing from current font.\n",
      "  plt.savefig('performance_gains.png')\n",
      "/tmp/ipykernel_6224/1523092173.py:632: UserWarning: Glyph 21319 (\\N{CJK UNIFIED IDEOGRAPH-5347}) missing from current font.\n",
      "  plt.savefig('performance_gains.png')\n",
      "/tmp/ipykernel_6224/1523092173.py:632: UserWarning: Glyph 25913 (\\N{CJK UNIFIED IDEOGRAPH-6539}) missing from current font.\n",
      "  plt.savefig('performance_gains.png')\n",
      "/tmp/ipykernel_6224/1523092173.py:632: UserWarning: Glyph 21892 (\\N{CJK UNIFIED IDEOGRAPH-5584}) missing from current font.\n",
      "  plt.savefig('performance_gains.png')\n",
      "/tmp/ipykernel_6224/1523092173.py:632: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.\n",
      "  plt.savefig('performance_gains.png')\n",
      "/tmp/ipykernel_6224/1523092173.py:632: UserWarning: Glyph 36234 (\\N{CJK UNIFIED IDEOGRAPH-8D8A}) missing from current font.\n",
      "  plt.savefig('performance_gains.png')\n",
      "/tmp/ipykernel_6224/1523092173.py:632: UserWarning: Glyph 39640 (\\N{CJK UNIFIED IDEOGRAPH-9AD8}) missing from current font.\n",
      "  plt.savefig('performance_gains.png')\n",
      "/tmp/ipykernel_6224/1523092173.py:632: UserWarning: Glyph 22909 (\\N{CJK UNIFIED IDEOGRAPH-597D}) missing from current font.\n",
      "  plt.savefig('performance_gains.png')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pytorch_msssim import ssim\n",
    "import lpips\n",
    "\n",
    "# 設定設備\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 載入CIFAR10測試資料集\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# JPEG壓縮函數\n",
    "def jpeg_compress(x, quality):\n",
    "    \"\"\"執行JPEG壓縮並加強色彩保存\"\"\"\n",
    "    x = (x * 127.5 + 127.5).clamp(0, 255).to(torch.uint8).cpu()\n",
    "    compressed_images = []\n",
    "    for img in x:\n",
    "        pil_img = torchvision.transforms.ToPILImage()(img)\n",
    "        buffer = io.BytesIO()\n",
    "        # 確保quality在1-100的有效範圍內\n",
    "        quality = max(1, min(100, int(quality)))\n",
    "        # 根據質量選擇子採樣模式，提高色彩保留\n",
    "        subsampling = \"4:4:4\" if quality > 30 else \"4:2:0\"\n",
    "        pil_img.save(buffer, format=\"JPEG\", quality=quality, subsampling=subsampling)\n",
    "        buffer.seek(0)\n",
    "        compressed_img = Image.open(buffer)\n",
    "        compressed_tensor = torchvision.transforms.ToTensor()(compressed_img)\n",
    "        compressed_images.append(compressed_tensor)\n",
    "    return torch.stack(compressed_images).to(device).sub(0.5).div(0.5)\n",
    "\n",
    "# 時間嵌入模組\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim * 4, dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, t):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return self.proj(emb)\n",
    "\n",
    "# DCT層\n",
    "class DCTLayer(nn.Module):\n",
    "    \"\"\"實現DCT變換層，用於頻域分析\"\"\"\n",
    "    def __init__(self, block_size=8):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 保存原始尺寸\n",
    "        b, c, h, w = x.shape\n",
    "        \n",
    "        # 使用可調整的插值確保輸出與輸入尺寸相同\n",
    "        # 先進行DCT變換\n",
    "        x_dct = self._apply_dct(x)\n",
    "        \n",
    "        # 確保輸出尺寸與輸入相同\n",
    "        if x_dct.shape[2:] != x.shape[2:]:\n",
    "            x_dct = F.interpolate(x_dct, size=(h, w), mode='bilinear', align_corners=False)\n",
    "            \n",
    "        return x_dct\n",
    "    \n",
    "    def _apply_dct(self, x):\n",
    "        \"\"\"實際執行DCT變換的輔助函數\"\"\"\n",
    "        b, c, h, w = x.shape\n",
    "        \n",
    "        # 補充填充以確保尺寸是block_size的倍數\n",
    "        h_pad = (self.block_size - h % self.block_size) % self.block_size\n",
    "        w_pad = (self.block_size - w % self.block_size) % self.block_size\n",
    "        \n",
    "        x_padded = F.pad(x, (0, w_pad, 0, h_pad))\n",
    "        \n",
    "        # 獲取填充後的尺寸\n",
    "        _, _, h_padded, w_padded = x_padded.shape\n",
    "        \n",
    "        # 計算块的數量\n",
    "        h_blocks = h_padded // self.block_size\n",
    "        w_blocks = w_padded // self.block_size\n",
    "        \n",
    "        # 分塊處理\n",
    "        x_blocks = x_padded.unfold(2, self.block_size, self.block_size).unfold(3, self.block_size, self.block_size)\n",
    "        \n",
    "        # 獲取展開後的尺寸\n",
    "        b_unf, c_unf, h_unf, w_unf, bs_h, bs_w = x_blocks.shape\n",
    "        \n",
    "        # 重構為便於進行DCT的形狀\n",
    "        x_blocks_flat = x_blocks.reshape(-1, self.block_size, self.block_size)\n",
    "        \n",
    "        # 獲取DCT矩陣\n",
    "        dct_matrix = self._get_dct_matrix(self.block_size).to(x.device)\n",
    "        \n",
    "        # 應用DCT變換: D * X * D^T\n",
    "        x_dct_flat = torch.matmul(dct_matrix, x_blocks_flat)\n",
    "        x_dct_flat = torch.matmul(x_dct_flat, dct_matrix.transpose(0, 1))\n",
    "        \n",
    "        # 恢復展開形狀\n",
    "        x_dct_blocks = x_dct_flat.reshape(b_unf, c_unf, h_unf, w_unf, bs_h, bs_w)\n",
    "        \n",
    "        # 重新排列為可以恢復原始形狀的排列\n",
    "        x_dct_perm = x_dct_blocks.permute(0, 1, 2, 4, 3, 5)\n",
    "        \n",
    "        # 重構為填充後的原始形狀\n",
    "        x_dct = x_dct_perm.reshape(b, c, h_padded, w_padded)\n",
    "        \n",
    "        # 去除填充部分\n",
    "        if h_pad > 0 or w_pad > 0:\n",
    "            x_dct = x_dct[:, :, :h, :w]\n",
    "        \n",
    "        return x_dct\n",
    "    \n",
    "    def _get_dct_matrix(self, size):\n",
    "        \"\"\"生成離散餘弦變換矩陣\"\"\"\n",
    "        dct_matrix = torch.zeros(size, size)\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                if i == 0:\n",
    "                    dct_matrix[i, j] = 1.0 / torch.sqrt(torch.tensor(size, dtype=torch.float32))\n",
    "                else:\n",
    "                    dct_matrix[i, j] = torch.sqrt(torch.tensor(2.0 / size)) * torch.cos(torch.tensor(torch.pi * (2 * j + 1) * i / (2 * size)))\n",
    "        return dct_matrix\n",
    "\n",
    "# 高頻補償模塊\n",
    "class HFCM(nn.Module):\n",
    "    \"\"\"高頻補償模塊，從FDG-Diff論文改編\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.dct = DCTLayer(block_size=8)\n",
    "        self.high_freq_attn = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.conv_out = nn.Conv2d(channels, channels, 1)\n",
    "        \n",
    "    def forward(self, x, compression_level):\n",
    "        # 提取DCT頻域表示\n",
    "        x_dct = self.dct(x)\n",
    "        \n",
    "        # 確保x_dct與x有相同的空間尺寸\n",
    "        if x_dct.shape[2:] != x.shape[2:]:\n",
    "            x_dct = F.interpolate(x_dct, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # 高頻注意力掩碼生成\n",
    "        attn_mask = self.high_freq_attn(x)\n",
    "        \n",
    "        # 確保compression_level是標量或可廣播的形狀\n",
    "        if isinstance(compression_level, torch.Tensor) and compression_level.dim() > 0:\n",
    "            compression_level = compression_level.view(-1, 1, 1, 1)\n",
    "        \n",
    "        # 根據壓縮級別調整高頻增強程度\n",
    "        # 壓縮級別越高(質量越低)，增強程度越大\n",
    "        freq_scale = 1.0 - compression_level\n",
    "        \n",
    "        # 應用高頻增強\n",
    "        enhanced = x + attn_mask * x_dct * freq_scale\n",
    "        return self.conv_out(enhanced)\n",
    "\n",
    "# 頻域引導模塊\n",
    "class FrequencyAwareBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.dct_layer = DCTLayer(block_size=8)\n",
    "        self.freq_conv = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.freq_attn = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // 4, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels // 4, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, compression_level):\n",
    "        # 提取頻域特徵\n",
    "        x_dct = self.dct_layer(x)\n",
    "        \n",
    "        # 確保x_dct與x有相同的空間尺寸\n",
    "        if x_dct.shape[2:] != x.shape[2:]:\n",
    "            x_dct = F.interpolate(x_dct, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "            \n",
    "        x_freq = self.freq_conv(x_dct)\n",
    "        \n",
    "        # 確保x_freq與x有相同的空間尺寸\n",
    "        if x_freq.shape[2:] != x.shape[2:]:\n",
    "            x_freq = F.interpolate(x_freq, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # 生成頻域注意力\n",
    "        attn = self.freq_attn(x_freq)\n",
    "        \n",
    "        # 確保compression_level是標量或可廣播的形狀\n",
    "        if isinstance(compression_level, torch.Tensor) and compression_level.dim() > 0:\n",
    "            compression_level = compression_level.view(-1, 1, 1, 1)\n",
    "        \n",
    "        # 根據壓縮級別調整頻域注意力\n",
    "        attn = attn * (1.0 - compression_level) + 0.5\n",
    "        \n",
    "        # 確保attn可以與x_freq適當廣播\n",
    "        if attn.shape[2:] != x_freq.shape[2:]:\n",
    "            attn = F.interpolate(attn, size=x_freq.shape[2:], mode='nearest')\n",
    "        \n",
    "        # 應用頻域注意力\n",
    "        return x + x_freq * attn\n",
    "\n",
    "# 殘差注意力模塊\n",
    "class ResAttnBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c, time_dim, dropout=0.1, use_freq_guide=False):\n",
    "        super().__init__()\n",
    "        # 確保組數能被通道數整除\n",
    "        num_groups = min(8, in_c)\n",
    "        while in_c % num_groups != 0 and num_groups > 1:\n",
    "            num_groups -= 1\n",
    "            \n",
    "        self.norm1 = nn.GroupNorm(num_groups, in_c)\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, 3, padding=1)\n",
    "        self.time_proj = nn.Linear(time_dim, out_c)\n",
    "        \n",
    "        # 調整 out_c 的組數\n",
    "        num_groups_out = min(8, out_c)\n",
    "        while out_c % num_groups_out != 0 and num_groups_out > 1:\n",
    "            num_groups_out -= 1\n",
    "            \n",
    "        self.norm2 = nn.GroupNorm(num_groups_out, out_c)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, 3, padding=1)\n",
    "        self.attn = nn.MultiheadAttention(out_c, 4, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.shortcut = nn.Conv2d(in_c, out_c, 1) if in_c != out_c else nn.Identity()\n",
    "        \n",
    "        # 頻域引導(僅在某些塊使用)\n",
    "        self.use_freq_guide = use_freq_guide\n",
    "        if use_freq_guide:\n",
    "            self.freq_guide = FrequencyAwareBlock(out_c)\n",
    "            self.hfcm = HFCM(out_c)\n",
    "        \n",
    "    def forward(self, x, t_emb, compression_level=None):\n",
    "        h = self.norm1(x)\n",
    "        h = self.conv1(h)\n",
    "        \n",
    "        # 加入時間編碼\n",
    "        t = self.time_proj(t_emb)[..., None, None]\n",
    "        h = h + t\n",
    "        \n",
    "        h = self.norm2(h)\n",
    "        h = self.conv2(F.silu(h))\n",
    "        \n",
    "        # 應用自注意力機制\n",
    "        b, c, hh, ww = h.shape\n",
    "        h_attn = h.view(b, c, -1).permute(0, 2, 1)\n",
    "        h_attn, _ = self.attn(h_attn, h_attn, h_attn)\n",
    "        h_attn = h_attn.permute(0, 2, 1).view(b, c, hh, ww)\n",
    "        \n",
    "        # 應用頻域引導(如果啟用)\n",
    "        if self.use_freq_guide and compression_level is not None:\n",
    "            h_attn = self.freq_guide(h_attn, compression_level)\n",
    "            h_attn = self.hfcm(h_attn, compression_level)\n",
    "        \n",
    "        return self.shortcut(x) + self.dropout(h_attn)\n",
    "\n",
    "# SVD結構保留輔助函數\n",
    "def svd_structure_preservation(x, k_ratio=0.5):\n",
    "    \"\"\"使用SVD提取主要結構特徵\"\"\"\n",
    "    b, c, h, w = x.shape\n",
    "    x_flat = x.view(b, c, -1)\n",
    "    \n",
    "    # 對每個通道進行SVD分解\n",
    "    structure_tensors = []\n",
    "    for i in range(b):\n",
    "        channels_structure = []\n",
    "        for j in range(c):\n",
    "            # SVD分解\n",
    "            U, S, Vh = torch.linalg.svd(x_flat[i, j].view(h, w), full_matrices=False)\n",
    "            \n",
    "            # 確定保留的奇異值數量\n",
    "            k = max(1, int(min(h, w) * k_ratio))\n",
    "            \n",
    "            # 重建降秩表示\n",
    "            S_k = torch.zeros_like(S)\n",
    "            S_k[:k] = S[:k]\n",
    "            structure = torch.matmul(U, torch.matmul(torch.diag(S_k), Vh))\n",
    "            channels_structure.append(structure.unsqueeze(0))\n",
    "        \n",
    "        # 所有通道結合\n",
    "        structure_tensors.append(torch.cat(channels_structure, dim=0).unsqueeze(0))\n",
    "    \n",
    "    return torch.cat(structure_tensors, dim=0)\n",
    "\n",
    "# 相位一致性函數\n",
    "def phase_consistency(x, ref, alpha=0.7):\n",
    "    \"\"\"保持參考圖像的相位信息，同時使用新的幅度\"\"\"\n",
    "    # FFT變換\n",
    "    x_fft = torch.fft.fft2(x)\n",
    "    ref_fft = torch.fft.fft2(ref)\n",
    "    \n",
    "    # 提取幅度和相位\n",
    "    x_mag = torch.abs(x_fft)\n",
    "    ref_phase = torch.angle(ref_fft)\n",
    "    \n",
    "    # 創建新的複數張量，使用x的幅度和參考的相位\n",
    "    real = x_mag * torch.cos(ref_phase)\n",
    "    imag = x_mag * torch.sin(ref_phase)\n",
    "    adjusted_fft = torch.complex(real, imag)\n",
    "    \n",
    "    # 反變換\n",
    "    adjusted_img = torch.fft.ifft2(adjusted_fft).real\n",
    "    \n",
    "    # 混合原始圖像和相位調整圖像\n",
    "    return alpha * x + (1 - alpha) * adjusted_img\n",
    "\n",
    "# UNet架構\n",
    "class JPEGDiffusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        time_dim = 256\n",
    "        self.time_embed = TimeEmbedding(time_dim)\n",
    "        \n",
    "        # 下采样路径\n",
    "        self.down1 = ResAttnBlock(3, 64, time_dim)\n",
    "        self.down2 = ResAttnBlock(64, 128, time_dim, use_freq_guide=True)\n",
    "        self.down3 = ResAttnBlock(128, 256, time_dim, use_freq_guide=True)\n",
    "        self.down4 = ResAttnBlock(256, 512, time_dim)\n",
    "        self.down5 = ResAttnBlock(512, 512, time_dim)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # 瓶颈层\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            ResAttnBlock(512, 1024, time_dim, use_freq_guide=True),\n",
    "            ResAttnBlock(1024, 1024, time_dim),\n",
    "            ResAttnBlock(1024, 512, time_dim, use_freq_guide=True)\n",
    "        )\n",
    "        \n",
    "        # 上采样路径\n",
    "        self.up1 = ResAttnBlock(1024, 512, time_dim)\n",
    "        self.up2 = ResAttnBlock(512 + 512, 256, time_dim, use_freq_guide=True)\n",
    "        self.up3 = ResAttnBlock(256 + 256, 128, time_dim, use_freq_guide=True)\n",
    "        self.up4 = ResAttnBlock(128 + 128, 64, time_dim)\n",
    "        self.up5 = ResAttnBlock(64 + 64, 64, time_dim)\n",
    "        \n",
    "        # 輸出層\n",
    "        self.out_conv = nn.Conv2d(64, 3, 1)\n",
    "        \n",
    "    def forward(self, x, t, compression_level=None):\n",
    "        t_emb = self.time_embed(t)\n",
    "        \n",
    "        # 如果未提供壓縮級別，從時間步估計\n",
    "        if compression_level is None:\n",
    "            compression_level = t.clone().detach()\n",
    "        \n",
    "        # 下采样\n",
    "        d1 = self.down1(x, t_emb)  # 32x32\n",
    "        d2 = self.down2(self.pool(d1), t_emb, compression_level)  # 16x16\n",
    "        d3 = self.down3(self.pool(d2), t_emb, compression_level)  # 8x8\n",
    "        d4 = self.down4(self.pool(d3), t_emb)  # 4x4\n",
    "        d5 = self.down5(self.pool(d4), t_emb)  # 2x2\n",
    "        \n",
    "        # 瓶颈层\n",
    "        b = self.bottleneck[0](self.pool(d5), t_emb, compression_level)\n",
    "        b = self.bottleneck[1](b, t_emb)\n",
    "        b = self.bottleneck[2](b, t_emb, compression_level)\n",
    "        \n",
    "        # 上采样\n",
    "        u1 = self.up1(torch.cat([F.interpolate(b, scale_factor=2, mode='bilinear', align_corners=False), d5], dim=1), t_emb)\n",
    "        u2 = self.up2(torch.cat([F.interpolate(u1, scale_factor=2, mode='bilinear', align_corners=False), d4], dim=1), t_emb, compression_level)\n",
    "        u3 = self.up3(torch.cat([F.interpolate(u2, scale_factor=2, mode='bilinear', align_corners=False), d3], dim=1), t_emb, compression_level)\n",
    "        u4 = self.up4(torch.cat([F.interpolate(u3, scale_factor=2, mode='bilinear', align_corners=False), d2], dim=1), t_emb)\n",
    "        u5 = self.up5(torch.cat([F.interpolate(u4, scale_factor=2, mode='bilinear', align_corners=False), d1], dim=1), t_emb)\n",
    "        \n",
    "        return self.out_conv(u5)\n",
    "\n",
    "# 高斯混合模型採樣器\n",
    "class GaussianMixtureSampler:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def sample(self, x_t, steps=100, use_phase_consistency=True, use_svd_guide=True, guidance_scale=1.0):\n",
    "        \"\"\"使用高斯混合模型進行採樣，結合相位一致性和SVD引導\"\"\"\n",
    "        self.model.eval()\n",
    "        # 保存原始壓縮圖像用於相位一致性\n",
    "        original_compressed = x_t.clone()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # 從給定的噪聲圖像開始\n",
    "            for i in tqdm(range(steps-1, -1, -1), desc=\"Sampling\"):\n",
    "                t = torch.full((x_t.size(0),), i, device=device).float() / num_timesteps\n",
    "                compression_level = t.clone()  # 壓縮級別與時間步對應\n",
    "                \n",
    "                # 獲取噪聲預測\n",
    "                pred_noise = model(x_t, t, compression_level)\n",
    "                \n",
    "                # 如果啟用SVD引導\n",
    "                if use_svd_guide and i > steps // 2:\n",
    "                    # 在前半部分採樣過程中使用SVD引導(粗糙結構)\n",
    "                    k_ratio = i / steps  # 隨時間降低保留比例\n",
    "                    structure_prior = svd_structure_preservation(x_t, k_ratio)\n",
    "                    # 混合SVD結構和預測\n",
    "                    guide_strength = k_ratio * 0.3  # SVD影響隨時間降低\n",
    "                    pred_noise = (1 - guide_strength) * pred_noise + guide_strength * (original_compressed - structure_prior)\n",
    "                \n",
    "                if i > 0:\n",
    "                    # 預測的x0\n",
    "                    x0_pred = x_t + pred_noise\n",
    "                    \n",
    "                    # 計算多個高斯分量的均值\n",
    "                    # 第一個均值 - 更保守的估計\n",
    "                    mu1 = x0_pred * 0.9 + x_t * 0.1\n",
    "                    # 第二個均值 - 更積極的估計\n",
    "                    mu2 = x0_pred * 1.1 - x_t * 0.1\n",
    "                    \n",
    "                    # 根據當前時間步選擇使用哪個分量\n",
    "                    p_conservative = max(0.2, min(0.8, i / steps))\n",
    "                    use_first = torch.rand(1).item() < p_conservative\n",
    "                    next_mean = mu1 if use_first else mu2\n",
    "                    \n",
    "                    # 逐步減少噪聲尺度\n",
    "                    noise_scale = 0.1 * i / steps * guidance_scale\n",
    "                    x_next = next_mean + noise_scale * torch.randn_like(x_t)\n",
    "                    \n",
    "                    # 相位一致性(每5步應用一次)\n",
    "                    if use_phase_consistency and i % 5 == 0:\n",
    "                        alpha = 0.6 + 0.3 * (1 - i / steps)  # 隨時間增加原始圖像權重\n",
    "                        x_next = phase_consistency(x_next, original_compressed, alpha)\n",
    "                    \n",
    "                    x_t = x_next\n",
    "                else:\n",
    "                    # 最後一步直接使用預測的原始圖像\n",
    "                    x_t = x_t + pred_noise\n",
    "        \n",
    "        return x_t\n",
    "\n",
    "# 設定JPEG擴散參數\n",
    "num_timesteps = 100\n",
    "betas = torch.linspace(1e-4, 0.02, num_timesteps).to(device)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "# 計算PSNR\n",
    "def calculate_psnr(img1, img2):\n",
    "    # 確保圖像在0到1範圍內\n",
    "    img1 = (img1 * 0.5 + 0.5).clamp(0, 1)\n",
    "    img2 = (img2 * 0.5 + 0.5).clamp(0, 1)\n",
    "    mse = F.mse_loss(img1, img2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 10 * torch.log10(1.0 / mse)\n",
    "\n",
    "# 計算SSIM\n",
    "def calculate_ssim(img1, img2):\n",
    "    # 確保圖像在0到1範圍內\n",
    "    img1 = (img1 * 0.5 + 0.5).clamp(0, 1)\n",
    "    img2 = (img2 * 0.5 + 0.5).clamp(0, 1)\n",
    "    return ssim(img1, img2, data_range=1.0)\n",
    "\n",
    "# 計算LPIPS\n",
    "def calculate_lpips(img1, img2, lpips_model):\n",
    "    # 確保圖像在-1到1範圍內 (LPIPS模型要求)\n",
    "    return lpips_model(img1, img2)\n",
    "\n",
    "# 載入模型\n",
    "model = JPEGDiffusionModel().to(device)\n",
    "try:\n",
    "    checkpoint = torch.load(\"best_jpeg_diffusion.pth\", map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded model from epoch {checkpoint['epoch'] + 1}\")\n",
    "except:\n",
    "    print(\"無法載入預訓練模型，請確保'best_jpeg_diffusion.pth'存在\")\n",
    "    exit()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 創建LPIPS損失計算模型\n",
    "lpips_model = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "# 測試修復\n",
    "sampler = GaussianMixtureSampler(model)\n",
    "\n",
    "# 測試不同質量級別\n",
    "quality_levels = [10, 30, 50, 70]\n",
    "num_test_images = 20  # 測試圖片數量\n",
    "\n",
    "# 用於保存結果的字典\n",
    "results = {q: {'psnr_compressed': [], 'psnr_restored': [], \n",
    "                'ssim_compressed': [], 'ssim_restored': [], \n",
    "                'lpips_compressed': [], 'lpips_restored': []} for q in quality_levels}\n",
    "\n",
    "for img_idx, (x0, _) in enumerate(test_dataloader):\n",
    "    if img_idx >= num_test_images:\n",
    "        break\n",
    "        \n",
    "    x0 = x0.to(device)\n",
    "    \n",
    "    plt.figure(figsize=(len(quality_levels)*4+4, 8))\n",
    "    plt.subplot(2, len(quality_levels)+1, 1)\n",
    "    plt.imshow((x0[0] * 0.5 + 0.5).cpu().permute(1, 2, 0).clamp(0, 1))\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    for i, quality in enumerate(quality_levels):\n",
    "        # 壓縮圖像\n",
    "        x_compressed = jpeg_compress(x0, quality)\n",
    "        \n",
    "        # 設定初始時間步基於質量\n",
    "        init_t = int((100 - quality) / 100 * num_timesteps)\n",
    "        \n",
    "        # 修復圖像\n",
    "        x_restored = sampler.sample(x_compressed, steps=init_t+1, guidance_scale=0.8)\n",
    "        \n",
    "        # 計算PSNR\n",
    "        psnr_compressed = calculate_psnr(x0, x_compressed)\n",
    "        psnr_restored = calculate_psnr(x0, x_restored)\n",
    "        \n",
    "        # 計算SSIM\n",
    "        ssim_compressed = calculate_ssim(x0, x_compressed)\n",
    "        ssim_restored = calculate_ssim(x0, x_restored)\n",
    "        \n",
    "        # 計算LPIPS\n",
    "        lpips_compressed = calculate_lpips(x0, x_compressed, lpips_model)\n",
    "        lpips_restored = calculate_lpips(x0, x_restored, lpips_model)\n",
    "        \n",
    "        # 保存結果\n",
    "        results[quality]['psnr_compressed'].append(psnr_compressed.item())\n",
    "        results[quality]['psnr_restored'].append(psnr_restored.item())\n",
    "        results[quality]['ssim_compressed'].append(ssim_compressed.item())\n",
    "        results[quality]['ssim_restored'].append(ssim_restored.item())\n",
    "        results[quality]['lpips_compressed'].append(lpips_compressed.item())\n",
    "        results[quality]['lpips_restored'].append(lpips_restored.item())\n",
    "        \n",
    "        # 列印當前圖像的結果\n",
    "        print(f\"圖像 {img_idx+1} 質量 {quality}:\")\n",
    "        print(f\"  PSNR - 壓縮: {psnr_compressed:.2f}dB, 修復: {psnr_restored:.2f}dB\")\n",
    "        print(f\"  SSIM - 壓縮: {ssim_compressed:.4f}, 修復: {ssim_restored:.4f}\")\n",
    "        print(f\"  LPIPS - 壓縮: {lpips_compressed.item():.4f}, 修復: {lpips_restored.item():.4f}\")\n",
    "        \n",
    "        # 顯示壓縮圖像\n",
    "        plt.subplot(2, len(quality_levels)+1, i+2)\n",
    "        plt.imshow((x_compressed[0] * 0.5 + 0.5).cpu().permute(1, 2, 0).clamp(0, 1))\n",
    "        plt.title(f\"JPEG Q{quality}\\nPSNR: {psnr_compressed:.2f}dB\\nSSIM: {ssim_compressed:.4f}\\nLPIPS: {lpips_compressed.item():.4f}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 顯示修復圖像\n",
    "        plt.subplot(2, len(quality_levels)+1, len(quality_levels)+i+2)\n",
    "        plt.imshow((x_restored[0] * 0.5 + 0.5).cpu().permute(1, 2, 0).clamp(0, 1))\n",
    "        plt.title(f\"Restored Q{quality}\\nPSNR: {psnr_restored:.2f}dB\\nSSIM: {ssim_restored:.4f}\\nLPIPS: {lpips_restored.item():.4f}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./0407_test/test_sample_{img_idx+1}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"處理圖像 {img_idx+1}/{num_test_images}\")\n",
    "\n",
    "# 計算並顯示平均結果\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"平均結果：\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'質量':<10} {'PSNR (壓縮)':<15} {'PSNR (修復)':<15} {'SSIM (壓縮)':<15} {'SSIM (修復)':<15} {'LPIPS (壓縮)':<15} {'LPIPS (修復)':<15}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "for quality in quality_levels:\n",
    "    avg_psnr_comp = sum(results[quality]['psnr_compressed']) / len(results[quality]['psnr_compressed'])\n",
    "    avg_psnr_rest = sum(results[quality]['psnr_restored']) / len(results[quality]['psnr_restored'])\n",
    "    avg_ssim_comp = sum(results[quality]['ssim_compressed']) / len(results[quality]['ssim_compressed'])\n",
    "    avg_ssim_rest = sum(results[quality]['ssim_restored']) / len(results[quality]['ssim_restored'])\n",
    "    avg_lpips_comp = sum(results[quality]['lpips_compressed']) / len(results[quality]['lpips_compressed'])\n",
    "    avg_lpips_rest = sum(results[quality]['lpips_restored']) / len(results[quality]['lpips_restored'])\n",
    "    \n",
    "    print(f\"{quality:<10} {avg_psnr_comp:<15.2f} {avg_psnr_rest:<15.2f} {avg_ssim_comp:<15.4f} {avg_ssim_rest:<15.4f} {avg_lpips_comp:<15.4f} {avg_lpips_rest:<15.4f}\")\n",
    "    \n",
    "print(\"=\"*90)\n",
    "print(f\"PSNR: 越高越好 | SSIM: 越高越好 | LPIPS: 越低越好\")\n",
    "\n",
    "# 繪製平均性能提升圖\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# PSNR提升\n",
    "plt.subplot(1, 3, 1)\n",
    "psnr_gains = [sum(results[q]['psnr_restored']) / len(results[q]['psnr_restored']) - \n",
    "              sum(results[q]['psnr_compressed']) / len(results[q]['psnr_compressed']) \n",
    "              for q in quality_levels]\n",
    "plt.bar(quality_levels, psnr_gains)\n",
    "plt.title('PSNR提升(dB)')\n",
    "plt.xlabel('JPEG質量')\n",
    "plt.ylabel('提升(dB)')\n",
    "\n",
    "# SSIM提升\n",
    "plt.subplot(1, 3, 2)\n",
    "ssim_gains = [sum(results[q]['ssim_restored']) / len(results[q]['ssim_restored']) - \n",
    "              sum(results[q]['ssim_compressed']) / len(results[q]['ssim_compressed']) \n",
    "              for q in quality_levels]\n",
    "plt.bar(quality_levels, ssim_gains)\n",
    "plt.title('SSIM提升')\n",
    "plt.xlabel('JPEG質量')\n",
    "plt.ylabel('提升')\n",
    "\n",
    "# LPIPS改善\n",
    "plt.subplot(1, 3, 3)\n",
    "lpips_gains = [sum(results[q]['lpips_compressed']) / len(results[q]['lpips_compressed']) - \n",
    "               sum(results[q]['lpips_restored']) / len(results[q]['lpips_restored']) \n",
    "               for q in quality_levels]\n",
    "plt.bar(quality_levels, lpips_gains)\n",
    "plt.title('LPIPS改善')\n",
    "plt.xlabel('JPEG質量')\n",
    "plt.ylabel('改善(值越高越好)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('performance_gains.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
