{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Total parameters: 119,873,161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Avg Loss: 0.00351, Color Loss: 0.07230, LR: 1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 1: 100%|██████████| 40/40 [00:03<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00302, Color Loss: 0.06658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.94it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.11it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.77it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.06it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val loss 0.00302 and color loss 0.06658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Avg Loss: 0.00298, Color Loss: 0.06407, LR: 9.99e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 2: 100%|██████████| 40/40 [00:03<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00293, Color Loss: 0.06489\n",
      "New best model saved with val loss 0.00293 and color loss 0.06489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Avg Loss: 0.00297, Color Loss: 0.06392, LR: 9.98e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 3: 100%|██████████| 40/40 [00:03<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00280, Color Loss: 0.06281\n",
      "New best model saved with val loss 0.00280 and color loss 0.06281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Avg Loss: 0.00283, Color Loss: 0.06112, LR: 9.96e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 4: 100%|██████████| 40/40 [00:03<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00288, Color Loss: 0.06326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Avg Loss: 0.00292, Color Loss: 0.06245, LR: 9.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 5: 100%|██████████| 40/40 [00:03<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00272, Color Loss: 0.06145\n",
      "New best model saved with val loss 0.00272 and color loss 0.06145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Avg Loss: 0.00288, Color Loss: 0.06233, LR: 9.91e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 6: 100%|██████████| 40/40 [00:03<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00275, Color Loss: 0.06184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.34it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.82it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.87it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.92it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 7: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Avg Loss: 0.00249, Color Loss: 0.05562, LR: 9.88e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 7: 100%|██████████| 40/40 [00:03<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00273, Color Loss: 0.06104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Avg Loss: 0.00264, Color Loss: 0.05809, LR: 9.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 8: 100%|██████████| 40/40 [00:03<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00268, Color Loss: 0.06028\n",
      "New best model saved with val loss 0.00268 and color loss 0.06028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Avg Loss: 0.00256, Color Loss: 0.05617, LR: 9.80e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 9: 100%|██████████| 40/40 [00:03<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00268, Color Loss: 0.06050\n",
      "New best model saved with val loss 0.00268 and color loss 0.06050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Avg Loss: 0.00244, Color Loss: 0.05464, LR: 9.76e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 10: 100%|██████████| 40/40 [00:03<00:00, 11.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00264, Color Loss: 0.05963\n",
      "New best model saved with val loss 0.00264 and color loss 0.05963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Avg Loss: 0.00251, Color Loss: 0.05556, LR: 9.70e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 11: 100%|██████████| 40/40 [00:03<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00273, Color Loss: 0.06092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.07it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.83it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.78it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.43it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 12: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Avg Loss: 0.00229, Color Loss: 0.05227, LR: 9.65e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 12: 100%|██████████| 40/40 [00:03<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00265, Color Loss: 0.05963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Avg Loss: 0.00232, Color Loss: 0.05232, LR: 9.59e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 13: 100%|██████████| 40/40 [00:03<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00260, Color Loss: 0.05873\n",
      "New best model saved with val loss 0.00260 and color loss 0.05873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Avg Loss: 0.00243, Color Loss: 0.05372, LR: 9.52e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 14: 100%|██████████| 40/40 [00:03<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00264, Color Loss: 0.05996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Avg Loss: 0.00237, Color Loss: 0.05301, LR: 9.46e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 15: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00256, Color Loss: 0.05787\n",
      "New best model saved with val loss 0.00256 and color loss 0.05787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Avg Loss: 0.00229, Color Loss: 0.05192, LR: 9.38e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 16: 100%|██████████| 40/40 [00:03<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00257, Color Loss: 0.05794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.73it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.04it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.46it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.94it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 17: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Avg Loss: 0.00216, Color Loss: 0.04942, LR: 9.30e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 17: 100%|██████████| 40/40 [00:03<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00260, Color Loss: 0.05846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Avg Loss: 0.00211, Color Loss: 0.04857, LR: 9.22e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 18: 100%|██████████| 40/40 [00:03<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00248, Color Loss: 0.05680\n",
      "New best model saved with val loss 0.00248 and color loss 0.05680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Avg Loss: 0.00224, Color Loss: 0.05090, LR: 9.14e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 19: 100%|██████████| 40/40 [00:03<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00252, Color Loss: 0.05720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Avg Loss: 0.00199, Color Loss: 0.04646, LR: 9.05e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 20: 100%|██████████| 40/40 [00:03<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00254, Color Loss: 0.05736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Avg Loss: 0.00196, Color Loss: 0.04586, LR: 8.95e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 21: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00250, Color Loss: 0.05665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.43it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.20it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.86it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.97it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 22: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Avg Loss: 0.00198, Color Loss: 0.04608, LR: 8.85e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 22: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00243, Color Loss: 0.05603\n",
      "New best model saved with val loss 0.00243 and color loss 0.05603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Avg Loss: 0.00205, Color Loss: 0.04714, LR: 8.75e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 23: 100%|██████████| 40/40 [00:03<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00247, Color Loss: 0.05620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Avg Loss: 0.00176, Color Loss: 0.04277, LR: 8.64e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 24: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00245, Color Loss: 0.05584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Avg Loss: 0.00187, Color Loss: 0.04432, LR: 8.54e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 25: 100%|██████████| 40/40 [00:03<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00253, Color Loss: 0.05730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 - Avg Loss: 0.00204, Color Loss: 0.04718, LR: 8.42e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 26: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00241, Color Loss: 0.05552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.22it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.68it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.31it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.68it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val loss 0.00241 and color loss 0.05552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 - Avg Loss: 0.00206, Color Loss: 0.04704, LR: 8.31e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 27: 100%|██████████| 40/40 [00:03<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00245, Color Loss: 0.05564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 - Avg Loss: 0.00184, Color Loss: 0.04325, LR: 8.19e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 28: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00255, Color Loss: 0.05743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 - Avg Loss: 0.00170, Color Loss: 0.04131, LR: 8.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 29: 100%|██████████| 40/40 [00:03<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00243, Color Loss: 0.05567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Avg Loss: 0.00194, Color Loss: 0.04518, LR: 7.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 30: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00244, Color Loss: 0.05587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 - Avg Loss: 0.00163, Color Loss: 0.04002, LR: 7.81e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 31: 100%|██████████| 40/40 [00:03<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00245, Color Loss: 0.05590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.48it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.64it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.90it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.60it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 32: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 - Avg Loss: 0.00153, Color Loss: 0.03837, LR: 7.68e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 32: 100%|██████████| 40/40 [00:03<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00235, Color Loss: 0.05404\n",
      "New best model saved with val loss 0.00235 and color loss 0.05404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 - Avg Loss: 0.00162, Color Loss: 0.03987, LR: 7.55e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 33: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00239, Color Loss: 0.05502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 - Avg Loss: 0.00155, Color Loss: 0.03850, LR: 7.41e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 34: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00239, Color Loss: 0.05514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 - Avg Loss: 0.00166, Color Loss: 0.04022, LR: 7.27e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 35: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00231, Color Loss: 0.05404\n",
      "New best model saved with val loss 0.00231 and color loss 0.05404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 - Avg Loss: 0.00155, Color Loss: 0.03839, LR: 7.13e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 36: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00237, Color Loss: 0.05476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.80it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.97it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.91it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.96it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 37: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 - Avg Loss: 0.00141, Color Loss: 0.03598, LR: 6.99e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 37: 100%|██████████| 40/40 [00:03<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00236, Color Loss: 0.05487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 - Avg Loss: 0.00146, Color Loss: 0.03679, LR: 6.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 38: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00229, Color Loss: 0.05367\n",
      "New best model saved with val loss 0.00229 and color loss 0.05367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 - Avg Loss: 0.00153, Color Loss: 0.03783, LR: 6.69e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 39: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00238, Color Loss: 0.05460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 - Avg Loss: 0.00145, Color Loss: 0.03647, LR: 6.55e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 40: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00237, Color Loss: 0.05471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 - Avg Loss: 0.00138, Color Loss: 0.03509, LR: 6.39e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 41: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00236, Color Loss: 0.05458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.63it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.90it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.22it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.75it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 42: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 - Avg Loss: 0.00132, Color Loss: 0.03429, LR: 6.24e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 42: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00238, Color Loss: 0.05505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 - Avg Loss: 0.00146, Color Loss: 0.03681, LR: 6.09e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 43: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00238, Color Loss: 0.05466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 - Avg Loss: 0.00137, Color Loss: 0.03491, LR: 5.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 44: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00234, Color Loss: 0.05441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 - Avg Loss: 0.00155, Color Loss: 0.03820, LR: 5.78e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 45: 100%|██████████| 40/40 [00:03<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00230, Color Loss: 0.05353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 - Avg Loss: 0.00138, Color Loss: 0.03549, LR: 5.63e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 46: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00235, Color Loss: 0.05441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.16it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.03it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.93it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.07it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 47: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 - Avg Loss: 0.00147, Color Loss: 0.03671, LR: 5.47e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 47: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00231, Color Loss: 0.05375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 - Avg Loss: 0.00137, Color Loss: 0.03503, LR: 5.31e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 48: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00237, Color Loss: 0.05482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 - Avg Loss: 0.00133, Color Loss: 0.03430, LR: 5.16e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 49: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00239, Color Loss: 0.05476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 - Avg Loss: 0.00157, Color Loss: 0.03856, LR: 5.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 50: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00236, Color Loss: 0.05426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 - Avg Loss: 0.00150, Color Loss: 0.03714, LR: 4.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 51: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00237, Color Loss: 0.05472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.55it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.34it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.36it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.57it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 52: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 - Avg Loss: 0.00124, Color Loss: 0.03302, LR: 4.69e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 52: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00232, Color Loss: 0.05373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 - Avg Loss: 0.00139, Color Loss: 0.03513, LR: 4.53e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 53: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00233, Color Loss: 0.05382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 - Avg Loss: 0.00137, Color Loss: 0.03519, LR: 4.37e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 54: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00233, Color Loss: 0.05397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 - Avg Loss: 0.00138, Color Loss: 0.03527, LR: 4.22e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 55: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00230, Color Loss: 0.05344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 - Avg Loss: 0.00129, Color Loss: 0.03363, LR: 4.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 56: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00228, Color Loss: 0.05300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.32it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.37it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.25it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.46it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val loss 0.00228 and color loss 0.05300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 57: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 - Avg Loss: 0.00133, Color Loss: 0.03424, LR: 3.91e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 57: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00231, Color Loss: 0.05353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 58: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 - Avg Loss: 0.00139, Color Loss: 0.03541, LR: 3.76e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 58: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00232, Color Loss: 0.05349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 59: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 - Avg Loss: 0.00162, Color Loss: 0.03908, LR: 3.61e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 59: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00231, Color Loss: 0.05375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 60: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 - Avg Loss: 0.00135, Color Loss: 0.03502, LR: 3.45e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 60: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00237, Color Loss: 0.05442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 61: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 - Avg Loss: 0.00147, Color Loss: 0.03656, LR: 3.31e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 61: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00236, Color Loss: 0.05442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 97.25it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.49it/s]\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 97.72it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 97.94it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 62: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 - Avg Loss: 0.00137, Color Loss: 0.03509, LR: 3.16e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 62: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00232, Color Loss: 0.05356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 63: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 - Avg Loss: 0.00137, Color Loss: 0.03495, LR: 3.01e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 63: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00227, Color Loss: 0.05308\n",
      "New best model saved with val loss 0.00227 and color loss 0.05308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 64: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 - Avg Loss: 0.00131, Color Loss: 0.03401, LR: 2.87e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 64: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00234, Color Loss: 0.05369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 65: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 - Avg Loss: 0.00132, Color Loss: 0.03430, LR: 2.73e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 65: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00234, Color Loss: 0.05412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 66: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 - Avg Loss: 0.00138, Color Loss: 0.03511, LR: 2.59e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 66: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00229, Color Loss: 0.05322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.27it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.86it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.07it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.27it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 67: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 - Avg Loss: 0.00142, Color Loss: 0.03571, LR: 2.45e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 67: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00229, Color Loss: 0.05339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 68: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 - Avg Loss: 0.00151, Color Loss: 0.03720, LR: 2.32e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 68: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00229, Color Loss: 0.05330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 69: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 - Avg Loss: 0.00136, Color Loss: 0.03468, LR: 2.19e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 69: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00232, Color Loss: 0.05333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 70: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 - Avg Loss: 0.00141, Color Loss: 0.03569, LR: 2.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 70: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00232, Color Loss: 0.05333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 71: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 - Avg Loss: 0.00142, Color Loss: 0.03574, LR: 1.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 71: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00233, Color Loss: 0.05407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.12it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.35it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.57it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.44it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 72: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 - Avg Loss: 0.00129, Color Loss: 0.03358, LR: 1.81e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 72: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00233, Color Loss: 0.05371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 73: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 - Avg Loss: 0.00141, Color Loss: 0.03562, LR: 1.69e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 73: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00230, Color Loss: 0.05333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 74: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 - Avg Loss: 0.00132, Color Loss: 0.03393, LR: 1.58e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 74: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00231, Color Loss: 0.05351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 75: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 - Avg Loss: 0.00127, Color Loss: 0.03307, LR: 1.46e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 75: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00229, Color Loss: 0.05322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 76: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 - Avg Loss: 0.00128, Color Loss: 0.03376, LR: 1.36e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 76: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00230, Color Loss: 0.05330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.80it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.50it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.93it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.91it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 77: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 - Avg Loss: 0.00135, Color Loss: 0.03439, LR: 1.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 77: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00227, Color Loss: 0.05293\n",
      "New best model saved with val loss 0.00227 and color loss 0.05293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 78: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 - Avg Loss: 0.00134, Color Loss: 0.03418, LR: 1.15e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 78: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00225, Color Loss: 0.05272\n",
      "New best model saved with val loss 0.00225 and color loss 0.05272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 79: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 - Avg Loss: 0.00128, Color Loss: 0.03342, LR: 1.05e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 79: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00226, Color Loss: 0.05275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 80: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 - Avg Loss: 0.00134, Color Loss: 0.03437, LR: 9.55e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 80: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00226, Color Loss: 0.05268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 81: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 - Avg Loss: 0.00126, Color Loss: 0.03292, LR: 8.65e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 81: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00224, Color Loss: 0.05246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.03it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.05it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.51it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.91it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val loss 0.00224 and color loss 0.05246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 82: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 - Avg Loss: 0.00121, Color Loss: 0.03211, LR: 7.78e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 82: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00233, Color Loss: 0.05377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 83: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 - Avg Loss: 0.00138, Color Loss: 0.03491, LR: 6.96e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 83: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05167\n",
      "New best model saved with val loss 0.00222 and color loss 0.05167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 84: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 - Avg Loss: 0.00126, Color Loss: 0.03297, LR: 6.18e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 84: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00231, Color Loss: 0.05309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 85: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 - Avg Loss: 0.00132, Color Loss: 0.03402, LR: 5.45e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 85: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00227, Color Loss: 0.05280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 86: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 - Avg Loss: 0.00149, Color Loss: 0.03687, LR: 4.76e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 86: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00226, Color Loss: 0.05313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.83it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.94it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.95it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.72it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 87: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 - Avg Loss: 0.00139, Color Loss: 0.03509, LR: 4.11e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 87: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00232, Color Loss: 0.05334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 88: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 - Avg Loss: 0.00129, Color Loss: 0.03375, LR: 3.51e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 88: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00230, Color Loss: 0.05333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 89: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 - Avg Loss: 0.00132, Color Loss: 0.03400, LR: 2.96e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 89: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00227, Color Loss: 0.05300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 90: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 - Avg Loss: 0.00149, Color Loss: 0.03686, LR: 2.45e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 90: 100%|██████████| 40/40 [00:03<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00223, Color Loss: 0.05232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 91: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 - Avg Loss: 0.00126, Color Loss: 0.03296, LR: 1.99e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 91: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00228, Color Loss: 0.05314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.89it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.22it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 96.99it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.12it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 92: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 - Avg Loss: 0.00136, Color Loss: 0.03473, LR: 1.57e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 92: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00236, Color Loss: 0.05432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 93: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 - Avg Loss: 0.00133, Color Loss: 0.03406, LR: 1.20e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 93: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00228, Color Loss: 0.05323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 94: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 - Avg Loss: 0.00140, Color Loss: 0.03515, LR: 8.86e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 94: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00230, Color Loss: 0.05314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 95: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 - Avg Loss: 0.00146, Color Loss: 0.03631, LR: 6.16e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 95: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00229, Color Loss: 0.05315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 96: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 - Avg Loss: 0.00130, Color Loss: 0.03375, LR: 3.94e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 96: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00225, Color Loss: 0.05254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.88it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.88it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.36it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.73it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 97: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 - Avg Loss: 0.00132, Color Loss: 0.03400, LR: 2.22e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 97: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00233, Color Loss: 0.05366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 98: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 - Avg Loss: 0.00128, Color Loss: 0.03310, LR: 9.87e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 98: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00229, Color Loss: 0.05304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 99: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 - Avg Loss: 0.00139, Color Loss: 0.03523, LR: 2.47e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 99: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00225, Color Loss: 0.05254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 100: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 - Avg Loss: 0.00133, Color Loss: 0.03424, LR: 1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 100: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00234, Color Loss: 0.05377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 101: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101 - Avg Loss: 0.00147, Color Loss: 0.03683, LR: 1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 101: 100%|██████████| 40/40 [00:03<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00234, Color Loss: 0.05392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.28it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 97.56it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.86it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.61it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 102: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 - Avg Loss: 0.00143, Color Loss: 0.03599, LR: 1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 102: 100%|██████████| 40/40 [00:03<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00234, Color Loss: 0.05432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 103: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103 - Avg Loss: 0.00140, Color Loss: 0.03558, LR: 9.99e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 103: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00225, Color Loss: 0.05266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 104: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104 - Avg Loss: 0.00131, Color Loss: 0.03388, LR: 9.99e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 104: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00230, Color Loss: 0.05326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 105: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 - Avg Loss: 0.00136, Color Loss: 0.03464, LR: 9.98e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 105: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00229, Color Loss: 0.05332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 106: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106 - Avg Loss: 0.00145, Color Loss: 0.03631, LR: 9.98e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 106: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00231, Color Loss: 0.05395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.03it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.20it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.52it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.22it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 107: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107 - Avg Loss: 0.00145, Color Loss: 0.03624, LR: 9.97e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 107: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00230, Color Loss: 0.05352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 108: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108 - Avg Loss: 0.00149, Color Loss: 0.03698, LR: 9.96e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 108: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00228, Color Loss: 0.05307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 109: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 - Avg Loss: 0.00145, Color Loss: 0.03626, LR: 9.95e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 109: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00228, Color Loss: 0.05289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 110: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 - Avg Loss: 0.00144, Color Loss: 0.03609, LR: 9.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 110: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00230, Color Loss: 0.05314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 111: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111 - Avg Loss: 0.00130, Color Loss: 0.03373, LR: 9.93e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 111: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00231, Color Loss: 0.05354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.23it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.35it/s] \n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.23it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.42it/s] \n",
      "Training Epoch 112: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 - Avg Loss: 0.00156, Color Loss: 0.03792, LR: 9.91e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 112: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00233, Color Loss: 0.05380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 113: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113 - Avg Loss: 0.00130, Color Loss: 0.03377, LR: 9.90e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 113: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00234, Color Loss: 0.05383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 114: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114 - Avg Loss: 0.00142, Color Loss: 0.03567, LR: 9.88e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 114: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00226, Color Loss: 0.05247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 115: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 - Avg Loss: 0.00141, Color Loss: 0.03564, LR: 9.86e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 115: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00228, Color Loss: 0.05312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 116: 100%|██████████| 313/313 [00:56<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116 - Avg Loss: 0.00141, Color Loss: 0.03578, LR: 9.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 116: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00228, Color Loss: 0.05241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.70it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.53it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.94it/s]\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.27it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 117: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117 - Avg Loss: 0.00149, Color Loss: 0.03695, LR: 9.82e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 117: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00223, Color Loss: 0.05234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 118: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118 - Avg Loss: 0.00134, Color Loss: 0.03408, LR: 9.80e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 118: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00228, Color Loss: 0.05272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 119: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 - Avg Loss: 0.00144, Color Loss: 0.03594, LR: 9.78e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 119: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00236, Color Loss: 0.05374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 120: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120 - Avg Loss: 0.00114, Color Loss: 0.03088, LR: 9.76e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 120: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00228, Color Loss: 0.05310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 121: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121 - Avg Loss: 0.00137, Color Loss: 0.03503, LR: 9.73e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 121: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00226, Color Loss: 0.05307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.45it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.08it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.35it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.44it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 122: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 - Avg Loss: 0.00133, Color Loss: 0.03397, LR: 9.70e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 122: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00224, Color Loss: 0.05242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 123: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123 - Avg Loss: 0.00132, Color Loss: 0.03388, LR: 9.68e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 123: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00234, Color Loss: 0.05396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 124: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124 - Avg Loss: 0.00166, Color Loss: 0.03971, LR: 9.65e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 124: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05155\n",
      "New best model saved with val loss 0.00222 and color loss 0.05155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 125: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 - Avg Loss: 0.00132, Color Loss: 0.03382, LR: 9.62e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 125: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00223, Color Loss: 0.05223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 126: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126 - Avg Loss: 0.00123, Color Loss: 0.03238, LR: 9.59e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 126: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00223, Color Loss: 0.05224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.28it/s] \n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.48it/s] \n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.43it/s]\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.02it/s] \n",
      "Training Epoch 127: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127 - Avg Loss: 0.00127, Color Loss: 0.03327, LR: 9.56e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 127: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00226, Color Loss: 0.05281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 128: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128 - Avg Loss: 0.00136, Color Loss: 0.03464, LR: 9.52e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 128: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00225, Color Loss: 0.05249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 129: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 - Avg Loss: 0.00144, Color Loss: 0.03600, LR: 9.49e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 129: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00230, Color Loss: 0.05327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 130: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130 - Avg Loss: 0.00138, Color Loss: 0.03486, LR: 9.46e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 130: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00223, Color Loss: 0.05260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 131: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131 - Avg Loss: 0.00148, Color Loss: 0.03676, LR: 9.42e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 131: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.67it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.09it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.88it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.25it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val loss 0.00220 and color loss 0.05174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 132: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 - Avg Loss: 0.00131, Color Loss: 0.03384, LR: 9.38e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 132: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00228, Color Loss: 0.05262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 133: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133 - Avg Loss: 0.00129, Color Loss: 0.03340, LR: 9.34e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 133: 100%|██████████| 40/40 [00:03<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00233, Color Loss: 0.05333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 134: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134 - Avg Loss: 0.00133, Color Loss: 0.03410, LR: 9.30e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 134: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 135: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 - Avg Loss: 0.00149, Color Loss: 0.03688, LR: 9.26e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 135: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00234, Color Loss: 0.05386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 136: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136 - Avg Loss: 0.00138, Color Loss: 0.03489, LR: 9.22e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 136: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.68it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.30it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.36it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.19it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 137: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137 - Avg Loss: 0.00133, Color Loss: 0.03385, LR: 9.18e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 137: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00226, Color Loss: 0.05223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 138: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138 - Avg Loss: 0.00131, Color Loss: 0.03379, LR: 9.14e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 138: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 139: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 - Avg Loss: 0.00129, Color Loss: 0.03346, LR: 9.09e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 139: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00225, Color Loss: 0.05236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 140: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140 - Avg Loss: 0.00138, Color Loss: 0.03466, LR: 9.05e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 140: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00231, Color Loss: 0.05287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 141: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141 - Avg Loss: 0.00126, Color Loss: 0.03278, LR: 9.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 141: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00225, Color Loss: 0.05275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.67it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.27it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.26it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.15it/s]\n",
      "Training Epoch 142: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 - Avg Loss: 0.00128, Color Loss: 0.03308, LR: 8.95e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 142: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00231, Color Loss: 0.05322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 143: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143 - Avg Loss: 0.00125, Color Loss: 0.03275, LR: 8.90e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 143: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00223, Color Loss: 0.05180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 144: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144 - Avg Loss: 0.00126, Color Loss: 0.03269, LR: 8.85e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 144: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00226, Color Loss: 0.05245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 145: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145 - Avg Loss: 0.00136, Color Loss: 0.03449, LR: 8.80e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 145: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00230, Color Loss: 0.05353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 146: 100%|██████████| 313/313 [00:56<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146 - Avg Loss: 0.00139, Color Loss: 0.03509, LR: 8.75e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 146: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.06it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.59it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.41it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.30it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val loss 0.00219 and color loss 0.05101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 147: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147 - Avg Loss: 0.00129, Color Loss: 0.03323, LR: 8.70e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 147: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 148: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148 - Avg Loss: 0.00138, Color Loss: 0.03492, LR: 8.64e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 148: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 149: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 - Avg Loss: 0.00131, Color Loss: 0.03409, LR: 8.59e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 149: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 150: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 - Avg Loss: 0.00130, Color Loss: 0.03363, LR: 8.54e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 150: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00225, Color Loss: 0.05247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 151: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151 - Avg Loss: 0.00126, Color Loss: 0.03306, LR: 8.48e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 151: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.99it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.01it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.20it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.58it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 152: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 - Avg Loss: 0.00136, Color Loss: 0.03455, LR: 8.42e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 152: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00224, Color Loss: 0.05231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 153: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153 - Avg Loss: 0.00125, Color Loss: 0.03298, LR: 8.37e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 153: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00227, Color Loss: 0.05280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 154: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154 - Avg Loss: 0.00135, Color Loss: 0.03443, LR: 8.31e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 154: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 155: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155 - Avg Loss: 0.00120, Color Loss: 0.03172, LR: 8.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 155: 100%|██████████| 40/40 [00:03<00:00, 11.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00223, Color Loss: 0.05188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 156: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156 - Avg Loss: 0.00122, Color Loss: 0.03198, LR: 8.19e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 156: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00224, Color Loss: 0.05246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.16it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.40it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.24it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.35it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 157: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157 - Avg Loss: 0.00140, Color Loss: 0.03539, LR: 8.13e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 157: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00225, Color Loss: 0.05240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 158: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158 - Avg Loss: 0.00128, Color Loss: 0.03335, LR: 8.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 158: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 159: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159 - Avg Loss: 0.00123, Color Loss: 0.03201, LR: 8.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 159: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 160: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160 - Avg Loss: 0.00130, Color Loss: 0.03343, LR: 7.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 160: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00223, Color Loss: 0.05204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 161: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161 - Avg Loss: 0.00146, Color Loss: 0.03621, LR: 7.88e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 161: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.71it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.21it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.46it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 97.87it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val loss 0.00217 and color loss 0.05117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 162: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162 - Avg Loss: 0.00124, Color Loss: 0.03243, LR: 7.81e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 162: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00224, Color Loss: 0.05217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 163: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163 - Avg Loss: 0.00143, Color Loss: 0.03560, LR: 7.75e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 163: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05114\n",
      "New best model saved with val loss 0.00217 and color loss 0.05114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 164: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164 - Avg Loss: 0.00120, Color Loss: 0.03170, LR: 7.68e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 164: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00232, Color Loss: 0.05304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 165: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165 - Avg Loss: 0.00131, Color Loss: 0.03369, LR: 7.61e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 165: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05099\n",
      "New best model saved with val loss 0.00216 and color loss 0.05099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 166: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166 - Avg Loss: 0.00138, Color Loss: 0.03463, LR: 7.55e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 166: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.69it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.77it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.02it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.99it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 167: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167 - Avg Loss: 0.00133, Color Loss: 0.03380, LR: 7.48e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 167: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00223, Color Loss: 0.05217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 168: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168 - Avg Loss: 0.00129, Color Loss: 0.03317, LR: 7.41e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 168: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 169: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169 - Avg Loss: 0.00136, Color Loss: 0.03436, LR: 7.34e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 169: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 170: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170 - Avg Loss: 0.00132, Color Loss: 0.03396, LR: 7.27e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 170: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 171: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171 - Avg Loss: 0.00124, Color Loss: 0.03232, LR: 7.20e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 171: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00224, Color Loss: 0.05183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.76it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.65it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 100.00it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.98it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 172: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172 - Avg Loss: 0.00115, Color Loss: 0.03089, LR: 7.13e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 172: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 173: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173 - Avg Loss: 0.00130, Color Loss: 0.03325, LR: 7.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 173: 100%|██████████| 40/40 [00:03<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 174: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174 - Avg Loss: 0.00131, Color Loss: 0.03331, LR: 6.99e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 174: 100%|██████████| 40/40 [00:03<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 175: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175 - Avg Loss: 0.00129, Color Loss: 0.03315, LR: 6.91e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 175: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 176: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176 - Avg Loss: 0.00132, Color Loss: 0.03383, LR: 6.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 176: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00224, Color Loss: 0.05195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.01it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.78it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.94it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.19it/s] \n",
      "Training Epoch 177: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177 - Avg Loss: 0.00129, Color Loss: 0.03332, LR: 6.77e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 177: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 178: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178 - Avg Loss: 0.00125, Color Loss: 0.03267, LR: 6.69e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 178: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 179: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179 - Avg Loss: 0.00125, Color Loss: 0.03251, LR: 6.62e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 179: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05101\n",
      "New best model saved with val loss 0.00215 and color loss 0.05101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 180: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180 - Avg Loss: 0.00139, Color Loss: 0.03510, LR: 6.55e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 180: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 181: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181 - Avg Loss: 0.00126, Color Loss: 0.03268, LR: 6.47e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 181: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.50it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.39it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.65it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.29it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 182: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182 - Avg Loss: 0.00148, Color Loss: 0.03652, LR: 6.39e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 182: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 183: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183 - Avg Loss: 0.00136, Color Loss: 0.03449, LR: 6.32e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 183: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 184: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184 - Avg Loss: 0.00117, Color Loss: 0.03123, LR: 6.24e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 184: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 185: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185 - Avg Loss: 0.00137, Color Loss: 0.03468, LR: 6.17e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 185: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 186: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186 - Avg Loss: 0.00127, Color Loss: 0.03270, LR: 6.09e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 186: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.24it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.68it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.67it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.50it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 187: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187 - Avg Loss: 0.00125, Color Loss: 0.03246, LR: 6.01e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 187: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05065\n",
      "New best model saved with val loss 0.00215 and color loss 0.05065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 188: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188 - Avg Loss: 0.00133, Color Loss: 0.03382, LR: 5.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 188: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 189: 100%|██████████| 313/313 [00:56<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189 - Avg Loss: 0.00123, Color Loss: 0.03230, LR: 5.86e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 189: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00224, Color Loss: 0.05240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 190: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190 - Avg Loss: 0.00138, Color Loss: 0.03499, LR: 5.78e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 190: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 191: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191 - Avg Loss: 0.00125, Color Loss: 0.03251, LR: 5.70e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 191: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.05it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.16it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.26it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.33it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 192: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 - Avg Loss: 0.00145, Color Loss: 0.03575, LR: 5.63e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 192: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 193: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193 - Avg Loss: 0.00141, Color Loss: 0.03542, LR: 5.55e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 193: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 194: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194 - Avg Loss: 0.00129, Color Loss: 0.03301, LR: 5.47e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 194: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 195: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195 - Avg Loss: 0.00145, Color Loss: 0.03618, LR: 5.39e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 195: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 196: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196 - Avg Loss: 0.00130, Color Loss: 0.03334, LR: 5.31e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 196: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.42it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.38it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.79it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.74it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 197: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197 - Avg Loss: 0.00127, Color Loss: 0.03300, LR: 5.24e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 197: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 198: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198 - Avg Loss: 0.00127, Color Loss: 0.03283, LR: 5.16e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 198: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00213, Color Loss: 0.05044\n",
      "New best model saved with val loss 0.00213 and color loss 0.05044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 199: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199 - Avg Loss: 0.00129, Color Loss: 0.03311, LR: 5.08e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 199: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00223, Color Loss: 0.05190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 200: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200 - Avg Loss: 0.00138, Color Loss: 0.03462, LR: 5.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 200: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 201: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201 - Avg Loss: 0.00120, Color Loss: 0.03152, LR: 4.92e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 201: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.04it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.25it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.51it/s]\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.86it/s] \n",
      "Training Epoch 202: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202 - Avg Loss: 0.00133, Color Loss: 0.03385, LR: 4.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 202: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 203: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203 - Avg Loss: 0.00124, Color Loss: 0.03233, LR: 4.76e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 203: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 204: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204 - Avg Loss: 0.00125, Color Loss: 0.03260, LR: 4.69e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 204: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 205: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205 - Avg Loss: 0.00136, Color Loss: 0.03435, LR: 4.61e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 205: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 206: 100%|██████████| 313/313 [00:57<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206 - Avg Loss: 0.00147, Color Loss: 0.03610, LR: 4.53e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 206: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.48it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.74it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.33it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.75it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 207: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207 - Avg Loss: 0.00124, Color Loss: 0.03238, LR: 4.45e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 207: 100%|██████████| 40/40 [00:03<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00224, Color Loss: 0.05182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 208: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208 - Avg Loss: 0.00119, Color Loss: 0.03170, LR: 4.37e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 208: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00213, Color Loss: 0.05062\n",
      "New best model saved with val loss 0.00213 and color loss 0.05062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 209: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209 - Avg Loss: 0.00124, Color Loss: 0.03210, LR: 4.30e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 209: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 210: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210 - Avg Loss: 0.00134, Color Loss: 0.03395, LR: 4.22e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 210: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00212, Color Loss: 0.05025\n",
      "New best model saved with val loss 0.00212 and color loss 0.05025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 211: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211 - Avg Loss: 0.00132, Color Loss: 0.03378, LR: 4.14e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 211: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.43it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.38it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.49it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.52it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 212: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212 - Avg Loss: 0.00139, Color Loss: 0.03483, LR: 4.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 212: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 213: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213 - Avg Loss: 0.00126, Color Loss: 0.03260, LR: 3.99e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 213: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 214: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214 - Avg Loss: 0.00122, Color Loss: 0.03169, LR: 3.91e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 214: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00224, Color Loss: 0.05213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 215: 100%|██████████| 313/313 [00:57<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215 - Avg Loss: 0.00132, Color Loss: 0.03376, LR: 3.83e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 215: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 216: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216 - Avg Loss: 0.00127, Color Loss: 0.03280, LR: 3.76e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 216: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 97.95it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.50it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.37it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.71it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 217: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217 - Avg Loss: 0.00146, Color Loss: 0.03603, LR: 3.68e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 217: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 218: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218 - Avg Loss: 0.00130, Color Loss: 0.03354, LR: 3.61e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 218: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 219: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219 - Avg Loss: 0.00119, Color Loss: 0.03142, LR: 3.53e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 219: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 220: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220 - Avg Loss: 0.00134, Color Loss: 0.03396, LR: 3.45e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 220: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 221: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221 - Avg Loss: 0.00128, Color Loss: 0.03271, LR: 3.38e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 221: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.90it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.65it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.10it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.87it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 222: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222 - Avg Loss: 0.00127, Color Loss: 0.03283, LR: 3.31e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 222: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 223: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223 - Avg Loss: 0.00143, Color Loss: 0.03562, LR: 3.23e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 223: 100%|██████████| 40/40 [00:03<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 224: 100%|██████████| 313/313 [00:57<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224 - Avg Loss: 0.00109, Color Loss: 0.02987, LR: 3.16e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 224: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 225: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225 - Avg Loss: 0.00128, Color Loss: 0.03319, LR: 3.09e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 225: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 226: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226 - Avg Loss: 0.00132, Color Loss: 0.03360, LR: 3.01e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 226: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.55it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.93it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.36it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.68it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 227: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227 - Avg Loss: 0.00122, Color Loss: 0.03196, LR: 2.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 227: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 228: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228 - Avg Loss: 0.00122, Color Loss: 0.03183, LR: 2.87e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 228: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 229: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229 - Avg Loss: 0.00118, Color Loss: 0.03114, LR: 2.80e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 229: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 230: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230 - Avg Loss: 0.00122, Color Loss: 0.03185, LR: 2.73e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 230: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00226, Color Loss: 0.05215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 231: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231 - Avg Loss: 0.00117, Color Loss: 0.03103, LR: 2.66e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 231: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.88it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.48it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.10it/s]\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.04it/s] \n",
      "Training Epoch 232: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232 - Avg Loss: 0.00122, Color Loss: 0.03189, LR: 2.59e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 232: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 233: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233 - Avg Loss: 0.00136, Color Loss: 0.03442, LR: 2.52e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 233: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00223, Color Loss: 0.05143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 234: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234 - Avg Loss: 0.00126, Color Loss: 0.03249, LR: 2.45e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 234: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 235: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235 - Avg Loss: 0.00130, Color Loss: 0.03311, LR: 2.39e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 235: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 236: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236 - Avg Loss: 0.00130, Color Loss: 0.03339, LR: 2.32e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 236: 100%|██████████| 40/40 [00:03<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.21it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.18it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.06it/s]\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.98it/s] \n",
      "Training Epoch 237: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237 - Avg Loss: 0.00121, Color Loss: 0.03166, LR: 2.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 237: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 238: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238 - Avg Loss: 0.00125, Color Loss: 0.03226, LR: 2.19e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 238: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 239: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239 - Avg Loss: 0.00142, Color Loss: 0.03506, LR: 2.12e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 239: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 240: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240 - Avg Loss: 0.00136, Color Loss: 0.03426, LR: 2.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 240: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 241: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241 - Avg Loss: 0.00130, Color Loss: 0.03336, LR: 2.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 241: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.65it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.33it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.19it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.62it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 242: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242 - Avg Loss: 0.00131, Color Loss: 0.03334, LR: 1.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 242: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 243: 100%|██████████| 313/313 [00:57<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243 - Avg Loss: 0.00123, Color Loss: 0.03212, LR: 1.87e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 243: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 244: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244 - Avg Loss: 0.00135, Color Loss: 0.03446, LR: 1.81e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 244: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 245: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245 - Avg Loss: 0.00116, Color Loss: 0.03090, LR: 1.75e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 245: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 246: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246 - Avg Loss: 0.00132, Color Loss: 0.03351, LR: 1.69e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 246: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.22it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.57it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.49it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.04it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 247: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247 - Avg Loss: 0.00111, Color Loss: 0.02971, LR: 1.63e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 247: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 248: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248 - Avg Loss: 0.00139, Color Loss: 0.03460, LR: 1.58e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 248: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 249: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249 - Avg Loss: 0.00133, Color Loss: 0.03385, LR: 1.52e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 249: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 250: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250 - Avg Loss: 0.00132, Color Loss: 0.03374, LR: 1.46e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 250: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00213, Color Loss: 0.05044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 251: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251 - Avg Loss: 0.00134, Color Loss: 0.03411, LR: 1.41e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 251: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.60it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.89it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.90it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.23it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 252: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252 - Avg Loss: 0.00132, Color Loss: 0.03380, LR: 1.36e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 252: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 253: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253 - Avg Loss: 0.00120, Color Loss: 0.03137, LR: 1.30e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 253: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 254: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254 - Avg Loss: 0.00154, Color Loss: 0.03732, LR: 1.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 254: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 255: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255 - Avg Loss: 0.00137, Color Loss: 0.03466, LR: 1.20e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 255: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 256: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256 - Avg Loss: 0.00127, Color Loss: 0.03249, LR: 1.15e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 256: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.62it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.44it/s] \n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.51it/s]\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 97.99it/s]\n",
      "Training Epoch 257: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257 - Avg Loss: 0.00131, Color Loss: 0.03346, LR: 1.10e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 257: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 258: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258 - Avg Loss: 0.00124, Color Loss: 0.03230, LR: 1.05e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 258: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 259: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259 - Avg Loss: 0.00119, Color Loss: 0.03134, LR: 1.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 259: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 260: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260 - Avg Loss: 0.00138, Color Loss: 0.03449, LR: 9.55e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 260: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00210, Color Loss: 0.04984\n",
      "New best model saved with val loss 0.00210 and color loss 0.04984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 261: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261 - Avg Loss: 0.00130, Color Loss: 0.03336, LR: 9.09e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 261: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.69it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.06it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.24it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.72it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 262: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262 - Avg Loss: 0.00118, Color Loss: 0.03129, LR: 8.65e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 262: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 263: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263 - Avg Loss: 0.00135, Color Loss: 0.03406, LR: 8.21e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 263: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 264: 100%|██████████| 313/313 [00:57<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264 - Avg Loss: 0.00122, Color Loss: 0.03201, LR: 7.78e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 264: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 265: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265 - Avg Loss: 0.00138, Color Loss: 0.03472, LR: 7.37e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 265: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 266: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266 - Avg Loss: 0.00135, Color Loss: 0.03399, LR: 6.96e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 266: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00213, Color Loss: 0.05033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.10it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.04it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.18it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.26it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 267: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267 - Avg Loss: 0.00128, Color Loss: 0.03278, LR: 6.57e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 267: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 268: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268 - Avg Loss: 0.00117, Color Loss: 0.03092, LR: 6.18e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 268: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 269: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269 - Avg Loss: 0.00125, Color Loss: 0.03248, LR: 5.81e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 269: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 270: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270 - Avg Loss: 0.00123, Color Loss: 0.03208, LR: 5.45e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 270: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 271: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271 - Avg Loss: 0.00138, Color Loss: 0.03474, LR: 5.10e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 271: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.23it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.47it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.38it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.53it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 272: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272 - Avg Loss: 0.00126, Color Loss: 0.03239, LR: 4.76e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 272: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00213, Color Loss: 0.05050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 273: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273 - Avg Loss: 0.00121, Color Loss: 0.03171, LR: 4.43e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 273: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 274: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274 - Avg Loss: 0.00128, Color Loss: 0.03273, LR: 4.11e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 274: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 275: 100%|██████████| 313/313 [00:57<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275 - Avg Loss: 0.00116, Color Loss: 0.03097, LR: 3.81e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 275: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 276: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276 - Avg Loss: 0.00119, Color Loss: 0.03112, LR: 3.51e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 276: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.69it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.39it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.37it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.61it/s]\n",
      "Training Epoch 277: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277 - Avg Loss: 0.00123, Color Loss: 0.03222, LR: 3.23e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 277: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 278: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278 - Avg Loss: 0.00137, Color Loss: 0.03448, LR: 2.96e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 278: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 279: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279 - Avg Loss: 0.00115, Color Loss: 0.03041, LR: 2.70e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 279: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 280: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280 - Avg Loss: 0.00126, Color Loss: 0.03243, LR: 2.45e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 280: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00213, Color Loss: 0.05020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 281: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281 - Avg Loss: 0.00121, Color Loss: 0.03165, LR: 2.21e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 281: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.75it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.26it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.94it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.61it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 282: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282 - Avg Loss: 0.00129, Color Loss: 0.03320, LR: 1.99e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 282: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00213, Color Loss: 0.05018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 283: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283 - Avg Loss: 0.00113, Color Loss: 0.03046, LR: 1.77e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 283: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 284: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284 - Avg Loss: 0.00115, Color Loss: 0.03075, LR: 1.57e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 284: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 285: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285 - Avg Loss: 0.00124, Color Loss: 0.03218, LR: 1.38e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 285: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 286: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286 - Avg Loss: 0.00118, Color Loss: 0.03099, LR: 1.20e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 286: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00212, Color Loss: 0.05015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.81it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.17it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.23it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.06it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 287: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287 - Avg Loss: 0.00149, Color Loss: 0.03629, LR: 1.04e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 287: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 288: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288 - Avg Loss: 0.00133, Color Loss: 0.03392, LR: 8.86e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 288: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 289: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289 - Avg Loss: 0.00140, Color Loss: 0.03503, LR: 7.45e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 289: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 290: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290 - Avg Loss: 0.00133, Color Loss: 0.03371, LR: 6.16e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 290: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 291: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291 - Avg Loss: 0.00127, Color Loss: 0.03253, LR: 4.99e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 291: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.31it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.35it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.78it/s]\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.45it/s] \n",
      "Training Epoch 292: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292 - Avg Loss: 0.00124, Color Loss: 0.03202, LR: 3.94e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 292: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 293: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293 - Avg Loss: 0.00135, Color Loss: 0.03412, LR: 3.02e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 293: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 294: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294 - Avg Loss: 0.00112, Color Loss: 0.02978, LR: 2.22e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 294: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 295: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295 - Avg Loss: 0.00119, Color Loss: 0.03121, LR: 1.54e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 295: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 296: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296 - Avg Loss: 0.00115, Color Loss: 0.03058, LR: 9.87e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 296: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.95it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.95it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.61it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.36it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 297: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297 - Avg Loss: 0.00118, Color Loss: 0.03110, LR: 5.55e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 297: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 298: 100%|██████████| 313/313 [00:57<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298 - Avg Loss: 0.00122, Color Loss: 0.03172, LR: 2.47e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 298: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 299: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299 - Avg Loss: 0.00147, Color Loss: 0.03613, LR: 6.17e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 299: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 300: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300 - Avg Loss: 0.00116, Color Loss: 0.03076, LR: 1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 300: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 301: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301 - Avg Loss: 0.00145, Color Loss: 0.03577, LR: 1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 301: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.20it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.48it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.89it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.62it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 302: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302 - Avg Loss: 0.00135, Color Loss: 0.03420, LR: 1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 302: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 303: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303 - Avg Loss: 0.00126, Color Loss: 0.03306, LR: 1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 303: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 304: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304 - Avg Loss: 0.00140, Color Loss: 0.03536, LR: 1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 304: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 305: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305 - Avg Loss: 0.00126, Color Loss: 0.03261, LR: 1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 305: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 306: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306 - Avg Loss: 0.00122, Color Loss: 0.03204, LR: 9.99e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 306: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00223, Color Loss: 0.05177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.37it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.10it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.06it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.27it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 307: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307 - Avg Loss: 0.00130, Color Loss: 0.03355, LR: 9.99e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 307: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 308: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308 - Avg Loss: 0.00128, Color Loss: 0.03294, LR: 9.99e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 308: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 309: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309 - Avg Loss: 0.00140, Color Loss: 0.03509, LR: 9.99e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 309: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 310: 100%|██████████| 313/313 [00:56<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310 - Avg Loss: 0.00112, Color Loss: 0.03017, LR: 9.98e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 310: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 311: 100%|██████████| 313/313 [00:57<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311 - Avg Loss: 0.00123, Color Loss: 0.03200, LR: 9.98e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 311: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 97.78it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.77it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.79it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.52it/s]\n",
      "Training Epoch 312: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312 - Avg Loss: 0.00132, Color Loss: 0.03348, LR: 9.98e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 312: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00224, Color Loss: 0.05187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 313: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313 - Avg Loss: 0.00142, Color Loss: 0.03532, LR: 9.97e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 313: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 314: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314 - Avg Loss: 0.00131, Color Loss: 0.03339, LR: 9.97e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 314: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 315: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315 - Avg Loss: 0.00127, Color Loss: 0.03280, LR: 9.97e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 315: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 316: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316 - Avg Loss: 0.00133, Color Loss: 0.03357, LR: 9.96e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 316: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.09it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.31it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.75it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.43it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 317: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317 - Avg Loss: 0.00123, Color Loss: 0.03211, LR: 9.96e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 317: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 318: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318 - Avg Loss: 0.00130, Color Loss: 0.03319, LR: 9.95e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 318: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 319: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319 - Avg Loss: 0.00121, Color Loss: 0.03157, LR: 9.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 319: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 320: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320 - Avg Loss: 0.00125, Color Loss: 0.03236, LR: 9.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 320: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 321: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321 - Avg Loss: 0.00129, Color Loss: 0.03319, LR: 9.93e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 321: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00223, Color Loss: 0.05194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.49it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.97it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.84it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.82it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 322: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322 - Avg Loss: 0.00128, Color Loss: 0.03272, LR: 9.93e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 322: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 323: 100%|██████████| 313/313 [00:57<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323 - Avg Loss: 0.00147, Color Loss: 0.03589, LR: 9.92e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 323: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00223, Color Loss: 0.05191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 324: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324 - Avg Loss: 0.00115, Color Loss: 0.03060, LR: 9.91e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 324: 100%|██████████| 40/40 [00:03<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 325: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325 - Avg Loss: 0.00129, Color Loss: 0.03302, LR: 9.90e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 325: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 326: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326 - Avg Loss: 0.00121, Color Loss: 0.03168, LR: 9.90e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 326: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.72it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.79it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.57it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.87it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 327: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327 - Avg Loss: 0.00124, Color Loss: 0.03251, LR: 9.89e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 327: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 328: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328 - Avg Loss: 0.00136, Color Loss: 0.03442, LR: 9.88e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 328: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 329: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329 - Avg Loss: 0.00107, Color Loss: 0.02933, LR: 9.87e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 329: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 330: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330 - Avg Loss: 0.00141, Color Loss: 0.03529, LR: 9.86e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 330: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 331: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331 - Avg Loss: 0.00126, Color Loss: 0.03261, LR: 9.85e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 331: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.32it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 97.83it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.08it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.98it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 332: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332 - Avg Loss: 0.00144, Color Loss: 0.03591, LR: 9.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 332: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 333: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333 - Avg Loss: 0.00131, Color Loss: 0.03359, LR: 9.83e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 333: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 334: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334 - Avg Loss: 0.00141, Color Loss: 0.03522, LR: 9.82e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 334: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 335: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335 - Avg Loss: 0.00140, Color Loss: 0.03485, LR: 9.81e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 335: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 336: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336 - Avg Loss: 0.00131, Color Loss: 0.03341, LR: 9.80e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 336: 100%|██████████| 40/40 [00:04<00:00,  9.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.60it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 100.24it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.18it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.07it/s] \n",
      "Training Epoch 337: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337 - Avg Loss: 0.00122, Color Loss: 0.03196, LR: 9.79e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 337: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 338: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338 - Avg Loss: 0.00132, Color Loss: 0.03356, LR: 9.78e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 338: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 339: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339 - Avg Loss: 0.00130, Color Loss: 0.03317, LR: 9.77e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 339: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 340: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340 - Avg Loss: 0.00125, Color Loss: 0.03237, LR: 9.76e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 340: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 341: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341 - Avg Loss: 0.00144, Color Loss: 0.03577, LR: 9.74e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 341: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.45it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 96.40it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.59it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.78it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 342: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342 - Avg Loss: 0.00126, Color Loss: 0.03256, LR: 9.73e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 342: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 343: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343 - Avg Loss: 0.00120, Color Loss: 0.03144, LR: 9.72e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 343: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 344: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344 - Avg Loss: 0.00133, Color Loss: 0.03369, LR: 9.70e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 344: 100%|██████████| 40/40 [00:03<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 345: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345 - Avg Loss: 0.00117, Color Loss: 0.03085, LR: 9.69e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 345: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 346: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346 - Avg Loss: 0.00118, Color Loss: 0.03107, LR: 9.68e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 346: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.78it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.40it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.00it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.44it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 347: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347 - Avg Loss: 0.00124, Color Loss: 0.03212, LR: 9.66e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 347: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 348: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348 - Avg Loss: 0.00128, Color Loss: 0.03285, LR: 9.65e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 348: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 349: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349 - Avg Loss: 0.00120, Color Loss: 0.03158, LR: 9.63e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 349: 100%|██████████| 40/40 [00:03<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 350: 100%|██████████| 313/313 [00:57<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350 - Avg Loss: 0.00120, Color Loss: 0.03145, LR: 9.62e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 350: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 351: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351 - Avg Loss: 0.00123, Color Loss: 0.03225, LR: 9.60e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 351: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.09it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.64it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.72it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.20it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 352: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352 - Avg Loss: 0.00119, Color Loss: 0.03149, LR: 9.59e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 352: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 353: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353 - Avg Loss: 0.00134, Color Loss: 0.03406, LR: 9.57e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 353: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 354: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354 - Avg Loss: 0.00142, Color Loss: 0.03503, LR: 9.56e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 354: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 355: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355 - Avg Loss: 0.00114, Color Loss: 0.03058, LR: 9.54e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 355: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 356: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356 - Avg Loss: 0.00126, Color Loss: 0.03271, LR: 9.52e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 356: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.25it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 97.94it/s]\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.23it/s]\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.13it/s]\n",
      "Training Epoch 357: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357 - Avg Loss: 0.00128, Color Loss: 0.03280, LR: 9.51e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 357: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 358: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358 - Avg Loss: 0.00129, Color Loss: 0.03321, LR: 9.49e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 358: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 359: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359 - Avg Loss: 0.00139, Color Loss: 0.03480, LR: 9.47e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 359: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00213, Color Loss: 0.05026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 360: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360 - Avg Loss: 0.00133, Color Loss: 0.03379, LR: 9.46e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 360: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00224, Color Loss: 0.05195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 361: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361 - Avg Loss: 0.00121, Color Loss: 0.03172, LR: 9.44e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 361: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.08it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.66it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.66it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.47it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 362: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362 - Avg Loss: 0.00122, Color Loss: 0.03180, LR: 9.42e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 362: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 363: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363 - Avg Loss: 0.00131, Color Loss: 0.03350, LR: 9.40e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 363: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 364: 100%|██████████| 313/313 [00:57<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364 - Avg Loss: 0.00139, Color Loss: 0.03460, LR: 9.38e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 364: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 365: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365 - Avg Loss: 0.00133, Color Loss: 0.03383, LR: 9.36e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 365: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 366: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366 - Avg Loss: 0.00115, Color Loss: 0.03068, LR: 9.34e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 366: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.18it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.29it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.29it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.79it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 367: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367 - Avg Loss: 0.00127, Color Loss: 0.03254, LR: 9.32e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 367: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 368: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368 - Avg Loss: 0.00129, Color Loss: 0.03291, LR: 9.30e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 368: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 369: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369 - Avg Loss: 0.00129, Color Loss: 0.03303, LR: 9.28e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 369: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00226, Color Loss: 0.05228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 370: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370 - Avg Loss: 0.00124, Color Loss: 0.03213, LR: 9.26e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 370: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 371: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371 - Avg Loss: 0.00120, Color Loss: 0.03128, LR: 9.24e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 371: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.18it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.01it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.13it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.98it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 372: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372 - Avg Loss: 0.00130, Color Loss: 0.03313, LR: 9.22e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 372: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00212, Color Loss: 0.05016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 373: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373 - Avg Loss: 0.00114, Color Loss: 0.03023, LR: 9.20e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 373: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 374: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374 - Avg Loss: 0.00142, Color Loss: 0.03525, LR: 9.18e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 374: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 375: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375 - Avg Loss: 0.00132, Color Loss: 0.03342, LR: 9.16e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 375: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 376: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376 - Avg Loss: 0.00118, Color Loss: 0.03138, LR: 9.14e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 376: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.23it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.33it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.11it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 97.66it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 377: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377 - Avg Loss: 0.00130, Color Loss: 0.03332, LR: 9.11e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 377: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 378: 100%|██████████| 313/313 [00:57<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378 - Avg Loss: 0.00135, Color Loss: 0.03400, LR: 9.09e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 378: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 379: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379 - Avg Loss: 0.00127, Color Loss: 0.03256, LR: 9.07e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 379: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 380: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380 - Avg Loss: 0.00134, Color Loss: 0.03393, LR: 9.05e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 380: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 381: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381 - Avg Loss: 0.00121, Color Loss: 0.03166, LR: 9.02e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 381: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.29it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.97it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.45it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 97.85it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 382: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382 - Avg Loss: 0.00110, Color Loss: 0.02958, LR: 9.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 382: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 383: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383 - Avg Loss: 0.00147, Color Loss: 0.03622, LR: 8.97e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 383: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 384: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384 - Avg Loss: 0.00123, Color Loss: 0.03198, LR: 8.95e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 384: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 385: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385 - Avg Loss: 0.00132, Color Loss: 0.03344, LR: 8.93e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 385: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 386: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386 - Avg Loss: 0.00122, Color Loss: 0.03172, LR: 8.90e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 386: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.14it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.53it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.43it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.23it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 387: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387 - Avg Loss: 0.00128, Color Loss: 0.03282, LR: 8.88e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 387: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 388: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388 - Avg Loss: 0.00133, Color Loss: 0.03387, LR: 8.85e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 388: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 389: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389 - Avg Loss: 0.00119, Color Loss: 0.03130, LR: 8.83e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 389: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 390: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390 - Avg Loss: 0.00112, Color Loss: 0.03001, LR: 8.80e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 390: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00210, Color Loss: 0.04991\n",
      "New best model saved with val loss 0.00210 and color loss 0.04991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 391: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391 - Avg Loss: 0.00123, Color Loss: 0.03189, LR: 8.78e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 391: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.10it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.92it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.92it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.58it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 392: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392 - Avg Loss: 0.00123, Color Loss: 0.03199, LR: 8.75e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 392: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 393: 100%|██████████| 313/313 [00:57<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393 - Avg Loss: 0.00133, Color Loss: 0.03340, LR: 8.72e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 393: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 394: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394 - Avg Loss: 0.00118, Color Loss: 0.03140, LR: 8.70e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 394: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 395: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395 - Avg Loss: 0.00137, Color Loss: 0.03461, LR: 8.67e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 395: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 396: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396 - Avg Loss: 0.00121, Color Loss: 0.03156, LR: 8.64e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 396: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.55it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.51it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.20it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.32it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 397: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397 - Avg Loss: 0.00115, Color Loss: 0.03037, LR: 8.62e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 397: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 398: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398 - Avg Loss: 0.00140, Color Loss: 0.03487, LR: 8.59e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 398: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 399: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399 - Avg Loss: 0.00125, Color Loss: 0.03232, LR: 8.56e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 399: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 400: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400 - Avg Loss: 0.00113, Color Loss: 0.03015, LR: 8.54e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 400: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 401: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401 - Avg Loss: 0.00126, Color Loss: 0.03234, LR: 8.51e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 401: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.70it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.13it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.07it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.86it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 402: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402 - Avg Loss: 0.00131, Color Loss: 0.03350, LR: 8.48e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 402: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 403: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403 - Avg Loss: 0.00119, Color Loss: 0.03122, LR: 8.45e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 403: 100%|██████████| 40/40 [00:03<00:00, 11.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 404: 100%|██████████| 313/313 [00:57<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404 - Avg Loss: 0.00112, Color Loss: 0.03034, LR: 8.42e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 404: 100%|██████████| 40/40 [00:03<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 405: 100%|██████████| 313/313 [00:58<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 405 - Avg Loss: 0.00130, Color Loss: 0.03338, LR: 8.39e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 405: 100%|██████████| 40/40 [00:03<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00212, Color Loss: 0.05049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 406: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406 - Avg Loss: 0.00118, Color Loss: 0.03119, LR: 8.37e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 406: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 96.49it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.17it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.57it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.04it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 407: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407 - Avg Loss: 0.00124, Color Loss: 0.03211, LR: 8.34e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 407: 100%|██████████| 40/40 [00:03<00:00, 11.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 408: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408 - Avg Loss: 0.00111, Color Loss: 0.02989, LR: 8.31e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 408: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 409: 100%|██████████| 313/313 [00:57<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 409 - Avg Loss: 0.00122, Color Loss: 0.03192, LR: 8.28e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 409: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00212, Color Loss: 0.05022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 410: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410 - Avg Loss: 0.00128, Color Loss: 0.03283, LR: 8.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 410: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 411: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411 - Avg Loss: 0.00115, Color Loss: 0.03047, LR: 8.22e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 411: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.65it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.78it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.34it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.17it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 412: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412 - Avg Loss: 0.00115, Color Loss: 0.03057, LR: 8.19e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 412: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00212, Color Loss: 0.05037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 413: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413 - Avg Loss: 0.00122, Color Loss: 0.03184, LR: 8.16e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 413: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 414: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414 - Avg Loss: 0.00120, Color Loss: 0.03112, LR: 8.13e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 414: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00211, Color Loss: 0.05001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 415: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415 - Avg Loss: 0.00113, Color Loss: 0.03035, LR: 8.10e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 415: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 416: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416 - Avg Loss: 0.00118, Color Loss: 0.03124, LR: 8.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 416: 100%|██████████| 40/40 [00:03<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00213, Color Loss: 0.05035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.01it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.89it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.68it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.95it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 417: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417 - Avg Loss: 0.00120, Color Loss: 0.03150, LR: 8.03e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 417: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 418: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 418 - Avg Loss: 0.00127, Color Loss: 0.03240, LR: 8.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 418: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 419: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419 - Avg Loss: 0.00119, Color Loss: 0.03114, LR: 7.97e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 419: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 420: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420 - Avg Loss: 0.00113, Color Loss: 0.03015, LR: 7.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 420: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 421: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421 - Avg Loss: 0.00119, Color Loss: 0.03103, LR: 7.91e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 421: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.41it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.39it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.27it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.39it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 422: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 422 - Avg Loss: 0.00120, Color Loss: 0.03135, LR: 7.88e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 422: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 423: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 423 - Avg Loss: 0.00124, Color Loss: 0.03220, LR: 7.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 423: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00211, Color Loss: 0.05032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 424: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424 - Avg Loss: 0.00126, Color Loss: 0.03247, LR: 7.81e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 424: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 425: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425 - Avg Loss: 0.00134, Color Loss: 0.03398, LR: 7.78e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 425: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 426: 100%|██████████| 313/313 [00:57<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426 - Avg Loss: 0.00119, Color Loss: 0.03101, LR: 7.75e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 426: 100%|██████████| 40/40 [00:03<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.86it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.12it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.65it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.26it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 427: 100%|██████████| 313/313 [00:57<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 427 - Avg Loss: 0.00118, Color Loss: 0.03097, LR: 7.71e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 427: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 428: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428 - Avg Loss: 0.00118, Color Loss: 0.03094, LR: 7.68e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 428: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 429: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429 - Avg Loss: 0.00137, Color Loss: 0.03395, LR: 7.65e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 429: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 430: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430 - Avg Loss: 0.00123, Color Loss: 0.03180, LR: 7.61e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 430: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00213, Color Loss: 0.05019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 431: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431 - Avg Loss: 0.00124, Color Loss: 0.03220, LR: 7.58e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 431: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.02it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.37it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.12it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.15it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 432: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432 - Avg Loss: 0.00119, Color Loss: 0.03130, LR: 7.55e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 432: 100%|██████████| 40/40 [00:03<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 433: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433 - Avg Loss: 0.00118, Color Loss: 0.03091, LR: 7.51e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 433: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 434: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434 - Avg Loss: 0.00132, Color Loss: 0.03348, LR: 7.48e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 434: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 435: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435 - Avg Loss: 0.00111, Color Loss: 0.02975, LR: 7.44e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 435: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 436: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436 - Avg Loss: 0.00120, Color Loss: 0.03120, LR: 7.41e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 436: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.41it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.60it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.54it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.32it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 437: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437 - Avg Loss: 0.00121, Color Loss: 0.03187, LR: 7.37e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 437: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00212, Color Loss: 0.05034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 438: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438 - Avg Loss: 0.00111, Color Loss: 0.02972, LR: 7.34e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 438: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 439: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439 - Avg Loss: 0.00128, Color Loss: 0.03256, LR: 7.30e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 439: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 440: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440 - Avg Loss: 0.00125, Color Loss: 0.03215, LR: 7.27e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 440: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 441: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441 - Avg Loss: 0.00135, Color Loss: 0.03381, LR: 7.23e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 441: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 97.71it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.12it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.29it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.53it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 442: 100%|██████████| 313/313 [00:57<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442 - Avg Loss: 0.00105, Color Loss: 0.02882, LR: 7.20e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 442: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 443: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443 - Avg Loss: 0.00121, Color Loss: 0.03135, LR: 7.16e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 443: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 444: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444 - Avg Loss: 0.00115, Color Loss: 0.03049, LR: 7.13e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 444: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 445: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445 - Avg Loss: 0.00134, Color Loss: 0.03382, LR: 7.09e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 445: 100%|██████████| 40/40 [00:03<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 446: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446 - Avg Loss: 0.00131, Color Loss: 0.03333, LR: 7.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 446: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.14it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.77it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.64it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.83it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 447: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447 - Avg Loss: 0.00137, Color Loss: 0.03436, LR: 7.02e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 447: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 448: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448 - Avg Loss: 0.00120, Color Loss: 0.03134, LR: 6.99e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 448: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 449: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449 - Avg Loss: 0.00132, Color Loss: 0.03367, LR: 6.95e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 449: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 450: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450 - Avg Loss: 0.00129, Color Loss: 0.03291, LR: 6.91e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 450: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 451: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451 - Avg Loss: 0.00115, Color Loss: 0.03056, LR: 6.88e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 451: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.40it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.62it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.53it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.84it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 452: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452 - Avg Loss: 0.00132, Color Loss: 0.03335, LR: 6.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 452: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00211, Color Loss: 0.05011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 453: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453 - Avg Loss: 0.00122, Color Loss: 0.03172, LR: 6.80e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 453: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00213, Color Loss: 0.04997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 454: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454 - Avg Loss: 0.00137, Color Loss: 0.03435, LR: 6.77e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 454: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00210, Color Loss: 0.05005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 455: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455 - Avg Loss: 0.00122, Color Loss: 0.03148, LR: 6.73e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 455: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00213, Color Loss: 0.05043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 456: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456 - Avg Loss: 0.00130, Color Loss: 0.03286, LR: 6.69e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 456: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.66it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.84it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 98.12it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.14it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 457: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457 - Avg Loss: 0.00143, Color Loss: 0.03520, LR: 6.66e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 457: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 458: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458 - Avg Loss: 0.00112, Color Loss: 0.02983, LR: 6.62e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 458: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 459: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459 - Avg Loss: 0.00111, Color Loss: 0.02955, LR: 6.58e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 459: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 460: 100%|██████████| 313/313 [00:58<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460 - Avg Loss: 0.00130, Color Loss: 0.03286, LR: 6.55e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 460: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 461: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461 - Avg Loss: 0.00124, Color Loss: 0.03187, LR: 6.51e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 461: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.07it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.11it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.12it/s]\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.55it/s] \n",
      "Training Epoch 462: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462 - Avg Loss: 0.00117, Color Loss: 0.03079, LR: 6.47e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 462: 100%|██████████| 40/40 [00:03<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00222, Color Loss: 0.05161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 463: 100%|██████████| 313/313 [00:57<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463 - Avg Loss: 0.00110, Color Loss: 0.02968, LR: 6.43e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 463: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00213, Color Loss: 0.05052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 464: 100%|██████████| 313/313 [00:57<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464 - Avg Loss: 0.00124, Color Loss: 0.03208, LR: 6.39e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 464: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 465: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465 - Avg Loss: 0.00115, Color Loss: 0.03034, LR: 6.36e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 465: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 466: 100%|██████████| 313/313 [00:57<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466 - Avg Loss: 0.00120, Color Loss: 0.03137, LR: 6.32e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 466: 100%|██████████| 40/40 [00:03<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00212, Color Loss: 0.05004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.52it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.36it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 97.35it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 97.43it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 467: 100%|██████████| 313/313 [00:58<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467 - Avg Loss: 0.00110, Color Loss: 0.02943, LR: 6.28e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 467: 100%|██████████| 40/40 [00:03<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 468: 100%|██████████| 313/313 [00:57<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468 - Avg Loss: 0.00115, Color Loss: 0.03043, LR: 6.24e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 468: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 469: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469 - Avg Loss: 0.00131, Color Loss: 0.03318, LR: 6.21e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 469: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 470: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470 - Avg Loss: 0.00116, Color Loss: 0.03067, LR: 6.17e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 470: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 471: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471 - Avg Loss: 0.00122, Color Loss: 0.03155, LR: 6.13e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 471: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.63it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.75it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.97it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 100.02it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 472: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472 - Avg Loss: 0.00114, Color Loss: 0.03030, LR: 6.09e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 472: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 473: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473 - Avg Loss: 0.00120, Color Loss: 0.03117, LR: 6.05e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 473: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 474: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474 - Avg Loss: 0.00138, Color Loss: 0.03437, LR: 6.01e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 474: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00214, Color Loss: 0.05085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 475: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475 - Avg Loss: 0.00126, Color Loss: 0.03248, LR: 5.98e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 475: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 476: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476 - Avg Loss: 0.00117, Color Loss: 0.03071, LR: 5.94e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 476: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.63it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.59it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.22it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.51it/s]\n",
      "Training Epoch 477: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477 - Avg Loss: 0.00119, Color Loss: 0.03106, LR: 5.90e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 477: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 478: 100%|██████████| 313/313 [00:57<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478 - Avg Loss: 0.00115, Color Loss: 0.03032, LR: 5.86e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 478: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00212, Color Loss: 0.05023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 479: 100%|██████████| 313/313 [00:56<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479 - Avg Loss: 0.00126, Color Loss: 0.03225, LR: 5.82e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 479: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 480: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480 - Avg Loss: 0.00131, Color Loss: 0.03308, LR: 5.78e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 480: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00218, Color Loss: 0.05126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 481: 100%|██████████| 313/313 [00:56<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481 - Avg Loss: 0.00117, Color Loss: 0.03069, LR: 5.74e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 481: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.11it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.26it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.09it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.13it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 482: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 482 - Avg Loss: 0.00122, Color Loss: 0.03136, LR: 5.70e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 482: 100%|██████████| 40/40 [00:03<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 483: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483 - Avg Loss: 0.00129, Color Loss: 0.03275, LR: 5.67e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 483: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 484: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484 - Avg Loss: 0.00126, Color Loss: 0.03213, LR: 5.63e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 484: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00220, Color Loss: 0.05134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 485: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485 - Avg Loss: 0.00117, Color Loss: 0.03067, LR: 5.59e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 485: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 486: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486 - Avg Loss: 0.00109, Color Loss: 0.02954, LR: 5.55e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 486: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00213, Color Loss: 0.05059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.23it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.05it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.34it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.54it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 487: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487 - Avg Loss: 0.00130, Color Loss: 0.03311, LR: 5.51e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 487: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 488: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488 - Avg Loss: 0.00124, Color Loss: 0.03206, LR: 5.47e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 488: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00212, Color Loss: 0.05010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 489: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489 - Avg Loss: 0.00130, Color Loss: 0.03293, LR: 5.43e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 489: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00216, Color Loss: 0.05102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 490: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490 - Avg Loss: 0.00122, Color Loss: 0.03166, LR: 5.39e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 490: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00212, Color Loss: 0.05040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 491: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491 - Avg Loss: 0.00119, Color Loss: 0.03110, LR: 5.35e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 491: 100%|██████████| 40/40 [00:03<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.80it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 99.56it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.83it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 99.27it/s] \n",
      "Training Epoch 492: 100%|██████████| 313/313 [00:56<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492 - Avg Loss: 0.00134, Color Loss: 0.03360, LR: 5.31e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 492: 100%|██████████| 40/40 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00211, Color Loss: 0.05008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 493: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493 - Avg Loss: 0.00124, Color Loss: 0.03190, LR: 5.27e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 493: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00212, Color Loss: 0.05029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 494: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494 - Avg Loss: 0.00112, Color Loss: 0.02977, LR: 5.24e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 494: 100%|██████████| 40/40 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 495: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495 - Avg Loss: 0.00116, Color Loss: 0.03048, LR: 5.20e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 495: 100%|██████████| 40/40 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00219, Color Loss: 0.05136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 496: 100%|██████████| 313/313 [00:56<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496 - Avg Loss: 0.00119, Color Loss: 0.03097, LR: 5.16e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 496: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 98.54it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 98.70it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 99.14it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 98.57it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Training Epoch 497: 100%|██████████| 313/313 [00:57<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497 - Avg Loss: 0.00128, Color Loss: 0.03264, LR: 5.12e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 497: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00217, Color Loss: 0.05101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 498: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498 - Avg Loss: 0.00122, Color Loss: 0.03181, LR: 5.08e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 498: 100%|██████████| 40/40 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00221, Color Loss: 0.05192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 499: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499 - Avg Loss: 0.00127, Color Loss: 0.03250, LR: 5.04e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 499: 100%|██████████| 40/40 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 500: 100%|██████████| 313/313 [00:56<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 - Avg Loss: 0.00115, Color Loss: 0.03054, LR: 5.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 500: 100%|██████████| 40/40 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Avg Loss: 0.00215, Color Loss: 0.05085\n",
      "Training completed!\n",
      "Loaded best model from epoch 390 with val loss 0.00210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 91/91 [00:00<00:00, 99.36it/s] \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 71/71 [00:00<00:00, 100.09it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 51/51 [00:00<00:00, 100.06it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Sampling: 100%|██████████| 31/31 [00:00<00:00, 100.02it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './0409_test/test_sample_1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 816\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;66;03m# 執行訓練\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;66;03m# 開始訓練\u001b[39;00m\n\u001b[0;32m--> 816\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 811\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded best model from epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with val loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    810\u001b[0m \u001b[38;5;66;03m# 測量還原效果\u001b[39;00m\n\u001b[0;32m--> 811\u001b[0m \u001b[43mtest_restoration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 745\u001b[0m, in \u001b[0;36mtest_restoration\u001b[0;34m(model, quality_levels)\u001b[0m\n\u001b[1;32m    742\u001b[0m         plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    744\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m--> 745\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./0409_test/test_sample_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    748\u001b[0m \u001b[38;5;66;03m# 顯示平均結果\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py:1023\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39msavefig)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavefig\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1022\u001b[0m     fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[0;32m-> 1023\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py:3343\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3339\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3340\u001b[0m         stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m   3341\u001b[0m             ax\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39m_cm_set(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m-> 3343\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2366\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2368\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2372\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2373\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2228\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2231\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2232\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py:458\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 458\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py:1689\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1687\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1688\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[0;32m-> 1689\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py:2317\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2320\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './0409_test/test_sample_1.png'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from PIL import Image\n",
    "import io\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pytorch_msssim import ssim\n",
    "import lpips\n",
    "\n",
    "# 設置GPU裝置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 資料集準備\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "train_dataset, valid_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, valid_size, test_size]\n",
    ")\n",
    "\n",
    "# 設置資料載入器\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# 定義JPEG壓縮函數\n",
    "def jpeg_compress(x, quality):\n",
    "    \"\"\"執行JPEG壓縮並保留色彩資訊\"\"\"\n",
    "    x = (x * 127.5 + 127.5).clamp(0, 255).to(torch.uint8).cpu()\n",
    "    compressed_images = []\n",
    "    for img in x:\n",
    "        pil_img = torchvision.transforms.ToPILImage()(img)\n",
    "        buffer = io.BytesIO()\n",
    "        # 確保quality在1-100的有效區間內\n",
    "        quality = max(1, min(100, int(quality)))\n",
    "        # 根據壓縮質量選擇子採樣方式，高質量時保留色彩資訊\n",
    "        subsampling = \"4:4:4\" if quality > 30 else \"4:2:0\"\n",
    "        pil_img.save(buffer, format=\"JPEG\", quality=quality, subsampling=subsampling)\n",
    "        buffer.seek(0)\n",
    "        compressed_img = Image.open(buffer)\n",
    "        compressed_tensor = torchvision.transforms.ToTensor()(compressed_img)\n",
    "        compressed_images.append(compressed_tensor)\n",
    "    return torch.stack(compressed_images).to(device).sub(0.5).div(0.5)\n",
    "\n",
    "# 色彩保持損失函數\n",
    "def color_preservation_loss(pred, target):\n",
    "    \"\"\"色彩保持損失，加強RGB通道保真度\"\"\"\n",
    "    # 將張量放縮回[0,1]的範圍\n",
    "    pred = (pred * 0.5 + 0.5).clamp(0, 1)\n",
    "    target = (target * 0.5 + 0.5).clamp(0, 1)\n",
    "    \n",
    "    # 計算RGB差異，給予色彩通道不同權重\n",
    "    r_loss = F.l1_loss(pred[:, 0], target[:, 0])\n",
    "    g_loss = F.l1_loss(pred[:, 1], target[:, 1])\n",
    "    b_loss = F.l1_loss(pred[:, 2], target[:, 2])\n",
    "    \n",
    "    # 綠色通道對感知影響最大，給予更高權重\n",
    "    color_loss = 0.25 * r_loss + 0.5 * g_loss + 0.25 * b_loss\n",
    "    \n",
    "    # 額外添加SSIM感知損失\n",
    "    ssim_loss = 1 - ssim(pred, target, data_range=1.0, size_average=True)\n",
    "    \n",
    "    # 總損失\n",
    "    return color_loss + 0.5 * ssim_loss\n",
    "\n",
    "# 時間嵌入模組\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim * 4, dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, t):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return self.proj(emb)\n",
    "\n",
    "# DCT變換層\n",
    "class DCTLayer(nn.Module):\n",
    "    \"\"\"執行DCT變換操作，處理頻率域信息\"\"\"\n",
    "    def __init__(self, block_size=8):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 獲取形狀信息\n",
    "        b, c, h, w = x.shape\n",
    "        \n",
    "        # 實際執行DCT變換的內部實現，確保輸出尺寸與輸入一致\n",
    "        # 完整實現DCT變換\n",
    "        x_dct = self._apply_dct(x)\n",
    "        \n",
    "        # 確保輸出尺寸與輸入一致\n",
    "        if x_dct.shape[2:] != x.shape[2:]:\n",
    "            x_dct = F.interpolate(x_dct, size=(h, w), mode='bilinear', align_corners=False)\n",
    "            \n",
    "        return x_dct\n",
    "    \n",
    "    def _apply_dct(self, x):\n",
    "        \"\"\"實際執行DCT變換的內部實現函數\"\"\"\n",
    "        b, c, h, w = x.shape\n",
    "        \n",
    "        # 填充至block_size的整數倍\n",
    "        h_pad = (self.block_size - h % self.block_size) % self.block_size\n",
    "        w_pad = (self.block_size - w % self.block_size) % self.block_size\n",
    "        \n",
    "        x_padded = F.pad(x, (0, w_pad, 0, h_pad))\n",
    "        \n",
    "        # 獲取填充後的形狀\n",
    "        _, _, h_padded, w_padded = x_padded.shape\n",
    "        \n",
    "        # 計算塊的數量\n",
    "        h_blocks = h_padded // self.block_size\n",
    "        w_blocks = w_padded // self.block_size\n",
    "        \n",
    "        # 分割圖像\n",
    "        x_blocks = x_padded.unfold(2, self.block_size, self.block_size).unfold(3, self.block_size, self.block_size)\n",
    "        \n",
    "        # 獲取展開後的形狀\n",
    "        b_unf, c_unf, h_unf, w_unf, bs_h, bs_w = x_blocks.shape\n",
    "        \n",
    "        # 展平以便進行DCT的形狀\n",
    "        x_blocks_flat = x_blocks.reshape(-1, self.block_size, self.block_size)\n",
    "        \n",
    "        # 獲取DCT矩陣\n",
    "        dct_matrix = self._get_dct_matrix(self.block_size).to(x.device)\n",
    "        \n",
    "        # 應用DCT變換: D * X * D^T\n",
    "        x_dct_flat = torch.matmul(dct_matrix, x_blocks_flat)\n",
    "        x_dct_flat = torch.matmul(x_dct_flat, dct_matrix.transpose(0, 1))\n",
    "        \n",
    "        # 還原形狀\n",
    "        x_dct_blocks = x_dct_flat.reshape(b_unf, c_unf, h_unf, w_unf, bs_h, bs_w)\n",
    "        \n",
    "        # 重新排列以從還原頻率形狀的排列\n",
    "        x_dct_perm = x_dct_blocks.permute(0, 1, 2, 4, 3, 5)\n",
    "        \n",
    "        # 展平以還原填充後的頻率形狀\n",
    "        x_dct = x_dct_perm.reshape(b, c, h_padded, w_padded)\n",
    "        \n",
    "        # 移除填充部分\n",
    "        if h_pad > 0 or w_pad > 0:\n",
    "            x_dct = x_dct[:, :, :h, :w]\n",
    "        \n",
    "        return x_dct\n",
    "    \n",
    "    def _get_dct_matrix(self, size):\n",
    "        \"\"\"生成標準離散餘弦變換矩陣\"\"\"\n",
    "        dct_matrix = torch.zeros(size, size)\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                if i == 0:\n",
    "                    dct_matrix[i, j] = 1.0 / torch.sqrt(torch.tensor(size, dtype=torch.float32))\n",
    "                else:\n",
    "                    dct_matrix[i, j] = torch.sqrt(torch.tensor(2.0 / size)) * torch.cos(torch.tensor(torch.pi * (2 * j + 1) * i / (2 * size)))\n",
    "        return dct_matrix\n",
    "\n",
    "# 高頻增強模組\n",
    "class HFCM(nn.Module):\n",
    "    \"\"\"高頻增強模組，參考FDG-Diff論文方法\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.dct = DCTLayer(block_size=8)\n",
    "        self.high_freq_attn = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.conv_out = nn.Conv2d(channels, channels, 1)\n",
    "        \n",
    "    def forward(self, x, compression_level):\n",
    "        # 獲取DCT頻率表示\n",
    "        x_dct = self.dct(x)\n",
    "        \n",
    "        # 確保x_dct與x具有相同的空間尺寸\n",
    "        if x_dct.shape[2:] != x.shape[2:]:\n",
    "            x_dct = F.interpolate(x_dct, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # 高頻注意力機制\n",
    "        attn_mask = self.high_freq_attn(x)\n",
    "        \n",
    "        # 如果compression_level是多維張量，將其轉換成適當的形狀\n",
    "        if isinstance(compression_level, torch.Tensor) and compression_level.dim() > 0:\n",
    "            compression_level = compression_level.view(-1, 1, 1, 1)\n",
    "        \n",
    "        # 根據壓縮程度調整高頻增強效果\n",
    "        # 壓縮程度越高(值越大)，保留高頻越少\n",
    "        freq_scale = 1.0 - compression_level\n",
    "        \n",
    "        # 應用高頻增強\n",
    "        enhanced = x + attn_mask * x_dct * freq_scale\n",
    "        return self.conv_out(enhanced)\n",
    "\n",
    "# 頻率感知塊\n",
    "class FrequencyAwareBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.dct_layer = DCTLayer(block_size=8)\n",
    "        self.freq_conv = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.freq_attn = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // 4, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels // 4, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, compression_level):\n",
    "        # 獲取頻率表示\n",
    "        x_dct = self.dct_layer(x)\n",
    "        \n",
    "        # 確保x_dct與x具有相同的空間尺寸\n",
    "        if x_dct.shape[2:] != x.shape[2:]:\n",
    "            x_dct = F.interpolate(x_dct, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "            \n",
    "        x_freq = self.freq_conv(x_dct)\n",
    "        \n",
    "        # 確保x_freq與x具有相同的空間尺寸\n",
    "        if x_freq.shape[2:] != x.shape[2:]:\n",
    "            x_freq = F.interpolate(x_freq, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # 生成頻率注意力圖\n",
    "        attn = self.freq_attn(x_freq)\n",
    "        \n",
    "        # 如果compression_level是多維張量，將其轉換成適當的形狀\n",
    "        if isinstance(compression_level, torch.Tensor) and compression_level.dim() > 0:\n",
    "            compression_level = compression_level.view(-1, 1, 1, 1)\n",
    "        \n",
    "        # 根據壓縮程度調整頻率注意力\n",
    "        attn = attn * (1.0 - compression_level) + 0.5\n",
    "        \n",
    "        # 確保attn與x_freq尺寸一致\n",
    "        if attn.shape[2:] != x_freq.shape[2:]:\n",
    "            attn = F.interpolate(attn, size=x_freq.shape[2:], mode='nearest')\n",
    "        \n",
    "        # 應用頻率注意力\n",
    "        return x + x_freq * attn\n",
    "\n",
    "# 定義的殘差注意力塊\n",
    "class ResAttnBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c, time_dim, dropout=0.1, use_freq_guide=False):\n",
    "        super().__init__()\n",
    "        # 確保組數適合通道數\n",
    "        num_groups = min(8, in_c)\n",
    "        while in_c % num_groups != 0 and num_groups > 1:\n",
    "            num_groups -= 1\n",
    "            \n",
    "        self.norm1 = nn.GroupNorm(num_groups, in_c)\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, 3, padding=1)\n",
    "        self.time_proj = nn.Linear(time_dim, out_c)\n",
    "        \n",
    "        # 調整 out_c 的組數\n",
    "        num_groups_out = min(8, out_c)\n",
    "        while out_c % num_groups_out != 0 and num_groups_out > 1:\n",
    "            num_groups_out -= 1\n",
    "            \n",
    "        self.norm2 = nn.GroupNorm(num_groups_out, out_c)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, 3, padding=1)\n",
    "        self.attn = nn.MultiheadAttention(out_c, 4, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.shortcut = nn.Conv2d(in_c, out_c, 1) if in_c != out_c else nn.Identity()\n",
    "        \n",
    "        # 頻率感知(可選使用)\n",
    "        self.use_freq_guide = use_freq_guide\n",
    "        if use_freq_guide:\n",
    "            self.freq_guide = FrequencyAwareBlock(out_c)\n",
    "            self.hfcm = HFCM(out_c)\n",
    "        \n",
    "    def forward(self, x, t_emb, compression_level=None):\n",
    "        h = self.norm1(x)\n",
    "        h = self.conv1(h)\n",
    "        \n",
    "        # 加入時間編碼\n",
    "        t = self.time_proj(t_emb)[..., None, None]\n",
    "        h = h + t\n",
    "        \n",
    "        h = self.norm2(h)\n",
    "        h = self.conv2(F.silu(h))\n",
    "        \n",
    "        # 應用自注意力機制\n",
    "        b, c, hh, ww = h.shape\n",
    "        h_attn = h.view(b, c, -1).permute(0, 2, 1)\n",
    "        h_attn, _ = self.attn(h_attn, h_attn, h_attn)\n",
    "        h_attn = h_attn.permute(0, 2, 1).view(b, c, hh, ww)\n",
    "        \n",
    "        # 應用頻率感知(如果啟用)\n",
    "        if self.use_freq_guide and compression_level is not None:\n",
    "            h_attn = self.freq_guide(h_attn, compression_level)\n",
    "            h_attn = self.hfcm(h_attn, compression_level)\n",
    "        \n",
    "        return self.shortcut(x) + self.dropout(h_attn)\n",
    "\n",
    "# SVD結構保持函數\n",
    "def svd_structure_preservation(x, k_ratio=0.5):\n",
    "    \"\"\"使用SVD保持主要結構特徵\"\"\"\n",
    "    b, c, h, w = x.shape\n",
    "    x_flat = x.view(b, c, -1)\n",
    "    \n",
    "    # 對每個通道分別進行SVD分解\n",
    "    structure_tensors = []\n",
    "    for i in range(b):\n",
    "        channels_structure = []\n",
    "        for j in range(c):\n",
    "            # SVD分解\n",
    "            U, S, Vh = torch.linalg.svd(x_flat[i, j].view(h, w), full_matrices=False)\n",
    "            \n",
    "            # 確定保留的奇異值數量\n",
    "            k = max(1, int(min(h, w) * k_ratio))\n",
    "            \n",
    "            # 重建低秩表示\n",
    "            S_k = torch.zeros_like(S)\n",
    "            S_k[:k] = S[:k]\n",
    "            structure = torch.matmul(U, torch.matmul(torch.diag(S_k), Vh))\n",
    "            channels_structure.append(structure.unsqueeze(0))\n",
    "        \n",
    "        # 合併通道結構\n",
    "        structure_tensors.append(torch.cat(channels_structure, dim=0).unsqueeze(0))\n",
    "    \n",
    "    return torch.cat(structure_tensors, dim=0)\n",
    "\n",
    "# 相位一致性函數\n",
    "def phase_consistency(x, ref, alpha=0.7):\n",
    "    \"\"\"使用傅里葉變換的相位一致性，保持頻域特性\"\"\"\n",
    "    # FFT變換\n",
    "    x_fft = torch.fft.fft2(x)\n",
    "    ref_fft = torch.fft.fft2(ref)\n",
    "    \n",
    "    # 獲取幅度和相位\n",
    "    x_mag = torch.abs(x_fft)\n",
    "    ref_phase = torch.angle(ref_fft)\n",
    "    \n",
    "    # 融合新的複數值，使用x的幅度和參考的相位\n",
    "    real = x_mag * torch.cos(ref_phase)\n",
    "    imag = x_mag * torch.sin(ref_phase)\n",
    "    adjusted_fft = torch.complex(real, imag)\n",
    "    \n",
    "    # 逆變換\n",
    "    adjusted_img = torch.fft.ifft2(adjusted_fft).real\n",
    "    \n",
    "    # 混合原始圖像和相位調整圖像\n",
    "    return alpha * x + (1 - alpha) * adjusted_img\n",
    "\n",
    "# 定義的UNet架構\n",
    "class JPEGDiffusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        time_dim = 256\n",
    "        self.time_embed = TimeEmbedding(time_dim)\n",
    "        \n",
    "        # 下採樣路徑 - 增強使用頻率感知\n",
    "        self.down1 = ResAttnBlock(3, 64, time_dim)\n",
    "        self.down2 = ResAttnBlock(64, 128, time_dim, use_freq_guide=True)\n",
    "        self.down3 = ResAttnBlock(128, 256, time_dim, use_freq_guide=True)\n",
    "        self.down4 = ResAttnBlock(256, 512, time_dim)\n",
    "        self.down5 = ResAttnBlock(512, 512, time_dim)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # 瓶頸層 - 使用頻率感知\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            ResAttnBlock(512, 1024, time_dim, use_freq_guide=True),\n",
    "            ResAttnBlock(1024, 1024, time_dim),\n",
    "            ResAttnBlock(1024, 512, time_dim, use_freq_guide=True)\n",
    "        )\n",
    "        \n",
    "        # 上採樣路徑 - 增強使用頻率感知\n",
    "        self.up1 = ResAttnBlock(1024, 512, time_dim)\n",
    "        self.up2 = ResAttnBlock(512 + 512, 256, time_dim, use_freq_guide=True)\n",
    "        self.up3 = ResAttnBlock(256 + 256, 128, time_dim, use_freq_guide=True)\n",
    "        self.up4 = ResAttnBlock(128 + 128, 64, time_dim)\n",
    "        self.up5 = ResAttnBlock(64 + 64, 64, time_dim)\n",
    "        \n",
    "        # 輸出層 - 使用1x1卷積產生空間色彩分布\n",
    "        self.out_conv = nn.Conv2d(64, 3, 1)\n",
    "        \n",
    "    def forward(self, x, t, compression_level=None):\n",
    "        t_emb = self.time_embed(t)\n",
    "        \n",
    "        # 如果未提供壓縮程度，使用時間步長代替\n",
    "        if compression_level is None:\n",
    "            compression_level = t.clone().detach()\n",
    "        \n",
    "        # 下採樣\n",
    "        d1 = self.down1(x, t_emb)  # 32x32\n",
    "        d2 = self.down2(self.pool(d1), t_emb, compression_level)  # 16x16\n",
    "        d3 = self.down3(self.pool(d2), t_emb, compression_level)  # 8x8\n",
    "        d4 = self.down4(self.pool(d3), t_emb)  # 4x4\n",
    "        d5 = self.down5(self.pool(d4), t_emb)  # 2x2\n",
    "        \n",
    "        # 瓶頸層\n",
    "        b = self.bottleneck[0](self.pool(d5), t_emb, compression_level)\n",
    "        b = self.bottleneck[1](b, t_emb)\n",
    "        b = self.bottleneck[2](b, t_emb, compression_level)\n",
    "        \n",
    "        # 上採樣 - 使用連接操作將特徵合併回來\n",
    "        u1 = self.up1(torch.cat([F.interpolate(b, scale_factor=2, mode='bilinear', align_corners=False), d5], dim=1), t_emb)\n",
    "        u2 = self.up2(torch.cat([F.interpolate(u1, scale_factor=2, mode='bilinear', align_corners=False), d4], dim=1), t_emb, compression_level)\n",
    "        u3 = self.up3(torch.cat([F.interpolate(u2, scale_factor=2, mode='bilinear', align_corners=False), d3], dim=1), t_emb, compression_level)\n",
    "        u4 = self.up4(torch.cat([F.interpolate(u3, scale_factor=2, mode='bilinear', align_corners=False), d2], dim=1), t_emb)\n",
    "        u5 = self.up5(torch.cat([F.interpolate(u4, scale_factor=2, mode='bilinear', align_corners=False), d1], dim=1), t_emb)\n",
    "        \n",
    "        return self.out_conv(u5)\n",
    "\n",
    "# 初始化模型\n",
    "model = JPEGDiffusionModel().to(device)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# 優化器設置 - 使用AdamW以獲得更好收斂性能\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5, betas=(0.9, 0.99))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=100, T_mult=2)\n",
    "# 設置Huber損失和色彩保持損失\n",
    "huber_loss_fn = nn.HuberLoss(reduction='mean', delta=1.0)\n",
    "\n",
    "# 訓練JPEG擴散數\n",
    "num_timesteps = 100\n",
    "# 根據DriftRec論文，使用線性增加的噪聲\n",
    "betas = torch.linspace(1e-4, 0.02, num_timesteps).to(device)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "# 高斯混合採樣模型設計方法\n",
    "class GaussianMixtureSampler:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def sample(self, x_t, steps=100, use_phase_consistency=True, use_svd_guide=True, guidance_scale=1.0):\n",
    "        \"\"\"使用高斯混合採樣進行推理，結合相位一致性和SVD引導\"\"\"\n",
    "        self.model.eval()\n",
    "        # 保存初始壓縮圖像作為相位一致性基準\n",
    "        original_compressed = x_t.clone()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # 從給定的噪聲圖像開始\n",
    "            for i in tqdm(range(steps-1, -1, -1), desc=\"Sampling\"):\n",
    "                t = torch.full((x_t.size(0),), i, device=device).float() / num_timesteps\n",
    "                compression_level = t.clone()  # 壓縮程度與時間步長關聯\n",
    "                \n",
    "                # 獲取噪聲預測\n",
    "                pred_noise = model(x_t, t, compression_level)\n",
    "                \n",
    "                # 可選使用SVD引導\n",
    "                if use_svd_guide and i > steps // 2:\n",
    "                    # 在採樣前半部分使用SVD引導(結構保存)\n",
    "                    k_ratio = i / steps  # 隨時間步長調整重要度\n",
    "                    structure_prior = svd_structure_preservation(x_t, k_ratio)\n",
    "                    # 混合SVD結構先驗與預測\n",
    "                    guide_strength = k_ratio * 0.3  # SVD權重隨時間步長調整\n",
    "                    pred_noise = (1 - guide_strength) * pred_noise + guide_strength * (original_compressed - structure_prior)\n",
    "                \n",
    "                if i > 0:\n",
    "                    # 預測的x0\n",
    "                    x0_pred = x_t + pred_noise\n",
    "                    \n",
    "                    # 計算高斯混合模型的兩個均值\n",
    "                    # 第一個均值 - 偏向原生的預測\n",
    "                    mu1 = x0_pred * 0.9 + x_t * 0.1\n",
    "                    # 第二個均值 - 偏向更激進的預測\n",
    "                    mu2 = x0_pred * 1.1 - x_t * 0.1\n",
    "                    \n",
    "                    # 根據當前時間步長動態使用不同均值\n",
    "                    # 時間步長較大時偏向保守，較小時偏向激進\n",
    "                    p_conservative = max(0.2, min(0.8, i / steps))\n",
    "                    use_first = torch.rand(1).item() < p_conservative\n",
    "                    next_mean = mu1 if use_first else mu2\n",
    "                    \n",
    "                    # 添加適量高斯噪聲\n",
    "                    noise_scale = 0.1 * i / steps * guidance_scale\n",
    "                    x_next = next_mean + noise_scale * torch.randn_like(x_t)\n",
    "                    \n",
    "                    # 相位一致性保持(每5步使用一次)\n",
    "                    if use_phase_consistency and i % 5 == 0:\n",
    "                        alpha = 0.6 + 0.3 * (1 - i / steps)  # 隨時間步長加強初始圖像權重\n",
    "                        x_next = phase_consistency(x_next, original_compressed, alpha)\n",
    "                    \n",
    "                    x_t = x_next\n",
    "                else:\n",
    "                    # 最後一步直接使用預測的去噪結果\n",
    "                    x_t = x_t + pred_noise\n",
    "        \n",
    "        return x_t\n",
    "\n",
    "# 定義的前向過程(類似DriftRec)\n",
    "def forward_process(x0, t, quality_factors=None):\n",
    "    \"\"\"使用類似DriftRec的前向SDE實現JPEG壓縮\"\"\"\n",
    "    b = x0.size(0)\n",
    "    \n",
    "    # 如果未提供quality_factors，根據時間步長計算\n",
    "    if quality_factors is None:\n",
    "        # 隨時間步長變化調整壓縮質量(1-100)，t越大，質量越低\n",
    "        quality_factors = torch.clamp(100 * (1 - t.float() / num_timesteps), 1, 100).cpu().numpy()\n",
    "    \n",
    "    # JPEG壓縮\n",
    "    xt = torch.stack([jpeg_compress(x0[i:i+1], int(q)) for i, q in enumerate(quality_factors)]).squeeze()\n",
    "    \n",
    "    # 添加少量高斯噪聲以增強穩定性(DriftRec建議)\n",
    "    noise_scale = 0.01 * t.float() / num_timesteps  # 隨時間強度增加\n",
    "    xt = xt + noise_scale.view(-1, 1, 1, 1) * torch.randn_like(xt)\n",
    "    \n",
    "    return xt\n",
    "\n",
    "# 定義的訓練函數(一致性保持)\n",
    "def train_epoch(model, loader, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    color_loss_total = 0\n",
    "    \n",
    "    for x0, _ in tqdm(loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "        x0 = x0.to(device)\n",
    "        b = x0.size(0)\n",
    "        \n",
    "        # 使用更符合現實的質量選擇策略\n",
    "        # 根據模型訓練進度增加高質量JPEG比例\n",
    "        if random.random() < 0.3 + min(0.4, epoch * 0.01):  # 隨訓練增加高質量JPEG比例\n",
    "            # 高質量壓縮\n",
    "            quality_range = (70, 100)\n",
    "        elif random.random() < 0.5:\n",
    "            # 中等質量壓縮\n",
    "            quality_range = (40, 70)\n",
    "        else:\n",
    "            # 低質量壓縮\n",
    "            quality_range = (5, 40)\n",
    "            \n",
    "        # 隨機選擇時間步長\n",
    "        t = torch.randint(1, num_timesteps, (b,), device=device).long()\n",
    "        \n",
    "        # 根據時間步長計算質量範圍，得到具體的壓縮質量\n",
    "        min_q, max_q = quality_range\n",
    "        quality = torch.clamp(min_q + (max_q - min_q) * (1 - t.float() / num_timesteps), 1, 100).cpu().numpy()\n",
    "        \n",
    "        # 使用定義的前向過程\n",
    "        xt = forward_process(x0, t, quality)\n",
    "        \n",
    "        # 計算噪聲 (x0 - xt)\n",
    "        noise = x0 - xt\n",
    "        \n",
    "        # 模型預測噪聲\n",
    "        compression_level = t.float() / num_timesteps  # 壓縮程度\n",
    "        pred_noise = model(xt, t.float()/num_timesteps, compression_level)\n",
    "        \n",
    "        # 計算損失\n",
    "        huber_loss = huber_loss_fn(pred_noise, noise)\n",
    "        \n",
    "        # 色彩保持損失\n",
    "        col_loss = color_preservation_loss(xt + pred_noise, x0)\n",
    "        \n",
    "        # 結合損失，隨訓練進度增加色彩損失權重\n",
    "        color_weight = min(1.0, 0.2 + epoch * 0.02)\n",
    "        loss = huber_loss + color_weight * col_loss\n",
    "        \n",
    "        # 反向傳播更新\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # 梯度裁剪防止梯度爆炸\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += huber_loss.item()\n",
    "        color_loss_total += col_loss.item()\n",
    "    \n",
    "    # 更新學習率\n",
    "    scheduler.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    avg_color_loss = color_loss_total / len(loader)\n",
    "    print(f\"Epoch {epoch+1} - Avg Loss: {avg_loss:.5f}, Color Loss: {avg_color_loss:.5f}, LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    return avg_loss, avg_color_loss\n",
    "\n",
    "# 驗證函數\n",
    "def validate(model, loader, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    color_loss_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x0, _ in tqdm(loader, desc=f\"Validating Epoch {epoch+1}\"):\n",
    "            x0 = x0.to(device)\n",
    "            b = x0.size(0)\n",
    "            \n",
    "            # 選擇隨機質量做驗證\n",
    "            quality = torch.randint(10, 90, (b,)).cpu().numpy()\n",
    "            t = torch.full((b,), num_timesteps//2, device=device).long()\n",
    "            \n",
    "            # 使用前向過程\n",
    "            xt = forward_process(x0, t, quality)\n",
    "            \n",
    "            # 計算噪聲\n",
    "            noise = x0 - xt\n",
    "            \n",
    "            # 模型預測噪聲\n",
    "            compression_level = t.float() / num_timesteps\n",
    "            pred_noise = model(xt, t.float()/num_timesteps, compression_level)\n",
    "            \n",
    "            # 計算損失\n",
    "            huber_loss = huber_loss_fn(pred_noise, noise)\n",
    "            col_loss = color_preservation_loss(xt + pred_noise, x0)\n",
    "            \n",
    "            total_loss += huber_loss.item()\n",
    "            color_loss_total += col_loss.item()\n",
    "            \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    avg_color_loss = color_loss_total / len(loader)\n",
    "    print(f\"Validation - Avg Loss: {avg_loss:.5f}, Color Loss: {avg_color_loss:.5f}\")\n",
    "    \n",
    "    # 定期可視化結果進行直觀觀察\n",
    "    if epoch % 5 == 0:\n",
    "        visualize_restoration(model, epoch)\n",
    "    \n",
    "    return avg_loss, avg_color_loss\n",
    "\n",
    "# 可視化還原效果\n",
    "def visualize_restoration(model, epoch):\n",
    "    model.eval()\n",
    "    sampler = GaussianMixtureSampler(model)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x0, _ = next(iter(test_dataloader))\n",
    "        x0 = x0.to(device)\n",
    "        \n",
    "        # 測試不同的質量級別\n",
    "        qualities = [10, 30, 50, 70]\n",
    "        plt.figure(figsize=(len(qualities)*3+3, 6))\n",
    "        \n",
    "        # 顯示原始圖像\n",
    "        plt.subplot(2, len(qualities)+1, 1)\n",
    "        plt.imshow(x0[0].cpu().permute(1,2,0)*0.5+0.5)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 對每個質量級別顯示JPEG和還原結果\n",
    "        for i, q in enumerate(qualities):\n",
    "            # JPEG壓縮\n",
    "            xt = jpeg_compress(x0, q)\n",
    "            \n",
    "            # 設定初始時間步長對應質量\n",
    "            init_t = int((100 - q) / 100 * num_timesteps)\n",
    "            \n",
    "            # 使用GMM採樣器進行還原\n",
    "            restored = sampler.sample(xt, steps=init_t+1)\n",
    "            \n",
    "            # 顯示JPEG壓縮結果\n",
    "            plt.subplot(2, len(qualities)+1, i+2)\n",
    "            plt.imshow(xt[0].cpu().permute(1,2,0)*0.5+0.5)\n",
    "            plt.title(f\"JPEG Q{q}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # 顯示還原結果\n",
    "            plt.subplot(2, len(qualities)+1, len(qualities)+i+2)\n",
    "            plt.imshow(restored[0].cpu().permute(1,2,0)*0.5+0.5)\n",
    "            plt.title(f\"Restored Q{q}\")\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'viz_epoch_{epoch}.png')\n",
    "        plt.close()\n",
    "\n",
    "# 測量還原效果，使用高斯混合模型採樣方法\n",
    "def test_restoration(model, quality_levels=[10, 30, 50, 70]):\n",
    "    # 初始化採樣方法\n",
    "    sampler = GaussianMixtureSampler(model)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 隨機選取10個樣本\n",
    "        results = {q: {'psnr': [], 'ssim': []} for q in quality_levels}\n",
    "        \n",
    "        for idx in range(10):\n",
    "            x0, _ = next(iter(test_dataloader))\n",
    "            x0 = x0.to(device)\n",
    "            \n",
    "            plt.figure(figsize=(len(quality_levels)*3+3, 6))\n",
    "            \n",
    "            # 顯示原始圖像\n",
    "            plt.subplot(2, len(quality_levels)+1, 1)\n",
    "            plt.imshow(x0[0].cpu().permute(1,2,0)*0.5+0.5)\n",
    "            plt.title(\"Original\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # 對每個質量級別顯示JPEG和還原結果\n",
    "            for i, q in enumerate(quality_levels):\n",
    "                # JPEG壓縮\n",
    "                xt = jpeg_compress(x0, q)\n",
    "                \n",
    "                # 設定初始時間步長對應質量\n",
    "                init_t = int((100 - q) / 100 * num_timesteps)\n",
    "                \n",
    "                # 使用GMM採樣方法進行還原\n",
    "                restored = sampler.sample(xt, steps=init_t+1, guidance_scale=0.8)\n",
    "                \n",
    "                # 計算PSNR\n",
    "                x0_01 = (x0 * 0.5 + 0.5).clamp(0, 1)\n",
    "                xt_01 = (xt * 0.5 + 0.5).clamp(0, 1)\n",
    "                restored_01 = (restored * 0.5 + 0.5).clamp(0, 1)\n",
    "                \n",
    "                # 計算PSNR\n",
    "                xt_psnr = -10 * torch.log10(F.mse_loss(xt_01, x0_01)).item()\n",
    "                restored_psnr = -10 * torch.log10(F.mse_loss(restored_01, x0_01)).item()\n",
    "                \n",
    "                # 計算SSIM\n",
    "                xt_ssim = ssim(xt_01, x0_01, data_range=1.0).item()\n",
    "                restored_ssim = ssim(restored_01, x0_01, data_range=1.0).item()\n",
    "                \n",
    "                # 儲存結果\n",
    "                results[q]['psnr'].append(restored_psnr - xt_psnr)  # PSNR增益\n",
    "                results[q]['ssim'].append(restored_ssim - xt_ssim)  # SSIM增益\n",
    "                \n",
    "                # 顯示JPEG壓縮結果\n",
    "                plt.subplot(2, len(quality_levels)+1, i+2)\n",
    "                plt.imshow(xt[0].cpu().permute(1,2,0)*0.5+0.5)\n",
    "                plt.title(f\"JPEG Q{q}\\nPSNR: {xt_psnr:.2f}dB\\nSSIM: {xt_ssim:.4f}\")\n",
    "                plt.axis('off')\n",
    "                \n",
    "                # 顯示還原結果\n",
    "                plt.subplot(2, len(quality_levels)+1, len(quality_levels)+i+2)\n",
    "                plt.imshow(restored[0].cpu().permute(1,2,0)*0.5+0.5)\n",
    "                plt.title(f\"Restored\\nPSNR: {restored_psnr:.2f}dB\\nSSIM: {restored_ssim:.4f}\")\n",
    "                plt.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'./0409_test/test_sample_{idx+1}.png')\n",
    "            plt.close()\n",
    "        \n",
    "        # 顯示平均結果\n",
    "        print(\"\\nAverage Improvement:\")\n",
    "        for q in quality_levels:\n",
    "            avg_psnr_gain = sum(results[q]['psnr']) / len(results[q]['psnr'])\n",
    "            avg_ssim_gain = sum(results[q]['ssim']) / len(results[q]['ssim'])\n",
    "            print(f\"Quality {q}: PSNR Gain = {avg_psnr_gain:.2f}dB, SSIM Gain = {avg_ssim_gain:.4f}\")\n",
    "\n",
    "def train_model(epochs=100):\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    color_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # 訓練一個周期\n",
    "        train_loss, train_color_loss = train_epoch(model, train_dataloader, epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # 驗證一個周期\n",
    "        val_loss, val_color_loss = validate(model, valid_dataloader, epoch)\n",
    "        val_losses.append(val_loss)\n",
    "        color_losses.append(val_color_loss)\n",
    "        \n",
    "        # 保存模型如果驗證損失有改善\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'color_loss': val_color_loss\n",
    "            }, f\"best_jpeg_diffusion.pth\")\n",
    "            print(f\"New best model saved with val loss {val_loss:.5f} and color loss {val_color_loss:.5f}\")\n",
    "        \n",
    "        # 繪製訓練曲線\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(val_losses, label='Val Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(color_losses, label='Color Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Color Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_curves.png')\n",
    "        plt.close()\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "    \n",
    "    # 載入最佳模型\n",
    "    checkpoint = torch.load(\"best_jpeg_diffusion.pth\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded best model from epoch {checkpoint['epoch']+1} with val loss {checkpoint['val_loss']:.5f}\")\n",
    "    \n",
    "    # 測量還原效果\n",
    "    test_restoration(model)\n",
    "\n",
    "# 執行訓練\n",
    "if __name__ == \"__main__\":\n",
    "    # 開始訓練\n",
    "    train_model(epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n",
      "載入模型權重從Epoch 390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 100.19it/s] ?it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 101.38it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 101.42it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 101.38it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 100.28it/s]28:10,  1.89it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 100.25it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 100.19it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 101.93it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 100.95it/s]28:22,  1.89it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 101.59it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 101.89it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 101.50it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 100.32it/s]28:01,  1.89it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 101.08it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 101.92it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 101.49it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 101.28it/s]27:54,  1.90it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 101.15it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 101.82it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 101.63it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 98.72it/s]:27:51,  1.90it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 99.99it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 102.08it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 101.60it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 98.66it/s]:40:26,  1.66it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 99.07it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 99.17it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 99.83it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 99.99it/s]:37:03,  1.72it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 100.50it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 100.77it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 100.77it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 100.94it/s]34:19,  1.77it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 101.35it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 100.63it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 100.85it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 100.85it/s]32:49,  1.79it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 100.94it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 100.17it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 99.64it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 101.10it/s]:31:25,  1.82it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 99.04it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 101.51it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 100.70it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 99.40it/s]1:34:35,  1.76it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 100.52it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 100.76it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 100.42it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 98.26it/s]1:32:42,  1.80it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 98.88it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 101.02it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 100.63it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 99.15it/s]1:31:32,  1.82it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 99.19it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 101.71it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 99.84it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 100.24it/s]:30:45,  1.83it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 86.55it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 102.05it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 101.38it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 100.95it/s]:30:39,  1.84it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 101.57it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 102.01it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 101.81it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 98.64it/s]1:29:48,  1.85it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 100.59it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 101.91it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 101.60it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 99.98it/s]1:35:40,  1.74it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 101.43it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 100.85it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 101.41it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 101.39it/s]:34:05,  1.77it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 101.02it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 101.69it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 102.45it/s]\n",
      "Sampling: 100%|██████████| 10/10 [00:00<00:00, 101.04it/s]:32:23,  1.80it/s]\n",
      "Sampling: 100%|██████████| 9/9 [00:00<00:00, 100.31it/s]\n",
      "Sampling: 100%|██████████| 8/8 [00:00<00:00, 101.68it/s]\n",
      "Sampling: 100%|██████████| 6/6 [00:00<00:00, 100.49it/s]\n",
      "Processing test images:   0%|          | 20/10000 [00:11<1:32:07,  1.81it/s]\n",
      "/tmp/ipykernel_952952/1171025023.py:640: UserWarning: Glyph 36074 (\\N{CJK UNIFIED IDEOGRAPH-8CEA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_952952/1171025023.py:640: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_952952/1171025023.py:640: UserWarning: Glyph 25552 (\\N{CJK UNIFIED IDEOGRAPH-63D0}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_952952/1171025023.py:640: UserWarning: Glyph 21319 (\\N{CJK UNIFIED IDEOGRAPH-5347}) missing from current font.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== 結果摘要 ====\n",
      "質量         PSNR (壓縮)       PSNR (還原)       SSIM (壓縮)       SSIM (還原)      \n",
      "----------------------------------------------------------------------\n",
      "10         22.74           22.53           0.7784          0.7646         \n",
      "30         26.21           25.75           0.8814          0.8645         \n",
      "50         28.82           27.55           0.9283          0.9031         \n",
      "70         30.84           28.28           0.9518          0.9165         \n",
      "\n",
      "LPIPS 結果 (越低越好):\n",
      "質量         LPIPS (壓縮)      LPIPS (還原)     \n",
      "----------------------------------------\n",
      "10         0.0448          0.0384         \n",
      "30         0.0160          0.0161         \n",
      "50         0.0044          0.0061         \n",
      "70         0.0020          0.0050         \n",
      "\n",
      "所有結果已保存至 ./inference_results 目錄\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_952952/1171025023.py:640: UserWarning: Glyph 25913 (\\N{CJK UNIFIED IDEOGRAPH-6539}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_952952/1171025023.py:640: UserWarning: Glyph 21892 (\\N{CJK UNIFIED IDEOGRAPH-5584}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_952952/1171025023.py:640: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_952952/1171025023.py:640: UserWarning: Glyph 36234 (\\N{CJK UNIFIED IDEOGRAPH-8D8A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_952952/1171025023.py:640: UserWarning: Glyph 39640 (\\N{CJK UNIFIED IDEOGRAPH-9AD8}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_952952/1171025023.py:640: UserWarning: Glyph 22909 (\\N{CJK UNIFIED IDEOGRAPH-597D}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_952952/1171025023.py:641: UserWarning: Glyph 36074 (\\N{CJK UNIFIED IDEOGRAPH-8CEA}) missing from current font.\n",
      "  plt.savefig(f'{output_path}/performance_gains.png')\n",
      "/tmp/ipykernel_952952/1171025023.py:641: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from current font.\n",
      "  plt.savefig(f'{output_path}/performance_gains.png')\n",
      "/tmp/ipykernel_952952/1171025023.py:641: UserWarning: Glyph 25552 (\\N{CJK UNIFIED IDEOGRAPH-63D0}) missing from current font.\n",
      "  plt.savefig(f'{output_path}/performance_gains.png')\n",
      "/tmp/ipykernel_952952/1171025023.py:641: UserWarning: Glyph 21319 (\\N{CJK UNIFIED IDEOGRAPH-5347}) missing from current font.\n",
      "  plt.savefig(f'{output_path}/performance_gains.png')\n",
      "/tmp/ipykernel_952952/1171025023.py:641: UserWarning: Glyph 25913 (\\N{CJK UNIFIED IDEOGRAPH-6539}) missing from current font.\n",
      "  plt.savefig(f'{output_path}/performance_gains.png')\n",
      "/tmp/ipykernel_952952/1171025023.py:641: UserWarning: Glyph 21892 (\\N{CJK UNIFIED IDEOGRAPH-5584}) missing from current font.\n",
      "  plt.savefig(f'{output_path}/performance_gains.png')\n",
      "/tmp/ipykernel_952952/1171025023.py:641: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.\n",
      "  plt.savefig(f'{output_path}/performance_gains.png')\n",
      "/tmp/ipykernel_952952/1171025023.py:641: UserWarning: Glyph 36234 (\\N{CJK UNIFIED IDEOGRAPH-8D8A}) missing from current font.\n",
      "  plt.savefig(f'{output_path}/performance_gains.png')\n",
      "/tmp/ipykernel_952952/1171025023.py:641: UserWarning: Glyph 39640 (\\N{CJK UNIFIED IDEOGRAPH-9AD8}) missing from current font.\n",
      "  plt.savefig(f'{output_path}/performance_gains.png')\n",
      "/tmp/ipykernel_952952/1171025023.py:641: UserWarning: Glyph 22909 (\\N{CJK UNIFIED IDEOGRAPH-597D}) missing from current font.\n",
      "  plt.savefig(f'{output_path}/performance_gains.png')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pytorch_msssim import ssim\n",
    "import lpips\n",
    "\n",
    "# 設定設備\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 載入CIFAR10測試數據\n",
    "def load_test_data(test_data_path, batch_size=1):\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    # 若您有自定義的測試數據集類，請替換下面的代碼\n",
    "    # 例如：test_dataset = YourCustomDataset(test_data_path, transform=transform)\n",
    "    \n",
    "    # 默認使用CIFAR10\n",
    "    test_dataset = torchvision.datasets.CIFAR10(\n",
    "        root=test_data_path, train=False, download=True, transform=transform\n",
    "    )\n",
    "    \n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return test_dataloader\n",
    "\n",
    "# JPEG壓縮函數\n",
    "def jpeg_compress(x, quality):\n",
    "    \"\"\"執行JPEG壓縮並保留色彩資訊\"\"\"\n",
    "    x = (x * 127.5 + 127.5).clamp(0, 255).to(torch.uint8).cpu()\n",
    "    compressed_images = []\n",
    "    for img in x:\n",
    "        pil_img = torchvision.transforms.ToPILImage()(img)\n",
    "        buffer = io.BytesIO()\n",
    "        # 確保quality在1-100的有效區間內\n",
    "        quality = max(1, min(100, int(quality)))\n",
    "        # 根據壓縮質量選擇子採樣方式，高質量時保留色彩資訊\n",
    "        subsampling = \"4:4:4\" if quality > 30 else \"4:2:0\"\n",
    "        pil_img.save(buffer, format=\"JPEG\", quality=quality, subsampling=subsampling)\n",
    "        buffer.seek(0)\n",
    "        compressed_img = Image.open(buffer)\n",
    "        compressed_tensor = torchvision.transforms.ToTensor()(compressed_img)\n",
    "        compressed_images.append(compressed_tensor)\n",
    "    return torch.stack(compressed_images).to(device).sub(0.5).div(0.5)\n",
    "\n",
    "# 時間嵌入模組\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim * 4, dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, t):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return self.proj(emb)\n",
    "\n",
    "# DCT變換層\n",
    "class DCTLayer(nn.Module):\n",
    "    \"\"\"執行DCT變換操作，處理頻率域信息\"\"\"\n",
    "    def __init__(self, block_size=8):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 執行DCT變換並確保輸出尺寸與輸入一致\n",
    "        x_dct = self._apply_dct(x)\n",
    "        b, c, h, w = x.shape\n",
    "        if x_dct.shape[2:] != x.shape[2:]:\n",
    "            x_dct = F.interpolate(x_dct, size=(h, w), mode='bilinear', align_corners=False)\n",
    "        return x_dct\n",
    "    \n",
    "    def _apply_dct(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        \n",
    "        # 填充至block_size的整數倍\n",
    "        h_pad = (self.block_size - h % self.block_size) % self.block_size\n",
    "        w_pad = (self.block_size - w % self.block_size) % self.block_size\n",
    "        \n",
    "        x_padded = F.pad(x, (0, w_pad, 0, h_pad))\n",
    "        _, _, h_padded, w_padded = x_padded.shape\n",
    "        \n",
    "        # 計算區塊數量\n",
    "        h_blocks = h_padded // self.block_size\n",
    "        w_blocks = w_padded // self.block_size\n",
    "        \n",
    "        # 分割圖像\n",
    "        x_blocks = x_padded.unfold(2, self.block_size, self.block_size).unfold(3, self.block_size, self.block_size)\n",
    "        \n",
    "        # 變形為適合DCT的形狀\n",
    "        b_unf, c_unf, h_unf, w_unf, bs_h, bs_w = x_blocks.shape\n",
    "        x_blocks_flat = x_blocks.reshape(-1, self.block_size, self.block_size)\n",
    "        \n",
    "        # 獲取DCT矩陣\n",
    "        dct_matrix = self._get_dct_matrix(self.block_size).to(x.device)\n",
    "        \n",
    "        # 應用DCT變換: D * X * D^T\n",
    "        x_dct_flat = torch.matmul(dct_matrix, x_blocks_flat)\n",
    "        x_dct_flat = torch.matmul(x_dct_flat, dct_matrix.transpose(0, 1))\n",
    "        \n",
    "        # 還原形狀\n",
    "        x_dct_blocks = x_dct_flat.reshape(b_unf, c_unf, h_unf, w_unf, bs_h, bs_w)\n",
    "        \n",
    "        # 重新排列並還原為原始形狀\n",
    "        x_dct_perm = x_dct_blocks.permute(0, 1, 2, 4, 3, 5)\n",
    "        x_dct = x_dct_perm.reshape(b, c, h_padded, w_padded)\n",
    "        \n",
    "        # 移除填充部分\n",
    "        if h_pad > 0 or w_pad > 0:\n",
    "            x_dct = x_dct[:, :, :h, :w]\n",
    "        \n",
    "        return x_dct\n",
    "    \n",
    "    def _get_dct_matrix(self, size):\n",
    "        \"\"\"生成標準DCT變換矩陣\"\"\"\n",
    "        dct_matrix = torch.zeros(size, size)\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                if i == 0:\n",
    "                    dct_matrix[i, j] = 1.0 / torch.sqrt(torch.tensor(size, dtype=torch.float32))\n",
    "                else:\n",
    "                    dct_matrix[i, j] = torch.sqrt(torch.tensor(2.0 / size)) * torch.cos(torch.tensor(torch.pi * (2 * j + 1) * i / (2 * size)))\n",
    "        return dct_matrix\n",
    "\n",
    "# 高頻增強模組\n",
    "class HFCM(nn.Module):\n",
    "    \"\"\"高頻增強模組，參考FDG-Diff論文方法\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.dct = DCTLayer(block_size=8)\n",
    "        self.high_freq_attn = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.conv_out = nn.Conv2d(channels, channels, 1)\n",
    "        \n",
    "    def forward(self, x, compression_level):\n",
    "        # 獲取DCT頻率表示\n",
    "        x_dct = self.dct(x)\n",
    "        \n",
    "        # 確保x_dct與x具有相同的空間尺寸\n",
    "        if x_dct.shape[2:] != x.shape[2:]:\n",
    "            x_dct = F.interpolate(x_dct, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # 高頻注意力機制\n",
    "        attn_mask = self.high_freq_attn(x)\n",
    "        \n",
    "        # 根據compression_level調整權重\n",
    "        if isinstance(compression_level, torch.Tensor) and compression_level.dim() > 0:\n",
    "            compression_level = compression_level.view(-1, 1, 1, 1)\n",
    "        \n",
    "        # 壓縮程度越高(值越大)，保留的高頻越少\n",
    "        freq_scale = 1.0 - compression_level\n",
    "        \n",
    "        # 應用高頻增強\n",
    "        enhanced = x + attn_mask * x_dct * freq_scale\n",
    "        return self.conv_out(enhanced)\n",
    "\n",
    "# 頻率感知塊\n",
    "class FrequencyAwareBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.dct_layer = DCTLayer(block_size=8)\n",
    "        self.freq_conv = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.freq_attn = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // 4, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels // 4, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, compression_level):\n",
    "        # 獲取頻率表示\n",
    "        x_dct = self.dct_layer(x)\n",
    "        \n",
    "        # 確保x_dct與x具有相同的空間尺寸\n",
    "        if x_dct.shape[2:] != x.shape[2:]:\n",
    "            x_dct = F.interpolate(x_dct, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "            \n",
    "        x_freq = self.freq_conv(x_dct)\n",
    "        \n",
    "        # 確保x_freq與x具有相同的空間尺寸\n",
    "        if x_freq.shape[2:] != x.shape[2:]:\n",
    "            x_freq = F.interpolate(x_freq, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # 生成頻率注意力圖\n",
    "        attn = self.freq_attn(x_freq)\n",
    "        \n",
    "        # 根據compression_level調整注意力權重\n",
    "        if isinstance(compression_level, torch.Tensor) and compression_level.dim() > 0:\n",
    "            compression_level = compression_level.view(-1, 1, 1, 1)\n",
    "        \n",
    "        # 壓縮程度越高，注意力權重越低\n",
    "        attn = attn * (1.0 - compression_level) + 0.5\n",
    "        \n",
    "        # 確保attn與x_freq尺寸一致\n",
    "        if attn.shape[2:] != x_freq.shape[2:]:\n",
    "            attn = F.interpolate(attn, size=x_freq.shape[2:], mode='nearest')\n",
    "        \n",
    "        # 應用頻率注意力\n",
    "        return x + x_freq * attn\n",
    "\n",
    "# 殘差注意力塊\n",
    "class ResAttnBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c, time_dim, dropout=0.1, use_freq_guide=False):\n",
    "        super().__init__()\n",
    "        # 確保組數適合通道數\n",
    "        num_groups = min(8, in_c)\n",
    "        while in_c % num_groups != 0 and num_groups > 1:\n",
    "            num_groups -= 1\n",
    "            \n",
    "        self.norm1 = nn.GroupNorm(num_groups, in_c)\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, 3, padding=1)\n",
    "        self.time_proj = nn.Linear(time_dim, out_c)\n",
    "        \n",
    "        # 調整 out_c 的組數\n",
    "        num_groups_out = min(8, out_c)\n",
    "        while out_c % num_groups_out != 0 and num_groups_out > 1:\n",
    "            num_groups_out -= 1\n",
    "            \n",
    "        self.norm2 = nn.GroupNorm(num_groups_out, out_c)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, 3, padding=1)\n",
    "        self.attn = nn.MultiheadAttention(out_c, 4, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.shortcut = nn.Conv2d(in_c, out_c, 1) if in_c != out_c else nn.Identity()\n",
    "        \n",
    "        # 頻率增強(可選使用)\n",
    "        self.use_freq_guide = use_freq_guide\n",
    "        if use_freq_guide:\n",
    "            self.freq_guide = FrequencyAwareBlock(out_c)\n",
    "            self.hfcm = HFCM(out_c)\n",
    "        \n",
    "    def forward(self, x, t_emb, compression_level=None):\n",
    "        h = self.norm1(x)\n",
    "        h = self.conv1(h)\n",
    "        \n",
    "        # 加入時間編碼\n",
    "        t = self.time_proj(t_emb)[..., None, None]\n",
    "        h = h + t\n",
    "        \n",
    "        h = self.norm2(h)\n",
    "        h = self.conv2(F.silu(h))\n",
    "        \n",
    "        # 應用自注意力機制\n",
    "        b, c, hh, ww = h.shape\n",
    "        h_attn = h.view(b, c, -1).permute(0, 2, 1)\n",
    "        h_attn, _ = self.attn(h_attn, h_attn, h_attn)\n",
    "        h_attn = h_attn.permute(0, 2, 1).view(b, c, hh, ww)\n",
    "        \n",
    "        # 應用頻率增強(如果啟用)\n",
    "        if self.use_freq_guide and compression_level is not None:\n",
    "            h_attn = self.freq_guide(h_attn, compression_level)\n",
    "            h_attn = self.hfcm(h_attn, compression_level)\n",
    "        \n",
    "        return self.shortcut(x) + self.dropout(h_attn)\n",
    "\n",
    "# JPEG擴散模型\n",
    "class JPEGDiffusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        time_dim = 256\n",
    "        self.time_embed = TimeEmbedding(time_dim)\n",
    "        \n",
    "        # 下採樣路徑\n",
    "        self.down1 = ResAttnBlock(3, 64, time_dim)\n",
    "        self.down2 = ResAttnBlock(64, 128, time_dim, use_freq_guide=True)\n",
    "        self.down3 = ResAttnBlock(128, 256, time_dim, use_freq_guide=True)\n",
    "        self.down4 = ResAttnBlock(256, 512, time_dim)\n",
    "        self.down5 = ResAttnBlock(512, 512, time_dim)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # 瓶頸層\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            ResAttnBlock(512, 1024, time_dim, use_freq_guide=True),\n",
    "            ResAttnBlock(1024, 1024, time_dim),\n",
    "            ResAttnBlock(1024, 512, time_dim, use_freq_guide=True)\n",
    "        )\n",
    "        \n",
    "        # 上採樣路徑\n",
    "        self.up1 = ResAttnBlock(1024, 512, time_dim)\n",
    "        self.up2 = ResAttnBlock(512 + 512, 256, time_dim, use_freq_guide=True)\n",
    "        self.up3 = ResAttnBlock(256 + 256, 128, time_dim, use_freq_guide=True)\n",
    "        self.up4 = ResAttnBlock(128 + 128, 64, time_dim)\n",
    "        self.up5 = ResAttnBlock(64 + 64, 64, time_dim)\n",
    "        \n",
    "        # 輸出層\n",
    "        self.out_conv = nn.Conv2d(64, 3, 1)\n",
    "        \n",
    "    def forward(self, x, t, compression_level=None):\n",
    "        t_emb = self.time_embed(t)\n",
    "        \n",
    "        # 如果未提供壓縮程度，使用時間步長代替\n",
    "        if compression_level is None:\n",
    "            compression_level = t.clone().detach()\n",
    "        \n",
    "        # 下採樣\n",
    "        d1 = self.down1(x, t_emb)  # 32x32\n",
    "        d2 = self.down2(self.pool(d1), t_emb, compression_level)  # 16x16\n",
    "        d3 = self.down3(self.pool(d2), t_emb, compression_level)  # 8x8\n",
    "        d4 = self.down4(self.pool(d3), t_emb)  # 4x4\n",
    "        d5 = self.down5(self.pool(d4), t_emb)  # 2x2\n",
    "        \n",
    "        # 瓶頸層\n",
    "        b = self.bottleneck[0](self.pool(d5), t_emb, compression_level)\n",
    "        b = self.bottleneck[1](b, t_emb)\n",
    "        b = self.bottleneck[2](b, t_emb, compression_level)\n",
    "        \n",
    "        # 上採樣 - 使用連接操作將特徵合併回來\n",
    "        u1 = self.up1(torch.cat([F.interpolate(b, scale_factor=2, mode='bilinear', align_corners=False), d5], dim=1), t_emb)\n",
    "        u2 = self.up2(torch.cat([F.interpolate(u1, scale_factor=2, mode='bilinear', align_corners=False), d4], dim=1), t_emb, compression_level)\n",
    "        u3 = self.up3(torch.cat([F.interpolate(u2, scale_factor=2, mode='bilinear', align_corners=False), d3], dim=1), t_emb, compression_level)\n",
    "        u4 = self.up4(torch.cat([F.interpolate(u3, scale_factor=2, mode='bilinear', align_corners=False), d2], dim=1), t_emb)\n",
    "        u5 = self.up5(torch.cat([F.interpolate(u4, scale_factor=2, mode='bilinear', align_corners=False), d1], dim=1), t_emb)\n",
    "        \n",
    "        return self.out_conv(u5)\n",
    "\n",
    "# SVD結構保持函數\n",
    "def svd_structure_preservation(x, k_ratio=0.5):\n",
    "    \"\"\"使用SVD保持主要結構特徵\"\"\"\n",
    "    b, c, h, w = x.shape\n",
    "    x_flat = x.view(b, c, -1)\n",
    "    \n",
    "    # 對每個通道分別進行SVD分解\n",
    "    structure_tensors = []\n",
    "    for i in range(b):\n",
    "        channels_structure = []\n",
    "        for j in range(c):\n",
    "            # SVD分解\n",
    "            U, S, Vh = torch.linalg.svd(x_flat[i, j].view(h, w), full_matrices=False)\n",
    "            \n",
    "            # 確定保留的奇異值數量\n",
    "            k = max(1, int(min(h, w) * k_ratio))\n",
    "            \n",
    "            # 重建低秩表示\n",
    "            S_k = torch.zeros_like(S)\n",
    "            S_k[:k] = S[:k]\n",
    "            structure = torch.matmul(U, torch.matmul(torch.diag(S_k), Vh))\n",
    "            channels_structure.append(structure.unsqueeze(0))\n",
    "        \n",
    "        # 合併通道結構\n",
    "        structure_tensors.append(torch.cat(channels_structure, dim=0).unsqueeze(0))\n",
    "    \n",
    "    return torch.cat(structure_tensors, dim=0)\n",
    "\n",
    "# 相位一致性函數\n",
    "def phase_consistency(x, ref, alpha=0.7):\n",
    "    \"\"\"使用傅里葉變換的相位一致性，保持頻域特性\"\"\"\n",
    "    # FFT變換\n",
    "    x_fft = torch.fft.fft2(x)\n",
    "    ref_fft = torch.fft.fft2(ref)\n",
    "    \n",
    "    # 獲取幅度和相位\n",
    "    x_mag = torch.abs(x_fft)\n",
    "    ref_phase = torch.angle(ref_fft)\n",
    "    \n",
    "    # 融合x的幅度和ref的相位\n",
    "    real = x_mag * torch.cos(ref_phase)\n",
    "    imag = x_mag * torch.sin(ref_phase)\n",
    "    adjusted_fft = torch.complex(real, imag)\n",
    "    \n",
    "    # 逆變換\n",
    "    adjusted_img = torch.fft.ifft2(adjusted_fft).real\n",
    "    \n",
    "    # 混合原始影像和相位調整影像\n",
    "    return alpha * x + (1 - alpha) * adjusted_img\n",
    "\n",
    "# 高斯混合採樣器\n",
    "class GaussianMixtureSampler:\n",
    "    def __init__(self, model, num_timesteps=100):\n",
    "        self.model = model\n",
    "        self.num_timesteps = num_timesteps\n",
    "        \n",
    "    def sample(self, x_t, steps=100, use_phase_consistency=True, use_svd_guide=True, guidance_scale=1.0):\n",
    "        \"\"\"使用高斯混合採樣進行推理，結合頻率一致性和SVD引導\"\"\"\n",
    "        self.model.eval()\n",
    "        # 保存初始壓縮影像作為頻率一致性基準\n",
    "        original_compressed = x_t.clone()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # 從給定的噪聲影像開始\n",
    "            for i in tqdm(range(steps-1, -1, -1), desc=\"Sampling\"):\n",
    "                t = torch.full((x_t.size(0),), i, device=device).float() / self.num_timesteps\n",
    "                compression_level = t.clone()  # 壓縮程度與時間步長關聯\n",
    "                \n",
    "                # 獲取噪聲預測\n",
    "                pred_noise = self.model(x_t, t, compression_level)\n",
    "                \n",
    "                # 可選使用SVD引導\n",
    "                if use_svd_guide and i > steps // 2:\n",
    "                    # 在採樣前半部分使用SVD引導(結構保存)\n",
    "                    k_ratio = i / steps  # 隨時間步長調整重要度\n",
    "                    structure_prior = svd_structure_preservation(x_t, k_ratio)\n",
    "                    # 混合SVD結構先驗與預測\n",
    "                    guide_strength = k_ratio * 0.3  # SVD權重隨時間步長調整\n",
    "                    pred_noise = (1 - guide_strength) * pred_noise + guide_strength * (original_compressed - structure_prior)\n",
    "                \n",
    "                if i > 0:\n",
    "                    # 預測的x0\n",
    "                    x0_pred = x_t + pred_noise\n",
    "                    \n",
    "                    # 計算高斯混合模型的兩個均值\n",
    "                    # 第一個均值 - 偏向原生的預測\n",
    "                    mu1 = x0_pred * 0.9 + x_t * 0.1\n",
    "                    # 第二個均值 - 偏向更激進的預測\n",
    "                    mu2 = x0_pred * 1.1 - x_t * 0.1\n",
    "                    \n",
    "                    # 根據當前時間步長動態使用不同均值\n",
    "                    # 時間步長較大時偏向保守，較小時偏向激進\n",
    "                    p_conservative = max(0.2, min(0.8, i / steps))\n",
    "                    use_first = torch.rand(1).item() < p_conservative\n",
    "                    next_mean = mu1 if use_first else mu2\n",
    "                    \n",
    "                    # 添加適量高斯噪聲\n",
    "                    noise_scale = 0.1 * i / steps * guidance_scale\n",
    "                    x_next = next_mean + noise_scale * torch.randn_like(x_t)\n",
    "                    \n",
    "                    # 頻率一致性保持(每5步使用一次)\n",
    "                    if use_phase_consistency and i % 5 == 0:\n",
    "                        alpha = 0.6 + 0.3 * (1 - i / steps)  # 隨時間步長加強初始影像權重\n",
    "                        x_next = phase_consistency(x_next, original_compressed, alpha)\n",
    "                    \n",
    "                    x_t = x_next\n",
    "                else:\n",
    "                    # 最後一步直接使用預測的去噪結果\n",
    "                    x_t = x_t + pred_noise\n",
    "        \n",
    "        return x_t\n",
    "\n",
    "# 計算評估指標\n",
    "def calculate_metrics(original, restored):\n",
    "    \"\"\"計算PSNR和SSIM指標\"\"\"\n",
    "    # 轉換到[0,1]區間\n",
    "    original_01 = (original * 0.5 + 0.5).clamp(0, 1)\n",
    "    restored_01 = (restored * 0.5 + 0.5).clamp(0, 1)\n",
    "    \n",
    "    # 計算PSNR\n",
    "    mse = F.mse_loss(original_01, restored_01)\n",
    "    psnr = -10 * torch.log10(mse)\n",
    "    \n",
    "    # 計算SSIM\n",
    "    ssim_val = ssim(original_01, restored_01, data_range=1.0)\n",
    "    \n",
    "    return psnr.item(), ssim_val.item()\n",
    "\n",
    "# 執行推理主函數\n",
    "def run_inference(model_path, test_data_path, output_path, num_samples=20, qualities=[10, 30, 50, 70]):\n",
    "    \"\"\"執行推理並產生結果\"\"\"\n",
    "    # 確保輸出目錄存在\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # 載入資料\n",
    "    test_dataloader = load_test_data(test_data_path)\n",
    "    \n",
    "    # 嘗試載入LPIPS模型\n",
    "    try:\n",
    "        lpips_fn = lpips.LPIPS(net='alex').to(device)\n",
    "        use_lpips = True\n",
    "    except:\n",
    "        print(\"未能載入LPIPS模型，將跳過LPIPS評估\")\n",
    "        use_lpips = False\n",
    "        lpips_fn = None\n",
    "    \n",
    "    # 載入模型\n",
    "    model = JPEGDiffusionModel().to(device)\n",
    "    num_timesteps = 100\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            print(f\"載入模型權重從Epoch {checkpoint['epoch']+1}\")\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "            print(\"載入模型權重\")\n",
    "    except Exception as e:\n",
    "        print(f\"載入模型失敗: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 初始化採樣器\n",
    "    model.eval()\n",
    "    sampler = GaussianMixtureSampler(model, num_timesteps=num_timesteps)\n",
    "    \n",
    "    # 追蹤結果\n",
    "    results = {q: {'psnr_compressed': [], 'psnr_restored': [], \n",
    "                   'ssim_compressed': [], 'ssim_restored': []} for q in qualities}\n",
    "    if use_lpips:\n",
    "        for q in qualities:\n",
    "            results[q]['lpips_compressed'] = []\n",
    "            results[q]['lpips_restored'] = []\n",
    "    \n",
    "    # 處理每個測試樣本\n",
    "    for idx, (x0, _) in enumerate(tqdm(test_dataloader, desc=\"Processing test images\")):\n",
    "        if idx >= num_samples:\n",
    "            break\n",
    "            \n",
    "        x0 = x0.to(device)\n",
    "        \n",
    "        # 為這個樣本創建圖像\n",
    "        plt.figure(figsize=(len(qualities)*4+4, 8))\n",
    "        plt.subplot(2, len(qualities)+1, 1)\n",
    "        plt.imshow((x0[0].cpu().permute(1, 2, 0) * 0.5 + 0.5).clamp(0, 1))\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 測試每個質量級別\n",
    "        for i, quality in enumerate(qualities):\n",
    "            # 進行JPEG壓縮\n",
    "            compressed = jpeg_compress(x0, quality)\n",
    "            \n",
    "            # 設定初始時間步長\n",
    "            init_t = int((100 - quality)**(1/2) / 100 * num_timesteps)\n",
    "            \n",
    "            # 使用擴散模型恢復\n",
    "            restored = sampler.sample(compressed, steps=init_t+1, guidance_scale=0.8)\n",
    "            \n",
    "            # 計算PSNR和SSIM\n",
    "            psnr_compressed, ssim_compressed = calculate_metrics(x0, compressed)\n",
    "            psnr_restored, ssim_restored = calculate_metrics(x0, restored)\n",
    "            \n",
    "            # 記錄結果\n",
    "            results[quality]['psnr_compressed'].append(psnr_compressed)\n",
    "            results[quality]['psnr_restored'].append(psnr_restored)\n",
    "            results[quality]['ssim_compressed'].append(ssim_compressed)\n",
    "            results[quality]['ssim_restored'].append(ssim_restored)\n",
    "            \n",
    "            # 如果可用，計算LPIPS\n",
    "            if use_lpips:\n",
    "                orig_01 = (x0 * 0.5 + 0.5).clamp(0, 1) * 2 - 1  # 轉換到[-1,1]區間供LPIPS使用\n",
    "                comp_01 = (compressed * 0.5 + 0.5).clamp(0, 1) * 2 - 1\n",
    "                rest_01 = (restored * 0.5 + 0.5).clamp(0, 1) * 2 - 1\n",
    "                \n",
    "                lpips_compressed = lpips_fn(orig_01, comp_01).item()\n",
    "                lpips_restored = lpips_fn(orig_01, rest_01).item()\n",
    "                \n",
    "                results[quality]['lpips_compressed'].append(lpips_compressed)\n",
    "                results[quality]['lpips_restored'].append(lpips_restored)\n",
    "                \n",
    "                lpips_info = f\"\\nLPIPS: {lpips_compressed:.4f}\"\n",
    "                lpips_restored_info = f\"\\nLPIPS: {lpips_restored:.4f}\"\n",
    "            else:\n",
    "                lpips_info = \"\"\n",
    "                lpips_restored_info = \"\"\n",
    "            \n",
    "            # 顯示壓縮圖像\n",
    "            plt.subplot(2, len(qualities)+1, i+2)\n",
    "            plt.imshow((compressed[0].cpu().permute(1, 2, 0) * 0.5 + 0.5).clamp(0, 1))\n",
    "            plt.title(f\"JPEG Q{quality}\\nPSNR: {psnr_compressed:.2f}dB\\nSSIM: {ssim_compressed:.4f}{lpips_info}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # 顯示恢復圖像\n",
    "            plt.subplot(2, len(qualities)+1, len(qualities)+i+2)\n",
    "            plt.imshow((restored[0].cpu().permute(1, 2, 0) * 0.5 + 0.5).clamp(0, 1))\n",
    "            plt.title(f\"Restored\\nPSNR: {psnr_restored:.2f}dB\\nSSIM: {ssim_restored:.4f}{lpips_restored_info}\")\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_path}/sample_{idx+1}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 計算和打印平均結果\n",
    "    print(\"\\n==== 結果摘要 ====\")\n",
    "    print(f\"{'質量':<10} {'PSNR (壓縮)':<15} {'PSNR (還原)':<15} {'SSIM (壓縮)':<15} {'SSIM (還原)':<15}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for q in qualities:\n",
    "        avg_psnr_comp = sum(results[q]['psnr_compressed']) / len(results[q]['psnr_compressed'])\n",
    "        avg_psnr_rest = sum(results[q]['psnr_restored']) / len(results[q]['psnr_restored'])\n",
    "        avg_ssim_comp = sum(results[q]['ssim_compressed']) / len(results[q]['ssim_compressed'])\n",
    "        avg_ssim_rest = sum(results[q]['ssim_restored']) / len(results[q]['ssim_restored'])\n",
    "        \n",
    "        print(f\"{q:<10} {avg_psnr_comp:<15.2f} {avg_psnr_rest:<15.2f} {avg_ssim_comp:<15.4f} {avg_ssim_rest:<15.4f}\")\n",
    "        \n",
    "    # 如果有LPIPS結果\n",
    "    if use_lpips:\n",
    "        print(\"\\nLPIPS 結果 (越低越好):\")\n",
    "        print(f\"{'質量':<10} {'LPIPS (壓縮)':<15} {'LPIPS (還原)':<15}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for q in qualities:\n",
    "            avg_lpips_comp = sum(results[q]['lpips_compressed']) / len(results[q]['lpips_compressed'])\n",
    "            avg_lpips_rest = sum(results[q]['lpips_restored']) / len(results[q]['lpips_restored'])\n",
    "            print(f\"{q:<10} {avg_lpips_comp:<15.4f} {avg_lpips_rest:<15.4f}\")\n",
    "    \n",
    "    # 繪製性能提升圖\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # PSNR提升\n",
    "    plt.subplot(1, 3, 1)\n",
    "    psnr_gains = [sum(results[q]['psnr_restored']) / len(results[q]['psnr_restored']) - \n",
    "                  sum(results[q]['psnr_compressed']) / len(results[q]['psnr_compressed']) \n",
    "                  for q in qualities]\n",
    "    plt.bar(qualities, psnr_gains)\n",
    "    plt.title('PSNR提升(dB)')\n",
    "    plt.xlabel('JPEG質量')\n",
    "    plt.ylabel('提升(dB)')\n",
    "    \n",
    "    # SSIM提升\n",
    "    plt.subplot(1, 3, 2)\n",
    "    ssim_gains = [sum(results[q]['ssim_restored']) / len(results[q]['ssim_restored']) - \n",
    "                  sum(results[q]['ssim_compressed']) / len(results[q]['ssim_compressed']) \n",
    "                  for q in qualities]\n",
    "    plt.bar(qualities, ssim_gains)\n",
    "    plt.title('SSIM提升')\n",
    "    plt.xlabel('JPEG質量')\n",
    "    plt.ylabel('提升')\n",
    "    \n",
    "    # LPIPS改善 (如果可用)\n",
    "    if use_lpips:\n",
    "        plt.subplot(1, 3, 3)\n",
    "        lpips_gains = [sum(results[q]['lpips_compressed']) / len(results[q]['lpips_compressed']) - \n",
    "                       sum(results[q]['lpips_restored']) / len(results[q]['lpips_restored']) \n",
    "                       for q in qualities]\n",
    "        plt.bar(qualities, lpips_gains)\n",
    "        plt.title('LPIPS改善')\n",
    "        plt.xlabel('JPEG質量')\n",
    "        plt.ylabel('改善(值越高越好)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/performance_gains.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\n所有結果已保存至 {output_path} 目錄\")\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 配置參數\n",
    "    model_path = \"best_jpeg_diffusion.pth\"  # 預訓練模型路徑\n",
    "    test_data_path = \"./data\"  # 測試數據路徑\n",
    "    output_path = \"./inference_results\"  # 輸出路徑\n",
    "    num_samples = 20  # 測試樣本數量\n",
    "    qualities = [10, 30, 50, 70]  # 測試的JPEG壓縮質量\n",
    "    \n",
    "    # 執行推理\n",
    "    run_inference(model_path, test_data_path, output_path, num_samples, qualities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
